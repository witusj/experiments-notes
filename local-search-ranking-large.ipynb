{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Large instance local search with trained XGBoost regressor model\n",
        "---"
      ],
      "id": "54b57a85"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective\n",
        "\n",
        "Test the working and performance of a [previously trained](xgboost-pairwise-ranking-large-w-bailey-welch.qmd) XGBoost Ranking model in a local search application.\n",
        "\n",
        "## Background\n",
        "\n",
        "In previous experiments, we trained an XGBoost Classifier model to predict the objective values of neighboring schedules. In this experiment, we will use the trained models to perform a local search to find the best schedule.\n",
        "\n",
        "## Hypothesis\n",
        "\n",
        "The XGBoost Classifier model will be able to efficiently guide the local search algorithm to find a schedule with a lower objective value than the initial schedule.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "### Tools and Materials\n"
      ],
      "id": "f8115caa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from itertools import chain, combinations\n",
        "import sys\n",
        "from math import comb  # Available in Python 3.8 and later\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "from typing import List, Tuple, Dict, Iterable, TypeVar, Union"
      ],
      "id": "c152743b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Parameters\n"
      ],
      "id": "9f1ebb9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "N = 22 # Number of patients\n",
        "T = 20 # Number of intervals\n",
        "l = 10\n",
        "\n",
        "file_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\n",
        "# Load the data from the pickle file\n",
        "with open(file_path_parameters, 'rb') as f:\n",
        "    data_params = pickle.load(f)\n",
        "\n",
        "N = data_params['N'] # Number of patients\n",
        "T = data_params['T'] # Number of intervals\n",
        "d = data_params['d'] # Length of each interval\n",
        "max_s = data_params['max_s'] # Maximum service time\n",
        "q = data_params['q'] # Probability of a scheduled patient not showing up\n",
        "w = data_params['w'] # Weight for the waiting time in objective function\n",
        "l = data_params['l']\n",
        "  \n",
        "num_schedules = data_params['num_schedules'] # Number of schedules to sample\n",
        "convolutions = data_params['convolutions']\n",
        "print(f\"Parameters loaded: N={N}, T={T}, l={l}, d={d}, max_s={max_s}, q={q}, w={w}, num_schedules={num_schedules}\")"
      ],
      "id": "4b863a4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimental Design\n",
        "\n",
        "We will use the trained XGBoost Classifier model to guide a local search algorithm to find the best schedule. The local search algorithm will start with an initial schedule and iteratively explore the neighborhood of the current schedule to find a better one. As an initial schedule, we will use the schedule with the lowest objective value from the training dataset that was used to train the XGBoost Classifier model.\n",
        "\n",
        "### Variables\n",
        "\n",
        "-   **Independent Variables**:\n",
        "    -   Initial schedule, trained XGBoost Classifier\n",
        "-   **Dependent Variables**:\n",
        "    -   Speed, accuracy, and convergence of the local search algorithm.\n",
        "\n",
        "### Data Collection\n",
        "\n",
        "We will use the training dataset to initialize the local search algorithm.\n",
        "\n",
        "### Sample Size and Selection\n",
        "\n",
        "### Experimental Procedure\n",
        "\n",
        "![Local search algorithm](images/local_search_algorithm.png){#fig-local-search-algorithm}\n",
        "\n",
        "## Results\n",
        "\n",
        "### Load the initial best schedule.\n",
        "\n",
        "Start with the best solution found so far $\\{x^*, C(x^*)\\}$ from the training set.\n"
      ],
      "id": "8698657c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the best solution from the training dataset\n",
        "file_path_schedules = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\n",
        "# Load the data from the pickle file\n",
        "with open(file_path_schedules, 'rb') as f:\n",
        "    data_sch = pickle.load(f)\n",
        "    \n",
        "print(f\"The data has following keys: {[key for key in data_sch.keys()]}\")\n",
        "\n",
        "# Step 1: Flatten the objectives into a 1D array\n",
        "flattened_data = [value for sublist in data_sch['objectives'] for value in sublist]\n",
        "\n",
        "# Step 2: Find the index of the minimum value\n",
        "min_index = np.argmin(flattened_data)\n",
        "\n",
        "# Step 3: Convert that index back to the original 2D structure\n",
        "row_index = min_index // 2  # Assuming each inner list has 2 values\n",
        "col_index = min_index % 2\n",
        "\n",
        "print(f\"The minimum objective value is at index [{row_index}][{col_index}].\\nThis is schedule: {data_sch['neighbors_list'][row_index][col_index]} with objective value {data_sch['objectives'][row_index][col_index]}.\")\n",
        "\n",
        "# Set the initial schedule to the best solution from the training dataset\n",
        "initial_schedule = data_sch['neighbors_list'][row_index][col_index]"
      ],
      "id": "c985ec23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate the neighborhood of $x^*$.\n",
        "\n",
        "#### Define $V^*$.\n",
        "\n",
        "Define the vectors $V^*$ as follows:\n",
        "\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{array}{c}\n",
        "\\vec{v_1}, \\\\\n",
        "\\vec{v_2}, \\\\\n",
        "\\vec{v_3}, \\\\\n",
        "\\vdots \\\\\n",
        "\\vec{v_{T-1}}, \\\\\n",
        "\\vec{v_T} \\\\\n",
        "\\end{array}\n",
        "\\right\\} = \n",
        "\\left\\{\n",
        "\\begin{array}{c}\n",
        "(-1, 0,...., 0, 1), \\\\\n",
        "(1, -1, 0,...., 0), \\\\\n",
        "(0, 1, -1,...., 0), \\\\\n",
        "\\vdots \\\\\n",
        "(0,...., 1, -1, 0), \\\\\n",
        "(0,...., 0, 1, -1) \\\\\n",
        "\\end{array}\n",
        "\\right\\}\n",
        "$$\n",
        "\n",
        "#### Define $U_t$.\n",
        "\n",
        "Define $U_t$ as the set of all possible subsets of $V^*$ such that each subset contains exactly $t$ elements, i.e.,\n",
        "\n",
        "$$\n",
        "U_t = \\{ S \\subsetneq V^* \\mid |S| = t \\}, \\quad t \\in \\{1, 2, \\dots, T\\}.\n",
        "$$\n"
      ],
      "id": "f80a7fc9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from functions import get_v_star\n",
        "\n",
        "def powerset(iterable, size=1):\n",
        "    \"powerset([1,2,3], 2) --> (1,2) (1,3) (2,3)\"\n",
        "    return [[i for i in item] for item in combinations(iterable, size)]\n",
        "  \n",
        "x = initial_schedule\n",
        "\n",
        "# Generate a matrix 'v_star' using the 'get_v_star' function\n",
        "v_star = get_v_star(T)\n",
        "\n",
        "# Generate all possible non-empty subsets (powerset) of the set {0, 1, 2, ..., t-1}\n",
        "# 'ids' will be a list of tuples, where each tuple is a subset of indices\n",
        "size = 2\n",
        "ids = powerset(range(T), size)\n",
        "len(ids)\n",
        "ids[:T]"
      ],
      "id": "e5668646",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define the neighborhood of $x$\n",
        "\n",
        "Define the neighborhood of $x$ as all vectors of the form $x + u_{tk}$ with $\\forall \\, u_{tk} \\in U_t$.\n"
      ],
      "id": "c60a785b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_neighborhood(x, v_star, ids, verbose=False):\n",
        "    x = np.array(x)\n",
        "    p = 50\n",
        "    if verbose:\n",
        "        print(f\"Printing every {p}th result\")\n",
        "    # Initialize the list 'neighborhood' to store the vectors in the neighborhood of 'x'\n",
        "    neighborhood = []\n",
        "    # Loop over all possible non-empty subsets of indices\n",
        "    for i in range(len(ids)):\n",
        "        # Initialize the vector 'neighbor' to store the sum of vectors in 'v_star' corresponding to the indices in 'ids[i]'\n",
        "        neighbor = np.zeros(len(x), dtype=int)\n",
        "        # Loop over all indices in 'ids[i]'\n",
        "        for j in range(len(ids[i])):\n",
        "            if verbose:\n",
        "                print(f\"v_star{[ids[i][j]]}: {v_star[ids[i][j]]}\")\n",
        "            # Add the vector in 'v_star' corresponding to the index 'ids[i][j]' to 'neighbor'\n",
        "            neighbor += v_star[ids[i][j]]\n",
        "        # Append the vector 'x' plus 'neighbor' to the list 'neighborhood'\n",
        "        x_n = x + neighbor\n",
        "        if i%p==0:\n",
        "            if verbose:\n",
        "                print(f\"x, x', delta:\\n{x},\\n{x_n},\\n{neighbor}\\n----------------- \")\n",
        "        neighborhood.append(x_n)\n",
        "    \n",
        "    # Convert the list 'neighborhood' into a NumPy array\n",
        "    neighborhood = np.array(neighborhood)\n",
        "    if verbose:\n",
        "        print(f\"Size of raw neighborhood: {len(neighborhood)}\")\n",
        "    # Create a mask for rows with negative values\n",
        "    mask = ~np.any(neighborhood < 0, axis=1)\n",
        "    # Filter out rows with negative values using the mask\n",
        "    if verbose:\n",
        "        print(f\"filtered out: {len(neighborhood)-mask.sum()} schedules with negative values.\")\n",
        "    filtered_neighborhood = neighborhood[mask]\n",
        "    if verbose:\n",
        "        print(f\"Size of filtered neighborhood: {len(filtered_neighborhood)}\")\n",
        "    return filtered_neighborhood\n",
        "\n",
        "# Example of function call:\n",
        "# This will generate the neighborhood of the vector 'x' using the vectors in 'v_star' and the indices in 'ids'\n",
        "test_nh = get_neighborhood(x, v_star, ids)\n",
        "print(f\"All neighborhoods with {size} patients switched:\\n x = {np.array(x)}: \\n {test_nh}\")"
      ],
      "id": "6a2d6ca1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Local search algorithm\n"
      ],
      "id": "3f959f0e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def local_search_predicted(x: List[int], v_star: np.ndarray, clf: xgb.XGBClassifier, size: int = 2) -> Tuple[np.ndarray, int]:\n",
        "    \"\"\"\n",
        "    Performs a local search around a given point in the feature space\n",
        "    and predicts the class label using an XGBClassifier model.\n",
        "\n",
        "    Args:\n",
        "        x (List[int]): The starting point for the local search, represented as a list of integers.\n",
        "        v_star (np.ndarray): The current best solution (e.g., a NumPy array representing a feature vector).\n",
        "        clf (XGBClassifier): An XGBoost Classifier model that will be used for prediction.\n",
        "        size (int, optional): The size of the neighborhood to explore around the starting point. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, int]: A tuple containing the best neighbor found (as a NumPy array)\n",
        "                                 and its predicted class label (as an integer).\n",
        "    \"\"\"\n",
        "    \n",
        "    # Outer loop for the number of patients to switch\n",
        "    max_restarts = size  # Or some other reasonable limit to prevent infinite loops when searching\n",
        "    restart_count = 0\n",
        "    x_star = x\n",
        "    t = 1\n",
        "    w = 0.1\n",
        "    while t < size and restart_count < max_restarts:\n",
        "        print(f'Running local search {t}')\n",
        "        ids_gen = powerset(range(T), t)\n",
        "        neighborhood = get_neighborhood(x_star, v_star, ids_gen)\n",
        "        print(f\"Switching {t} patient(s). Size of neighborhood: {len(list(ids_gen))}\")\n",
        "        found_better_solution = False\n",
        "        for neighbor in neighborhood:\n",
        "            objectives_list = [calculate_objective_serv_time_lookup(x, d, convolutions) for x in [x_star, neighbor]]\n",
        "            costs_list = [w * objectives[0] + (1 - w) * objectives[1] for objectives in objectives_list]\n",
        "            schedule_pairs = x_star + neighbor.tolist()\n",
        "            print(f\"Schedule pairs: {schedule_pairs}\")\n",
        "            print(f\"Costs: {costs_list}\")\n",
        "            rank = clf.predict([schedule_pairs])\n",
        "            ambiguousness = clf.predict_proba([schedule_pairs])\n",
        "            print(f\"Predicted rank: {rank}, ambiguousness: {ambiguousness}\")\n",
        "            if rank[0] == 1:\n",
        "                x_star = neighbor.tolist()\n",
        "                print(f\"Found better solution: {x_star}\")\n",
        "                found_better_solution = True\n",
        "                break\n",
        "        if found_better_solution:\n",
        "            t = 1\n",
        "            restart_count += 1\n",
        "        else:\n",
        "            t += 1\n",
        "    return x_star"
      ],
      "id": "b3ad191f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from functions import calculate_objective_serv_time_lookup\n",
        "\n",
        "# Define the path to the saved model\n",
        "model_path = \"models/classifier_large_instance.json\" # Make sure this path is correct\n",
        "\n",
        "# Initialize an XGBoost Classifier instance\n",
        "clf = xgb.XGBClassifier()\n",
        "\n",
        "# Load the model directly from the file path\n",
        "clf.load_model(model_path)\n",
        "\n",
        "intial_objectives = calculate_objective_serv_time_lookup(x, d, convolutions)\n",
        "initial_c_star = w * intial_objectives[0] + (1 - w) * intial_objectives[1]\n",
        "x_star = local_search_predicted(x, v_star, clf, size=T)\n",
        "final_objectives = calculate_objective_serv_time_lookup(x_star, d, convolutions)\n",
        "final_c_star = w * final_objectives[0] + (1 - w) * final_objectives[1]\n",
        "print(f\"\\nInitial schedule: {x}, with objective value: {initial_c_star}.\\nFinal schedule: {x_star}, with objective value: {final_c_star}.\")"
      ],
      "id": "e8cab87d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the local search algorithm\n"
      ],
      "id": "dd713010"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from functions import local_search\n",
        "# Computing optimal solution with real cost\n",
        "print(f\"Initial schedule: {x}\")\n",
        "test_x = local_search(x, d, convolutions, w, v_star, T, echo=True)"
      ],
      "id": "2402956c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Initial schedule: {x}\\nFinal schedule: {test_x[0]}\\nDifference: {test_x[0] - x}\\nObjective value: {test_x[1]}\")"
      ],
      "id": "cbbd48e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "\n",
        "Analyze your results in this section. Discuss whether your hypothesis was supported, what the results mean, and the implications for future work. Address any anomalies or unexpected findings, and consider the broader impact of your results.\n",
        "\n",
        "## Timeline\n",
        "\n",
        "Document the duration and key dates of the experiment. This helps in project management and reproducibility.\n",
        "\n",
        "## References\n",
        "\n",
        "Cite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.s"
      ],
      "id": "1a52d67d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}