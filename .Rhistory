result = minimize(
objective,
initial_guess,
method='SLSQP',
bounds=bounds,
constraints=constraints,
# options={'disp': False} # Set True for detailed optimizer output
)
# Check if optimization was successful
if not result.success:
print(f"Warning: Optimization failed! Message: {result.message}")
# Optionally print result object for more details: print(result)
return None # Indicate failure
# The optimized probabilities (P(1) to P(max_s))
optimized_probs = result.x
# --- Post-process: Correct potential floating point inaccuracies ---
# Ensure probabilities are non-negative and sum *exactly* to 1
optimized_probs[optimized_probs < 0] = 0 # Clamp small negatives to 0
current_sum = np.sum(optimized_probs)
if not np.isclose(current_sum, 1.0):
if current_sum > 0: # Avoid division by zero
optimized_probs /= current_sum # Normalize to sum to 1
else:
print("Warning: Optimization resulted in zero sum probabilities after clamping negatives.")
# Handle this case - maybe return uniform distribution or None
return None # Or return uniform: np.ones(max_s) / max_s
except Exception as e:
print(f"An error occurred during optimization: {e}")
return None
# --- Reorder the probabilities based on the index 'i' ---
# Split the probabilities P(1)...P(i) and P(i+1)...P(max_s)
# Note: Python slicing is exclusive of the end index, array indexing is 0-based.
# result.x[0] corresponds to P(1), result.x[i-1] to P(i).
# result.x[i] corresponds to P(i+1), result.x[max_s-1] to P(max_s).
first_part_probs = optimized_probs[:i]   # Probabilities P(1) to P(i)
second_part_probs = optimized_probs[i:]  # Probabilities P(i+1) to P(max_s)
# Sort the first part ascending, the second part descending
sorted_first_part = np.sort(first_part_probs)
sorted_second_part = np.sort(second_part_probs)[::-1] # [::-1] reverses
# --- Create final output array ---
# Array of size max_s + 1, initialized to zeros. Index 0 unused.
values = np.zeros(max_s + 1)
# Assign the sorted probabilities back into the correct slots (index 1 onwards)
values[1 : i + 1] = sorted_first_part      # Assign P(1)...P(i)
values[i + 1 : max_s + 1] = sorted_second_part # Assign P(i+1)...P(max_s)
# Final check on sum after potential normalization/sorting
if not np.isclose(np.sum(values[1:]), 1.0):
print(f"Warning: Final distribution sum is {np.sum(values[1:])}, not 1.0. Check logic.")
# Return the final array with the sorted probability distribution
return values
i = 5  # First 5 highest values in ascending order, rest in descending order
s = generate_weighted_list(max_s, l, i)
print(f"Average generated service time: {np.dot(np.arange(len(s)), s)}")
convolutions = compute_convolutions(s, N, q)
X = np.array(bailey_welch_schedule(T, d, N, s))
# Objective Function Calculation
LARGE_PENALTY = 1e10 # Penalty for infeasible solutions
def evaluate_objective(U_np, X_vec, v_star, convolutions, d, w):
"""
Target function: Evaluates objective for a single binary numpy array U.
Returns a float.
"""
# Input validation (same as before)
if not isinstance(U_np, np.ndarray):
raise TypeError("Input U must be a numpy array")
if U_np.ndim != 1:
raise ValueError("Input U must be 1-dimensional")
if U_np.shape[0] != v_star.shape[0]:
raise ValueError(f"Dimension mismatch: U length {U_np.shape[0]} != V* rows {v_star.shape[0]}.")
if X_vec.shape[0] != v_star.shape[1]:
raise ValueError("Dimension mismatch: X length must match V* columns.")
if not np.all((U_np == 0) | (U_np == 1)):
raise ValueError("Input U must be binary (0s and 1s).")
# Calculate Y based on selected rows of V_star
V_sum = np.sum(v_star[U_np == 1, :], axis=0)
Y = X_vec + V_sum
# Check feasibility and calculate objective
if np.all(Y >= 0):
ewt, esp = calculate_objective_serv_time_lookup(Y, d, convolutions)
objective_value = w * ewt + (1 - w) * esp
return objective_value
else:
# Infeasible solution
return LARGE_PENALTY
# --- HED Implementation ---
def hamming_distance(u1, u2):
"""Calculates Hamming distance between two binary numpy arrays."""
return np.sum(u1 != u2)
def generate_diverse_random_dictionary(T, m):
"""Generates the random dictionary A for HED."""
dictionary_A = np.zeros((m, T), dtype=int)
for i in range(m):
# Sample theta for density of 1s in this dictionary vector
theta = np.random.uniform(0, 1)
row = (np.random.rand(T) < theta).astype(int)
dictionary_A[i, :] = row
return dictionary_A
def embed_vector(U_np, dictionary_A):
"""Embeds a single binary vector U using HED."""
m = dictionary_A.shape[0]
embedding_phi = np.zeros(m, dtype=float) # Use float for GP
for i in range(m):
embedding_phi[i] = hamming_distance(U_np, dictionary_A[i, :])
return embedding_phi
def embed_batch(U_batch_np, dictionary_A):
"""Embeds a batch of binary vectors U."""
# Input U_batch_np is expected to be a NumPy array
m = dictionary_A.shape[0]
if U_batch_np.ndim == 1: # Handle single vector case
U_batch_np = U_batch_np.reshape(1, -1)
batch_size = U_batch_np.shape[0]
embeddings_np = np.zeros((batch_size, m), dtype=float) # Use float for GP
for j in range(batch_size):
embeddings_np[j, :] = embed_vector(U_batch_np[j, :], dictionary_A)
# Return NumPy array directly
return embeddings_np
# --- BO Helper Functions ---
def get_fitted_model(train_X_embedded_scaled, train_Y, m):
"""
Fits a GaussianProcessRegressor model to the SCALED embedded data.
Assumes train_Y contains negative objective values for maximization.
"""
if train_Y.ndim > 1 and train_Y.shape[1] == 1:
train_Y = train_Y.ravel() # sklearn GP expects 1D target array
# Define the kernel for the Gaussian Process
# Matern kernel is a common choice, nu=2.5 is smooth (twice differentiable)
# ConstantKernel handles the overall variance scaling
# WhiteKernel handles the observation noise
kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \
Matern(length_scale=np.ones(m), # Enable ARD, initialize length scales to 1
length_scale_bounds=(1e-2, 1e2),
nu=2.5) + \
WhiteKernel(noise_level=1e-10, # Small value for numerical stability
noise_level_bounds="fixed") # Bounds for noise optimization
# Instantiate the Gaussian Process Regressor
# alpha: Value added to the diagonal of the kernel matrix during fitting
#        for numerical stability (can also be seen as additional noise)
# n_restarts_optimizer: Restarts optimizer to find better hyperparameters
gp_model = GaussianProcessRegressor(
kernel=kernel,
alpha=1e-10, # Small value for numerical stability
n_restarts_optimizer=10, # More restarts -> better hyperparams but slower
random_state=42 # For reproducibility of optimizer restarts
)
# Fit the GP model
gp_model.fit(train_X_embedded_scaled, train_Y)
return gp_model
def expected_improvement(mu, sigma, f_best, xi=0.01):
"""
Computes the Expected Improvement acquisition function.
Assumes maximization (f_best is the current maximum observed value).
mu, sigma: Predicted mean and standard deviation (NumPy arrays).
f_best: Current best observed function value (scalar).
xi: Exploration-exploitation trade-off parameter.
"""
# Ensure sigma is positive and non-zero to avoid division errors
sigma = np.maximum(sigma, 1e-9)
Z = (mu - f_best - xi) / sigma
ei = (mu - f_best - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)
# Set EI to 0 where variance is negligible
ei[sigma <= 1e-9] = 0.0
return ei
# MODIFIED: Accepts the scaler and uses scikit-learn GP + EI
def optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, current_best_neg_f_val):
"""
Optimizes acquisition function (Expected Improvement) by sampling random
binary candidates, embedding, SCALING, predicting with GP, and calculating EI.
Selects the top q candidates based on EI.
Returns candidates as a numpy array (q x T).
"""
m = dictionary_A.shape[0]
# 1. Generate Random Binary Candidates
candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))
# Optional: Ensure unique candidates if needed (adds overhead)
# candidate_u_vectors_np = np.unique(candidate_u_vectors_np, axis=0)
# num_candidates = candidate_u_vectors_np.shape[0] # Update count
# 2. Embed the Candidates
embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)
# 3. Scale the Embedded Candidates
# Handle potential warning if scaler expects float64 (already float here)
# Use the *fitted* scaler from the training data
embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)
# 4. Predict Mean and Std Dev using the GP Model
mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)
# 5. Calculate Acquisition Function (Expected Improvement)
# current_best_neg_f_val is the maximum of the (negative) objectives seen so far
acq_values = expected_improvement(mu, std, current_best_neg_f_val, xi=0.01)
# 6. Select Top Candidates
# Use np.argsort to find indices that would sort the array (ascending)
# Select the last q indices for the highest EI values
# If q=1, np.argmax(acq_values) is simpler but argsort works generally
top_indices = np.argsort(acq_values)[-q:]
# Ensure indices are returned in descending order of acquisition value (optional but nice)
top_indices = top_indices[::-1]
return candidate_u_vectors_np[top_indices, :]
# --- BO Loop ---
# Parameters
N_INITIAL = 20
N_ITERATIONS = 20
BATCH_SIZE_q = 5
NUM_CANDIDATES_Acqf = T*1024 # Might need more for higher T
m = 128 # Dimension of the embedding space
# Store evaluated points (using NumPy arrays)
evaluated_U_np_list = [] # List to store evaluated U vectors (binary)
evaluated_f_vals = []    # List to store raw objective values (lower is better)
train_Y_list = []        # List to store NEGATED objective values for GP (higher is better)
# 1. Initialization
print(f"Generating {N_INITIAL} initial points...")
initial_candidates = []
while len(initial_candidates) < N_INITIAL:
U_init = np.random.randint(0, 2, size=T)
# Ensure unique initial points
is_duplicate = any(np.array_equal(U_init, u) for u in initial_candidates)
if not is_duplicate:
initial_candidates.append(U_init)
for U_init in initial_candidates:
f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)
neg_f_val = -f_val
evaluated_U_np_list.append(U_init)
evaluated_f_vals.append(f_val)
train_Y_list.append(neg_f_val)
# Convert lists to NumPy arrays for GP fitting
train_Y = np.array(train_Y_list).reshape(-1, 1) # Keep as column vector initially
best_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')
initial_best_obj_so_far_ei = best_obj_so_far
print(f"Initial best objective value: {best_obj_so_far}")
if not np.isfinite(best_obj_so_far):
print("Warning: Initial best objective is infinite, possibly all initial points were infeasible.")
# 2. BO Iterations
for iteration in range(N_ITERATIONS):
start_time = time.time()
print(f"\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---")
# a. Generate dictionary A for HED
current_dictionary_A = generate_diverse_random_dictionary(T, m)
# b. Embed ALL evaluated U vectors so far
if not evaluated_U_np_list:
print("Warning: No points evaluated yet. Skipping iteration.")
continue
evaluated_U_np_array = np.array(evaluated_U_np_list)
embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)
# c. Scale the embedded training data
scaler = MinMaxScaler()
# Fit scaler only if there's data
if embedded_train_X.shape[0] > 0:
# Fit and transform
embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)
else:
# Handle case with no data (shouldn't happen after init)
embedded_train_X_scaled = embedded_train_X # Will be empty
# Ensure train_Y is a NumPy array for fitting
train_Y_for_fit = np.array(train_Y_list) # Use the list directly
# d. Fit GP Model using SCALED data
print("Fitting GP model...")
if embedded_train_X_scaled.shape[0] > 0 and train_Y_for_fit.shape[0] == embedded_train_X_scaled.shape[0]:
gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)
print("GP model fitted.")
else:
print("Warning: Not enough data or data mismatch to fit GP model. Skipping iteration.")
continue # Skip if no data or mismatch
# e. Determine current best value for Acquisition Function
# We are maximizing the negative objective in the GP
current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size > 0 else -float('inf')
# Prevent potential issues if all points were infeasible (very large negative best_f)
if current_best_neg_f_val <= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):
print(f"Warning: Current best value ({current_best_neg_f_val:.2f}) is very low (likely from penalties). Acqf might behave unexpectedly.")
# f. Optimize Acquisition Function (Expected Improvement)
print("Optimizing acquisition function...")
next_U_candidates_np = optimize_acqf_discrete_via_embedding(
gp_model=gp_model,
scaler=scaler, # Pass the fitted scaler
dictionary_A=current_dictionary_A,
T=T,
q=BATCH_SIZE_q,
num_candidates=NUM_CANDIDATES_Acqf,
current_best_neg_f_val=current_best_neg_f_val
)
print(f"Selected {next_U_candidates_np.shape[0]} candidate(s).")
# g. Evaluate Objective for the selected candidate(s)
newly_evaluated_U = []
newly_evaluated_f = []
newly_evaluated_neg_f = []
for i in range(next_U_candidates_np.shape[0]):
next_U = next_U_candidates_np[i, :]
# Check if this candidate was already evaluated
# Use a tolerance for floating point comparisons if U were continuous
# For binary, exact comparison is fine
already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)
if already_evaluated:
print(f"  Candidate {i} was already evaluated. Skipping re-evaluation.")
# TODO: Optionally, could try to generate a *different* candidate here
#       e.g., by running optimize_acqf again excluding this one,
#       or sampling randomly near it. For now, just skip.
continue # Skip to next candidate
# Evaluate the objective
next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)
next_neg_f = -next_f
print(f"  Candidate {i}: Obj = {next_f:.4f}")
# Add to temporary lists for this iteration
newly_evaluated_U.append(next_U)
newly_evaluated_f.append(next_f)
newly_evaluated_neg_f.append(next_neg_f)
# Update overall best objective found
if next_f < best_obj_so_far:
best_obj_so_far = next_f
# h. Augment Dataset for next iteration
evaluated_U_np_list.extend(newly_evaluated_U)
evaluated_f_vals.extend(newly_evaluated_f)
train_Y_list.extend(newly_evaluated_neg_f) # Add negative values for next GP fit
# Convert train_Y_list back to array for potential use (though we rebuild it next iter)
train_Y = np.array(train_Y_list).reshape(-1, 1)
iter_time = time.time() - start_time
print(f"Best objective value found so far: {best_obj_so_far:.4f}")
print(f"Total points evaluated: {len(evaluated_f_vals)}")
print(f"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.")
# --- Results ---
print("\n--- Optimization Finished ---")
if not evaluated_f_vals:
print("No points were successfully evaluated.")
else:
# Find the best point among all evaluated points
final_best_idx_ei = np.argmin(evaluated_f_vals) # Index of minimum raw objective
final_best_U_ei = evaluated_U_np_list[final_best_idx_ei]
final_best_f_ei = evaluated_f_vals[final_best_idx_ei]
nr_evaluated_f_vals_ei = len(evaluated_f_vals) # Saved for reporting results
print(f"Total evaluations: {len(evaluated_f_vals)}")
print(f"Best Objective Value Found: {final_best_f_ei}")
# Ensure U is printed correctly if it's long
print(f"Best U vector Found: {final_best_U_ei}")
# print(f"Best U vector Found (Indices of 1s): {np.where(final_best_U_ei == 1)[0]}")
# Verification - Recalculate Y for the best U found
V_sum_best = np.sum(v_star[final_best_U_ei == 1, :], axis=0)
Y_best_ei = X + V_sum_best
is_feasible = np.all(Y_best_ei >= 0)
if is_feasible:
ewt, esp = calculate_objective_serv_time_lookup(Y_best_ei, d, convolutions)
recalculated_obj = w * ewt + (1 - w) * esp
else:
LARGE_PENALTY
print(f"\n--- Verification ---")
print(f"Is the best U feasible? {is_feasible}")
if is_feasible:
print(f"Resulting Y vector for best U: {Y_best_ei}")
print(f"Objective value (recalculated): {recalculated_obj:.4f}")
if not np.isclose(final_best_f_ei, recalculated_obj):
print(f"Warning: Stored best objective ({final_best_f_ei}) does not match recalculation ({recalculated_obj})!")
elif final_best_f < LARGE_PENALTY:
print(f"Warning: Best objective ({final_best_f_ei}) is not the penalty value, but feasibility check failed.")
print(f"Resulting Y vector (infeasible): {Y_best_ei}")
else:
print("Best solution found corresponds to an infeasible penalty value.")
# --- BO Helper Functions ---
# --- get_fitted_model function remains the same ---
def get_fitted_model(train_X_embedded_scaled, train_Y, m):
# ... (implementation is unchanged) ...
if train_Y.ndim > 1 and train_Y.shape[1] == 1: train_Y = train_Y.ravel()
kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \
Matern(length_scale=np.ones(m), length_scale_bounds=(1e-2, 1e2), nu=2.5) + \
WhiteKernel(noise_level=1e-10, # Small value for numerical stability
noise_level_bounds="fixed") # Bounds for noise optimization
gp_model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, n_restarts_optimizer=10, random_state=42)
gp_model.fit(train_X_embedded_scaled, train_Y)
return gp_model
def lower_confidence_bound(mu, sigma, kappa=2.576):
"""
Computes the Lower Confidence Bound (LCB) acquisition function.
Assumes maximization of this value guides the search (since mu is neg objective).
Higher LCB means lower predicted objective or lower penalty for uncertainty.
mu, sigma: Predicted mean and standard deviation (NumPy arrays).
kappa: Controls the balance between exploitation (high mu -> low original objective)
and exploration (low sigma).
"""
# Ensure sigma is non-negative
sigma = np.maximum(sigma, 0)
return mu - kappa * sigma # <<< Sign flipped from UCB
def optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, kappa):
"""
Optimizes LCB acquisition function by sampling random binary candidates,
embedding, SCALING, predicting with GP, and calculating LCB.
Selects the top q candidates based on LCB.
Returns candidates as a numpy array (q x T).
"""
m = dictionary_A.shape[0]
# 1. Generate Random Binary Candidates
candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))
# 2. Embed the Candidates
embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)
# 3. Scale the Embedded Candidates
embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)
# 4. Predict Mean and Std Dev using the GP Model
mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)
# 5. Calculate Acquisition Function (Lower Confidence Bound) <<< CHANGED HERE
acq_values = lower_confidence_bound(mu, std, kappa=kappa) # Use LCB
# 6. Select Top Candidates (based on highest LCB) <<< COMMENT UPDATED
# We maximize LCB = mu - kappa*sigma, where mu is neg_objective
top_indices = np.argsort(acq_values)[-q:]
top_indices = top_indices[::-1] # Ensure descending order of LCB
return candidate_u_vectors_np[top_indices, :]
# --- BO Loop ---
# Parameters
KAPPA = 2.576 # Exploration parameter for LCB. Adjust as needed.
N_INITIAL = 20
N_ITERATIONS = 20
BATCH_SIZE_q = 5
NUM_CANDIDATES_Acqf = T*1024 # Might need more for higher T
m = 128 # Dimension of the embedding space
# Store evaluated points (using NumPy arrays)
evaluated_U_np_list = [] # List to store evaluated U vectors (binary)
evaluated_f_vals = []    # List to store raw objective values (lower is better)
train_Y_list = []        # List to store NEGATED objective values for GP (higher is better)
# 1. Initialization
for U_init in initial_candidates:
f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)
neg_f_val = -f_val
evaluated_U_np_list.append(U_init)
evaluated_f_vals.append(f_val)
train_Y_list.append(neg_f_val)
# Convert lists to NumPy arrays for GP fitting
train_Y = np.array(train_Y_list).reshape(-1, 1) # Keep as column vector initially
best_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')
initial_best_obj_so_far_lcb = best_obj_so_far # Saved for reporting results
print(f"Initial best objective value: {best_obj_so_far}")
if not np.isfinite(best_obj_so_far):
print("Warning: Initial best objective is infinite, possibly all initial points were infeasible.")
# 2. BO Iterations
for iteration in range(N_ITERATIONS):
start_time = time.time()
print(f"\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---")
# a. Generate dictionary A (remains the same)
current_dictionary_A = generate_diverse_random_dictionary(T, m)
# b. Embed ALL evaluated U vectors (remains the same)
if not evaluated_U_np_list: continue
evaluated_U_np_array = np.array(evaluated_U_np_list)
embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)
# c. Scale the embedded training data (remains the same)
scaler = MinMaxScaler()
if embedded_train_X.shape[0] > 0: embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)
else: embedded_train_X_scaled = embedded_train_X
# Ensure train_Y is NumPy array
train_Y_for_fit = np.array(train_Y_list)
# d. Fit GP Model (remains the same)
print("Fitting GP model...")
if embedded_train_X_scaled.shape[0] > 0 and train_Y_for_fit.shape[0] == embedded_train_X_scaled.shape[0]:
gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)
print("GP model fitted.")
else:
print("Warning: Not enough data or data mismatch to fit GP model. Skipping iteration.")
continue
# e. Determine current best neg value (useful for tracking, not directly used in LCB calculation)
current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size > 0 else -float('inf')
if current_best_neg_f_val <= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):
print(f"Warning: Current best NEGATIVE objective value ({current_best_neg_f_val:.2f}) is very low (likely from penalties).")
# f. Optimize Acquisition Function (LCB) <<< MODIFIED CALL & COMMENT
print("Optimizing acquisition function (LCB)...") # Comment updated
next_U_candidates_np = optimize_acqf_discrete_via_embedding(
gp_model=gp_model,
scaler=scaler,
dictionary_A=current_dictionary_A,
T=T,
q=BATCH_SIZE_q,
num_candidates=NUM_CANDIDATES_Acqf,
kappa=KAPPA # Pass kappa
)
print(f"Selected {next_U_candidates_np.shape[0]} candidate(s).")
# g. Evaluate Objective (remains the same)
newly_evaluated_U = []; newly_evaluated_f = []; newly_evaluated_neg_f = []
for i in range(next_U_candidates_np.shape[0]):
next_U = next_U_candidates_np[i, :]
already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)
if already_evaluated: print(f"  Candidate {i} was already evaluated. Skipping."); continue
next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)
next_neg_f = -next_f
print(f"  Candidate {i}: Obj = {next_f:.4f}")
newly_evaluated_U.append(next_U); newly_evaluated_f.append(next_f); newly_evaluated_neg_f.append(next_neg_f)
if next_f < best_obj_so_far: best_obj_so_far = next_f
# h. Augment Dataset (remains the same)
evaluated_U_np_list.extend(newly_evaluated_U); evaluated_f_vals.extend(newly_evaluated_f); train_Y_list.extend(newly_evaluated_neg_f)
train_Y = np.array(train_Y_list).reshape(-1, 1)
iter_time = time.time() - start_time
print(f"Best objective value found so far: {best_obj_so_far:.4f}")
print(f"Total points evaluated: {len(evaluated_f_vals)}")
print(f"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.")
# --- Results ---
print("\n--- Optimization Finished ---")
if not evaluated_f_vals: print("No points were successfully evaluated.")
else:
final_best_idx_lcb = np.argmin(evaluated_f_vals)
final_best_U_lcb = evaluated_U_np_list[final_best_idx_lcb]
final_best_f_lcb = evaluated_f_vals[final_best_idx_lcb]
nr_evaluated_f_vals_lcb = len(evaluated_f_vals) # Saved for reporting results
print(f"Total evaluations: {nr_evaluated_f_vals_lcb}")
print(f"Best Objective Value Found: {final_best_f_lcb}")
print(f"Best U vector Found: {final_best_U_lcb}")
# Verification
V_sum_best = np.sum(v_star[final_best_U_lcb == 1, :], axis=0)
Y_best_lcb = X + V_sum_best
is_feasible = np.all(Y_best_lcb >= 0)
recalculated_obj = LARGE_PENALTY
if is_feasible:
ewt, esp = calculate_objective_serv_time_lookup(Y_best_lcb, d, convolutions)
recalculated_obj = w * ewt + (1 - w) * esp
print(f"\n--- Verification ---")
print(f"Is the best U feasible? {is_feasible}")
if is_feasible:
print(f"Resulting Y vector for best U: {Y_best_lcb}")
print(f"Objective value (recalculated): {recalculated_obj:.4f}")
if not np.isclose(final_best_f_lcb, recalculated_obj): print(f"Warning: Stored best objective ({final_best_f:.4f}) does not match recalculation ({recalculated_obj:.4f})!")
elif final_best_f_lcb < LARGE_PENALTY: print(f"Warning: Best objective ({final_best_f_lcb:.4f}) is not the penalty value, but feasibility check failed."); print(f"Resulting Y vector (infeasible): {Y_best_lcb}")
else: print("Best solution found corresponds to an infeasible penalty value.")
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
