---
title: "Combinatorial Bayesian Optimization for a Scheduling Problem"
author: "Based on Experiment by Witek ten Hove"
date: "2025-05-05"
format:
  html:
    toc: true
    code-fold: true
---

## Objective

This experiment aims to optimize a complex scheduling problem using Bayesian Optimization (BO). The schedule is represented by a high-dimensional vector subject to constraints, and the objective function balances conflicting criteria (e.g., waiting time and service provider productivity). Specifically, we explore the effectiveness of a BO approach tailored for high-dimensional combinatorial spaces, leveraging Hamming Embedding via Dictionaries (HED) as proposed by Deshwal et al. (2023), comparing different acquisition functions.

## Background

We address a scheduling problem where a schedule is defined by a vector $x=(x_{0},x_{1},...,x_{T-1})^{T}$. Each component $x_{j}$ represents a non-negative integer allocation (e.g., number of patients) to time slot $j$. The total allocation must sum to a fixed constant $N$: $\sum_{j=0}^{T-1}x_{j}=N$. The set of valid schedules is denoted by $\mathcal{F}=\{z\in\mathbb{Z}_{\ge0}^{T}|\sum_{j=0}^{T-1}z_{j}=N, z_{j}\ge0~\forall j\}$.

Optimization within this space often involves local search. A neighborhood structure $\mathcal{N}(x)$ around a schedule $x$ is defined using perturbations $r(U)$. These perturbations are generated by selecting a subset of $T$ basis change vectors $v_i$ using a binary selection vector $U=(u_{0},...,u_{T-1}) \in \{0,1\}^{T}$, where $r(U) = \sum_{i=0}^{T-1}u_{i}v_{i}$. Each $v_i$ represents an elementary shift between slots (e.g., $v_1=(1,-1,0,...,0)$ shifts one unit from slot 1 to slot 0) and sums to zero, ensuring that $x' = x + r(U)$ maintains the total allocation $N$. The neighborhood $\mathcal{N}(x)$ contains all distinct, feasible schedules $x'$ reachable by applying a non-zero perturbation ($r(U) \ne 0$, excluding $U=0$ and $U=1$). The size of the neighborhood is bounded by $|\mathcal{N}(x)|\le2^{T}-2$.

The goal is to minimize an objective function $C(x)=w\cdot EWT(x)+(1-w)\cdot ESP(x)$, where $EWT$ might represent Expected Waiting Time and $ESP$ Expected Service Provider time, weighted by $w \in [0,1]$. The parameters influencing $C(x)$ include the schedule $x$, total allocation $N$, number of slots $T$, slot duration $d$, service time distribution $s$, and no-show probability $q$.

Due to the high dimensionality ($T$) and the potentially expensive evaluation of $C(x)$, standard local search or exhaustive methods are infeasible. Bayesian Optimization (BO) is a suitable framework for optimizing such expensive black-box functions. However, applying BO directly to high-dimensional combinatorial spaces like the space of selection vectors $U \in \{0,1\}^T$ presents challenges.

This experiment adopts the Hamming Embedding via Dictionaries (HED) approach from Deshwal et al. (2023). HED embeds the high-dimensional binary vector $U$ into a lower-dimensional continuous space using Hamming distances to a set of 'dictionary' vectors. A Gaussian Process (GP) surrogate model is then built on this embedded space, allowing standard BO techniques (like Expected Improvement or Lower Confidence Bound acquisition functions) to be applied more effectively.

## Hypothesis

Using Bayesian Optimization with Hamming Embedding via Dictionaries (HED) will efficiently identify near-optimal perturbation selection vectors $U$ (leading to improved schedules $x' = x + r(U)$) for the defined scheduling problem. Comparing different acquisition functions within this framework—specifically Expected Improvement (EI), Lower Confidence Bound (LCB) with fixed exploration parameter ($\kappa$), and LCB with dynamically increasing $\kappa$—will reveal differences in convergence speed and the quality of the final solution found within a fixed budget of function evaluations. We expect LCB variants, particularly the adaptive one, might explore the complex space more effectively than EI.

## Methodology

### Tools and Materials

-   **Programming Language:** Python 3
-   **Core Libraries:**
    -   NumPy: For numerical operations and array manipulation.
    -   SciPy: For optimization (`minimize`) and statistics (`norm`).
    -   Scikit-learn: For Gaussian Process Regression (`GaussianProcessRegressor`, `Matern`, `ConstantKernel`, `WhiteKernel`), data scaling (`MinMaxScaler`), and handling warnings.
-   **Custom Functions:**
    -   `bailey_welch_schedule`, `get_v_star`, `compute_convolutions`: Functions assumed to be available for calculating components of the objective function (details not provided in the source document).
    -   `generate_weighted_list`: Creates a service time probability distribution.
    -   `calculate_objective_serv_time_lookup`: Assumed function to calculate EWT and ESP based on a schedule Y, duration d, and precomputed convolutions.
    -   `evaluate_objective`: Calculates the objective function $C(x)$ for a given perturbation vector $U$.
    -   `hamming_distance`, `generate_diverse_random_dictionary`, `embed_vector`, `embed_batch`: Implement the HED embedding based on Deshwal et al. (2023).
    -   `get_fitted_model`: Fits the GP surrogate model.
    -   `expected_improvement`, `lower_confidence_bound`: Acquisition functions.
    -   `optimize_acqf_discrete_via_embedding`: Optimizes the acquisition function over the discrete space of $U$ vectors using the embedding.
-   **Dataset:** The initial schedule $X$ is provided as fixed data. Objective function values are generated dynamically during the BO process.

### Experimental Design

The experiment employs a standard Bayesian Optimization loop adapted for the combinatorial space of perturbation selection vectors $U \in \{0,1\}^T$ using the HED methodology.

1.  **Initialization:** A set of `N_INITIAL` unique, randomly generated binary vectors $U$ are evaluated using `evaluate_objective`.
2.  **Iteration Loop (N_ITERATIONS):**
    -   **Dictionary Generation:** A new 'diverse random' dictionary `A` of size `m x T` is generated (Alg. 1, Deshwal et al.).
    -   **Embedding:** All previously evaluated $U$ vectors are embedded into an `m`-dimensional space using Hamming distances to the dictionary `A`.
    -   **Scaling:** The embedded vectors are scaled (e.g., using `MinMaxScaler`).
    -   **GP Model Fitting:** A Gaussian Process Regressor with a Matérn kernel (and ARD) is fitted to the scaled embedded vectors and their corresponding (negated) objective function values.
    -   **Acquisition Function Optimization:** The chosen acquisition function (EI or LCB) is optimized over the space of possible $U$ vectors. This involves generating `NUM_CANDIDATES_Acqf` random candidate $U$ vectors, embedding them, scaling them, predicting their mean and standard deviation with the GP, calculating the acquisition function value, and selecting the top `BATCH_SIZE_q` candidates with the highest acquisition values.
    -   **Evaluation:** The selected candidate $U$ vectors (if not already evaluated) are evaluated using `evaluate_objective`.
    -   **Augmentation:** The newly evaluated points $(U, C(x+r(U)))$ are added to the dataset.
    -   **Kappa Update (for LCB-IK):** If an improvement in the best objective value is found, the `kappa` parameter for LCB is increased by `KAPPA_INCREASE_FACTOR`.
3.  **Termination:** The loop runs for a fixed number of iterations (`N_ITERATIONS`).
4.  **Comparison:** Three separate runs are conducted, differing only in the acquisition function used:
    -   Expected Improvement (EI)
    -   Lower Confidence Bound (LCB) with fixed `kappa`
    -   Lower Confidence Bound (LCB) with initial `kappa` dynamically increased upon finding improvements (LCB-IK).

### Variables

-   **Independent Variables:**
    -   Acquisition Function Choice: EI, LCB (fixed $\kappa$), LCB-IK (increasing $\kappa$).
    -   Binary Selection Vector ($U \in \{0,1\}^T$): The primary variable being optimized.
    -   BO Hyperparameters:
        -   `N_INITIAL`: Number of initial random samples (20).
        -   `N_ITERATIONS`: Number of BO iterations (20).
        -   `BATCH_SIZE_q`: Number of points selected per iteration (5).
        -   `NUM_CANDIDATES_Acqf`: Number of random candidates sampled for acquisition function optimization ($T \times 1024$).
        -   `m`: Dimension of the HED embedding (64).
        -   `kappa` (for LCB): Exploration-exploitation trade-off parameter (fixed at 2.576 or starting at 3.75 and increasing by 1.3).
-   **Dependent Variables:**
    -   Objective Function Value ($C(x+r(U))$): The value returned by `evaluate_objective` for a given $U$.
    -   Best Objective Value Found: The minimum objective value observed across all evaluations up to a given iteration.
    -   Computation Time: Time taken per BO iteration.
    -   Final Best $U$ Vector: The binary vector corresponding to the best objective value found.
    -   Final Best Schedule ($Y_{best}$): The resulting schedule $X + r(U_{best})$.

### Data Collection

Data consists of pairs $(U, C(x+r(U)))$, where $U$ is a binary selection vector and $C(x+r(U))$ is the corresponding objective function value. Initial data points (`N_INITIAL`) are generated using random $U$ vectors. Subsequent data points are generated iteratively by the BO loop, selecting $U$ vectors that maximize the chosen acquisition function based on the GP model learned from previous evaluations. The `evaluate_objective` function serves as the data generation oracle. Feasibility ($x+r(U) \ge 0$) is checked within `evaluate_objective`; infeasible solutions are assigned a `LARGE_PENALTY`.

### Sample Size and Selection

-   **Sample Size:** Each experimental run evaluates a total of $N_{eval} = N_{INITIAL} + N_{ITERATIONS} \times BATCH_{SIZE}_q = 20 + 20 \times 5 = 120$ points (approximately, as duplicates might be skipped).
-   **Sample Selection:**
    -   Initial samples (`N_INITIAL`) are chosen randomly and uniquely from the $\{0,1\}^T$ space.
    -   Subsequent samples (`BATCH_SIZE_q` per iteration) are selected based on maximizing the acquisition function (EI or LCB). This selection process is guided by the GP surrogate model, which predicts the objective function and its uncertainty across the embedded space. The acquisition function balances exploiting promising regions (low predicted objective) and exploring uncertain regions (high variance), aiming for sample efficiency. The selection happens over `NUM_CANDIDATES_Acqf` randomly generated $U$ vectors within the `optimize_acqf_discrete_via_embedding` function.

### Experimental Procedure

The core procedure involves setting up the problem parameters, defining the objective and helper functions, and running the Bayesian Optimization loop for each of the three acquisition function variants.

**1. Setup and Problem Definition:**

Define constants (`N`, `T`, `d`, `max_s`, `q`, `w`, `l`), load initial schedule `X`, generate `v_star` matrix, and create the service time distribution `s`.

``` python
# Core Libraries
import numpy as np
import time
import warnings
from scipy.optimize import minimize
from typing import List, Dict, Tuple, Callable, Optional, Union, Any, Iterable

# Scikit-learn for GP, Scaling, and potentially acquisition functions
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel
from sklearn.preprocessing import MinMaxScaler
from sklearn.exceptions import ConvergenceWarning

# SciPy for statistics (needed for Expected Improvement calculation)
from scipy.stats import norm

# Assume these functions are defined elsewhere or provided
# from functions import bailey_welch_schedule, get_v_star, compute_convolutions, calculate_objective_serv_time_lookup

# --- Mock Function Definitions (Replace with actual implementations) ---
def get_v_star(T):
    """Generates the T x T basis change matrix V*."""
    # Placeholder implementation - use the actual logic
    v_star = np.zeros((T, T))
    if T > 0:
        v_star[0, 0] = -1
        v_star[0, T-1] = 1
    if T > 1:
        v_star[1, 1] = -1
        v_star[1, 0] = 1
    for i in range(2, T):
        v_star[i, i] = -1
        v_star[i, i-1] = 1
    return v_star

def compute_convolutions(s, N, q):
    """Computes convolutions needed for objective calculation."""
    # Placeholder - use actual logic
    print("Warning: Using mock compute_convolutions.")
    return {"mock_data": np.random.rand(N + 1)}

def calculate_objective_serv_time_lookup(Y, d, convolutions):
    """Calculates EWT and ESP based on schedule Y."""
    # Placeholder - use actual logic
    # Returns mock EWT, ESP values
    print(f"Warning: Using mock calculate_objective_serv_time_lookup for Y={Y}.")
    # Simulate some dependency on Y to avoid constant output
    mock_ewt = np.sum(Y) * 0.5 + np.random.rand() * 5
    mock_esp = (np.max(Y) if Y.size > 0 else 0) * 2.0 + np.random.rand() * 10
    return mock_ewt, mock_esp
# --- End Mock Function Definitions ---


# Filter warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings("ignore", category=ConvergenceWarning) # GP fitting might not converge

# Problem Definition
# Fixed Data (Use your actual data from the PDF for each run)
# Example from EI run:
X = np.array([2, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 4])
# Example from LCB run:
# X = np.array([2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 4])
# Example from LCB-IK run:
# X = np.array([2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 4])


N = int(np.sum(X)) # Total number of patients/tasks
T = X.shape[0]   # Dimension of the binary vector U (number of time slots)
d = 5            # Length of each interval
max_s = 20       # Maximum service time
q = 0.20         # Probability of a scheduled patient not showing up
w = 0.1          # Weight for the waiting time in objective function
l = 10           # Target average service time

v_star = get_v_star(T) # Get the V matrix (T x T)

# Create service time distribution
def generate_weighted_list(max_s: int, l: float, i: int) -> Optional[np.ndarray]:
    """
    Generates a service time probability distribution using optimization.

    This function creates a discrete probability distribution over max_s possible
    service times (from 1 to max_s). It uses optimization (SLSQP) to find a
    distribution whose weighted average service time is as close as possible
    to a target value 'l', subject to the constraint that the probabilities
    sum to 1 and each probability is between 0 and 1.

    After finding the distribution, it sorts the probabilities: the first 'i'
    probabilities (corresponding to service times 1 to i) are sorted in
    ascending order, and the remaining probabilities (service times i+1 to max_s)
    are sorted in descending order.

    Note: Requires NumPy and SciPy libraries (specifically scipy.optimize.minimize).

    Args:
        max_s (int): Maximum service time parameter (number of probability bins).
                     Must be a positive integer.
        l (float): The target weighted average service time for the distribution.
                   Must be between 1 and max_s, inclusive.
        i (int): The index determining the sorting split point. Probabilities
                 for service times 1 to 'i' are sorted ascendingly, and
                 probabilities for service times 'i+1' to 'max_s' are sorted
                 descendingly. Must be between 1 and max_s-1 for meaningful sorting.

    Returns:
        numpy.ndarray: An array of size max_s+1. The first element (index 0) is 0.
                       Elements from index 1 to max_s represent the calculated
                       and sorted probability distribution, summing to 1.
                       Returns None if optimization fails or inputs are invalid.
    """
    # Input Validation
    if not isinstance(max_s, int) or max_s <= 0:
        print(f"Error: max_s must be a positive integer, but got {max_s}")
        return None
    if not isinstance(l, (int, float)) or not (1 <= l <= max_s):
        print(f"Error: Target average 'l' ({l}) must be between 1 and max_s ({max_s}).")
        return None
    if not isinstance(i, int) or not (0 < i < max_s):
        print(f"Error: Sorting index 'i' ({i}) must be between 1 and max_s-1 ({max_s-1}).")
        # If clamping is desired instead of error:
        # print(f"Warning: Index 'i' ({i}) is outside the valid range (1 to max_s-1). Clamping.")
        # i = max(1, min(i, max_s - 1))
        return None # Strict check based on docstring requirement

    # Inner helper function for optimization
    def objective(x: np.ndarray) -> float:
        """Objective function: Squared difference between weighted average and target l."""
        # x represents probabilities P(1) to P(max_s)
        service_times = np.arange(1, max_s + 1)
        weighted_avg = np.dot(service_times, x) # Equivalent to sum(k*P(k) for k=1..max_s)
        return (weighted_avg - l) ** 2

    # Constraints for optimization
    # Constraint 1: The sum of the probabilities must be 1
    constraints = ({
        'type': 'eq',
        'fun': lambda x: np.sum(x) - 1.0 # Ensure float comparison
    })

    # Bounds: Each probability value x[k] must be between 0 and 1
    # Creates a list of max_s tuples, e.g., [(0, 1), (0, 1), ..., (0, 1)]
    bounds = [(0, 1)] * max_s

    # Initial guess: Use Dirichlet distribution to get a random distribution that sums to 1.
    # Provides a starting point for the optimizer. np.ones(max_s) gives equal weights initially.
    initial_guess = np.random.dirichlet(np.ones(max_s))

    # Perform Optimization
    try:
        result = minimize(
            objective,
            initial_guess,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints,
            options={'disp': False} # Set True for detailed optimizer output
        )

        # Check if optimization was successful
        if not result.success:
            print(f"Warning: Optimization failed! Message: {result.message}")
            # Optionally print result object for more details: print(result)
            return None # Indicate failure

        # The optimized probabilities (P(1) to P(max_s))
        optimized_probs = result.x

        # Post-process: Correct potential floating point inaccuracies
        # Ensure probabilities are non-negative and sum *exactly* to 1
        optimized_probs[optimized_probs < 0] = 0 # Clamp small negatives to 0
        current_sum = np.sum(optimized_probs)

        if not np.isclose(current_sum, 1.0):
            if current_sum > 0: # Avoid division by zero
                 optimized_probs /= current_sum # Normalize to sum to 1
            else:
                 print("Warning: Optimization resulted in zero sum probabilities.")
                 # Handle this case maybe return uniform distribution or None
                 return None # Or return uniform: np.ones(max_s) / max_s

    except Exception as e:
        print(f"An error occurred during optimization: {e}")
        return None

    # Reorder the probabilities based on the index 'i'
    # Split the probabilities P(1)...P(i) and P(i+1)...P(max_s)
    # Note: Python slicing is exclusive of the end index, array indexing is 0-based.
    # result.x[0] corresponds to P(1), result.x[i-1] to P(i).
    # result.x[i] corresponds to P(i+1), result.x[max_s-1] to P(max_s).

    # Probabilities P(1) to P(i)
    first_part_probs = optimized_probs[:i]
    # Probabilities P(i+1) to P(max_s)
    second_part_probs = optimized_probs[i:]

    # Sort the first part ascending, the second part descending
    sorted_first_part = np.sort(first_part_probs)
    sorted_second_part = np.sort(second_part_probs)[::-1] # [::-1] reverses array

    # Create final output array
    # Array of size max_s + 1, initialized to zeros. Index 0 unused.
    values = np.zeros(max_s + 1)

    # Assign the sorted probabilities back into the correct slots (index 1 onwards)
    values[1:i+1] = sorted_first_part      # Assign P(1)...P(i)
    values[i+1:max_s + 1] = sorted_second_part # Assign P(i+1)...P(max_s)

    # Final check on sum after potential normalization/sorting
    if not np.isclose(np.sum(values[1:]), 1.0):
         print(f"Warning: Final distribution sum is {np.sum(values[1:])}, not 1.0.")

    # Return the final array with the sorted probability distribution
    return values

i = 5 # First 5 highest values in ascending order, rest in descending order
s = generate_weighted_list(max_s, l, i)
if s is None:
    raise ValueError("Failed to generate service time distribution.")

convolutions = compute_convolutions(s, N, q)

# Objective Function Calculation
LARGE_PENALTY = 1e10 # Penalty for infeasible solutions

def evaluate_objective(U_np, X_vec, v_star, convolutions, d, w):
    """
    Target function: Evaluates objective for a single binary numpy array U.
    Returns a float. Checks feasibility (Y >= 0).
    """
    # Input validation
    if not isinstance(U_np, np.ndarray):
        raise TypeError("Input U must be a numpy array")
    if U_np.ndim != 1:
        raise ValueError("Input U must be 1-dimensional")
    if U_np.shape[0] != v_star.shape[0]: # T should match rows of v_star
        raise ValueError(f"Dimension mismatch: U length {U_np.shape[0]} != V* rows {v_star.shape[0]}")
    if X_vec.shape[0] != v_star.shape[1]: # T should match columns of v_star
        raise ValueError(f"Dimension mismatch: X length {X_vec.shape[0]} must match V* columns {v_star.shape[1]}.")
    if not np.all((U_np == 0) | (U_np == 1)):
        raise ValueError("Input U must be binary (0s and 1s).")

    # Calculate perturbation r(U) = sum(u_i * v_i)
    # This is equivalent to summing rows of v_star where U_np is 1
    V_sum = np.sum(v_star[U_np == 1, :], axis=0)

    # Calculate the potential new schedule Y = X + r(U)
    Y = X_vec + V_sum

    # Check feasibility (all elements of Y must be non-negative)
    if np.all(Y >= 0):
        # If feasible, calculate the actual objective
        try:
            # Ensure Y is integer type if required by the objective function
            Y_int = Y.astype(int)
            ewt, esp = calculate_objective_serv_time_lookup(Y_int, d, convolutions)
            objective_value = w * ewt + (1 - w) * esp
            # print(f"  Feasible U: {U_np}, Y: {Y_int}, EWT: {ewt:.4f}, ESP: {esp:.4f}, Obj: {objective_value:.4f}") # Debug
            return objective_value
        except Exception as e:
            print(f"Error during objective calculation for feasible Y={Y}: {e}")
            return LARGE_PENALTY # Penalize if calculation fails unexpectedly
    else:
        # If infeasible, return a large penalty value
        # print(f"  Infeasible U: {U_np}, Y: {Y}") # Debug
        return LARGE_PENALTY
```

**2. HED Implementation (Based on Deshwal et al., 2023):**

Define functions for Hamming distance, generating the diverse random dictionary, and embedding vectors.

``` python
# HED Implementation (Deshwal et al., 2023)
def hamming_distance(u1, u2):
    """Calculates Hamming distance between two binary numpy arrays."""
    return np.sum(u1 != u2)

def generate_diverse_random_dictionary(T, m):
    """
    Generates the random dictionary A for HED using diverse sparsity.
    (Based on Algorithm 1 / Appendix G in Deshwal et al., 2023)
    """
    dictionary_A = np.zeros((m, T), dtype=int)
    for i in range(m):
        # Sample theta for density of 1s in this dictionary vector
        theta = np.random.uniform(0, 1)
        # Generate row based on theta
        row = (np.random.rand(T) < theta).astype(int)
        dictionary_A[i, :] = row
    return dictionary_A

def embed_vector(U_np, dictionary_A):
    """Embeds a single binary vector U using HED."""
    m = dictionary_A.shape[0]
    embedding_phi = np.zeros(m, dtype=float) # Use float for GP input
    for i in range(m):
        embedding_phi[i] = hamming_distance(U_np, dictionary_A[i, :])
    return embedding_phi

def embed_batch(U_batch_np, dictionary_A):
    """Embeds a batch of binary vectors U."""
    # Input U_batch_np is expected to be a NumPy array (n_samples x T)
    m = dictionary_A.shape[0]
    if U_batch_np.ndim == 1: # Handle single vector case
        U_batch_np = U_batch_np.reshape(1, -1)

    batch_size = U_batch_np.shape[0]
    embeddings_np = np.zeros((batch_size, m), dtype=float) # Use float for GP

    for j in range(batch_size):
        embeddings_np[j, :] = embed_vector(U_batch_np[j, :], dictionary_A)

    # Return NumPy array directly
    return embeddings_np
```

**3. BO Helper Functions:**

Define functions for fitting the GP model and calculating acquisition functions (EI and LCB).

``` python
# BO Helper Functions
def get_fitted_model(train_X_embedded_scaled, train_Y, m):
    """
    Fits a Gaussian Process Regressor model to the SCALED embedded data.
    Assumes train_Y contains negative objective values (for maximization).
    'm' is the embedding dimension.
    """
    if train_Y.ndim > 1 and train_Y.shape[1] == 1:
        train_Y = train_Y.ravel() # sklearn GP expects 1D target array

    if train_X_embedded_scaled.shape[0] == 0 or train_Y.shape[0] == 0:
         print("Warning: Cannot fit GP model with no data.")
         return None
    if train_X_embedded_scaled.shape[0] != train_Y.shape[0]:
        print(f"Warning: Mismatch between train_X ({train_X_embedded_scaled.shape[0]}) and train_Y ({train_Y.shape[0]}) samples.")
        return None
    if train_X_embedded_scaled.shape[1] != m:
        print(f"Warning: Mismatch between train_X columns ({train_X_embedded_scaled.shape[1]}) and embedding dim m ({m}).")
        # Adjust m if possible, or raise error depending on desired behavior
        # m = train_X_embedded_scaled.shape[1] # Example: Adjust m
        # return None # Example: Fail


    # Define the kernel for the Gaussian Process
    # Matern kernel is a common choice, nu=2.5 is smooth (twice differentiable)
    # ConstantKernel handles the overall variance scaling
    # WhiteKernel handles the observation noise
    kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \
             Matern(length_scale=np.ones(m), # Enable ARD, initialize length scales to 1
                    length_scale_bounds=(1e-2, 1e2),
                    nu=2.5) + \
             WhiteKernel(noise_level=1e-4, # Initial guess for noise
                         noise_level_bounds=(1e-6, 1e1)) # Bounds for noise level

    # Instantiate the Gaussian Process Regressor
    # alpha: Value added to the diagonal of the kernel matrix during fitting
    #        for numerical stability (can also be seen as additional noise)
    # n_restarts_optimizer: Restarts optimizer to find better hyperparameters
    gp_model = GaussianProcessRegressor(
        kernel=kernel,
        alpha=1e-10, # Small value for numerical stability
        n_restarts_optimizer=10, # More restarts -> better hyperparams but slower
        random_state=42 # For reproducibility of optimizer restarts
    )

    # Fit the GP model
    try:
        gp_model.fit(train_X_embedded_scaled, train_Y)
        # print("GP model fitted successfully.") # Debug
        # print(f"  Log-marginal-likelihood: {gp_model.log_marginal_likelihood_value_:.3f}") # Debug
        # print(f"  Kernel parameters: {gp_model.kernel_}") # Debug
    except Exception as e:
        print(f"Error fitting GP model: {e}")
        print(f"  Train X shape: {train_X_embedded_scaled.shape}")
        print(f"  Train Y shape: {train_Y.shape}")
        return None # Return None if fitting fails

    return gp_model

# --- Acquisition Functions ---

def expected_improvement(mu, sigma, f_best, xi=0.01):
    """
    Computes the Expected Improvement acquisition function.
    Assumes maximization (f_best is the current maximum observed NEGATIVE value).

    Args:
        mu, sigma: Predicted mean and standard deviation (NumPy arrays).
        f_best: Current best observed function value (scalar, max of negative objectives).
        xi: Exploration-exploitation trade-off parameter.

    Returns:
        ei: Expected improvement values (NumPy array).
    """
    # Ensure sigma is positive and non-zero to avoid division errors/warnings
    sigma = np.maximum(sigma, 1e-9)

    Z = (mu - f_best - xi) / sigma

    ei = (mu - f_best - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)

    # Set EI to 0 where variance is negligible (or where sigma was clamped)
    ei[sigma <= 1e-9] = 0.0

    return ei

def lower_confidence_bound(mu, sigma, kappa=2.576):
    """
    Computes the Lower Confidence Bound (LCB) acquisition function.
    Assumes GP model predicts NEGATIVE objective values (maximization target).
    We want to MAXIMIZE LCB = mu - kappa * sigma.
    This corresponds to minimizing the original objective:
    min (objective) <=> max (-objective)
    High mu (less negative) is good. Low sigma (low uncertainty) is preferred.
    LCB balances predicted performance (mu) and uncertainty (sigma).

    Args:
        mu, sigma: Predicted mean and standard deviation (NumPy arrays).
        kappa: Controls the balance between exploitation (high mu -> low original obj)
               and exploration (low sigma). Higher kappa encourages exploration more.

    Returns:
        lcb: Lower Confidence Bound values (NumPy array).
    """
    # Ensure sigma is non-negative
    sigma = np.maximum(sigma, 0)
    lcb = mu - kappa * sigma # Maximize this value
    return lcb


# --- Acquisition Function Optimization ---

def optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, acquisition_func, current_best_neg_f_val=None, kappa=None, xi=None):
    """
    Optimizes the specified acquisition function (EI or LCB) by sampling random
    binary candidates, embedding, SCALING, predicting with GP, and calculating acqf values.
    Selects the top q candidates based on the acquisition function.

    Args:
        gp_model: The fitted Gaussian Process model.
        scaler: The fitted scaler (e.g., MinMaxScaler).
        dictionary_A: The current dictionary used for embedding.
        T: Dimension of the binary space.
        q: Number of top candidates to return (batch size).
        num_candidates: Number of random candidates to generate and evaluate.
        acquisition_func: String identifier ('EI' or 'LCB').
        current_best_neg_f_val (float, optional): Max negative objective value seen so far. Required for EI.
        kappa (float, optional): Kappa value for LCB. Required for LCB.
        xi (float, optional): Xi value for EI. Required for EI.

    Returns:
        numpy.ndarray: Top q candidate U vectors as a numpy array (q x T).
                       Returns empty array if inputs are invalid or process fails.
    """
    if gp_model is None or scaler is None:
        print("Error: GP model or scaler is not provided.")
        return np.empty((0, T), dtype=int)

    m = dictionary_A.shape[0]

    # 1. Generate Random Binary Candidates
    candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))
    # Optional: Ensure unique candidates if needed (adds overhead but might be beneficial)
    # candidate_u_vectors_np = np.unique(candidate_u_vectors_np, axis=0)
    # num_candidates = candidate_u_vectors_np.shape[0] # Update count if unique is used

    if candidate_u_vectors_np.shape[0] == 0:
        print("Warning: No unique candidates generated.")
        return np.empty((0, T), dtype=int)

    # 2. Embed the Candidates
    embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)

    # 3. Scale the Embedded Candidates
    try:
        # Use the *fitted* scaler from the training data
        embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)
    except Exception as e:
        print(f"Error scaling candidates: {e}")
        return np.empty((0, T), dtype=int)

    # 4. Predict Mean and Std Dev using the GP Model
    try:
        mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)
    except Exception as e:
        print(f"Error predicting with GP model: {e}")
        return np.empty((0, T), dtype=int)

    # 5. Calculate Acquisition Function
    if acquisition_func == 'EI':
        if current_best_neg_f_val is None or xi is None:
            print("Error: current_best_neg_f_val and xi must be provided for EI.")
            return np.empty((0, T), dtype=int)
        acq_values = expected_improvement(mu, std, current_best_neg_f_val, xi=xi)
    elif acquisition_func == 'LCB':
        if kappa is None:
            print("Error: kappa must be provided for LCB.")
            return np.empty((0, T), dtype=int)
        acq_values = lower_confidence_bound(mu, std, kappa=kappa)
    else:
        print(f"Error: Unknown acquisition function '{acquisition_func}'. Use 'EI' or 'LCB'.")
        return np.empty((0, T), dtype=int)

    # 6. Select Top Candidates
    # Use np.argsort to find indices that would sort the array (ascending)
    # Select the last q indices for the highest acquisition values (EI or LCB)
    # If q=1, np.argmax(acq_values) is simpler but argsort works generally
    if acq_values.size == 0:
        print("Warning: No acquisition values calculated.")
        return np.empty((0, T), dtype=int)

    # Ensure q is not larger than the number of candidates evaluated
    q_actual = min(q, acq_values.size)
    if q_actual == 0:
         return np.empty((0, T), dtype=int)


    # Get indices of the top q_actual values
    # Partition is faster than full sort for finding top k: O(N) vs O(N log N)
    # We want indices of the largest values, so partition around (N - q_actual)-th element
    kth_largest_idx = acq_values.size - q_actual
    # Indices of elements >= the (N-q_actual)-th element
    top_indices_unordered = np.argpartition(acq_values, kth_largest_idx)[kth_largest_idx:]

    # If we need exactly q_actual and there are ties, we might get more. Refine:
    if len(top_indices_unordered) > q_actual:
        # Sort the values of these top candidates and take the highest q_actual
        top_values = acq_values[top_indices_unordered]
        sorted_within_top_indices = np.argsort(top_values)[::-1] # Descending order of value
        top_indices = top_indices_unordered[sorted_within_top_indices[:q_actual]]
    else:
         # If we got exactly q_actual or fewer, sort them by value
         top_values = acq_values[top_indices_unordered]
         sorted_within_top_indices = np.argsort(top_values)[::-1] # Descending order of value
         top_indices = top_indices_unordered[sorted_within_top_indices]


    # Return the corresponding original U vectors
    return candidate_u_vectors_np[top_indices, :]
```

**4. Bayesian Optimization Loop:**

Execute the main BO loop, iterating, fitting the model, optimizing the acquisition function, and evaluating points. This needs to be run three times, changing the `ACQUISITION_FUNCTION` parameter and `KAPPA` / `KAPPA_INCREASE_FACTOR` as needed.

``` python
# BO Loop Parameters (Adjust per experiment variant)

# --- Variant 1: Expected Improvement (EI) ---
ACQUISITION_FUNCTION = 'EI'
XI = 0.01 # Exploration parameter for EI
KAPPA = None
INITIAL_KAPPA = None
KAPPA_INCREASE_FACTOR = None
# Use X from EI run in PDF

# # --- Variant 2: Lower Confidence Bound (LCB) ---
# ACQUISITION_FUNCTION = 'LCB'
# XI = None
# KAPPA = 2.576 # Fixed kappa for LCB
# INITIAL_KAPPA = KAPPA
# KAPPA_INCREASE_FACTOR = None
# # Use X from LCB run in PDF

# # --- Variant 3: LCB with Increasing Kappa (LCB-IK) ---
# ACQUISITION_FUNCTION = 'LCB'
# XI = None
# KAPPA = None # Kappa will be dynamic
# INITIAL_KAPPA = 3.75 # Starting kappa
# KAPPA_INCREASE_FACTOR = 1.3 # Factor to increase kappa on improvement
# # Use X from LCB-IK run in PDF


# --- Common Parameters ---
N_INITIAL = 20
N_ITERATIONS = 20
BATCH_SIZE_q = 5
NUM_CANDIDATES_Acqf = T * 1024 # Number of random U's to sample for acqf opt
m = 64 # Dimension of the embedding space

# --- Data Storage ---
evaluated_U_np_list = [] # List to store evaluated U vectors (binary, as numpy arrays)
evaluated_f_vals = []    # List to store raw objective values (lower is better)
train_Y_list = []        # List to store NEGATED objective values for GP (higher is better)

# 1. Initialization
print(f"--- Starting BO with {ACQUISITION_FUNCTION} ---")
print(f"Generating {N_INITIAL} initial points...")
initial_candidates_U = []
while len(initial_candidates_U) < N_INITIAL:
    U_init = np.random.randint(0, 2, size=T)
    # Ensure unique initial points (compare numpy arrays correctly)
    is_duplicate = any(np.array_equal(U_init, u) for u in initial_candidates_U)
    if not is_duplicate:
        initial_candidates_U.append(U_init)

for i, U_init in enumerate(initial_candidates_U):
    print(f" Evaluating initial point {i+1}/{N_INITIAL}...")
    f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)
    if f_val < LARGE_PENALTY: # Only store valid initial points
        neg_f_val = -f_val
        evaluated_U_np_list.append(U_init)
        evaluated_f_vals.append(f_val)
        train_Y_list.append(neg_f_val)
        print(f"  Initial point {i+1}: Obj = {f_val:.4f}")
    else:
        print(f"  Initial point {i+1}: Infeasible (Penalty)")


# Initial best objective
best_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')
print(f"Initial best objective value: {best_obj_so_far if np.isfinite(best_obj_so_far) else 'None (all initial points infeasible)'}")

# Initialize kappa for LCB-IK
current_kappa = INITIAL_KAPPA
if ACQUISITION_FUNCTION == 'LCB' and KAPPA_INCREASE_FACTOR is not None:
    print(f"Initial Kappa: {current_kappa:.3f}")


# 2. BO Iterations
for iteration in range(N_ITERATIONS):
    start_time = time.time()
    print(f"\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---")

    # Check if we have any valid points to model
    if not evaluated_U_np_list:
        print("Warning: No valid points evaluated yet. Evaluating random points.")
        # Try to evaluate a few more random points if initialization failed
        new_random_U = np.random.randint(0, 2, size=T)
        is_duplicate = any(np.array_equal(new_random_U, u) for u in evaluated_U_np_list)
        if not is_duplicate:
             f_val = evaluate_objective(new_random_U, X, v_star, convolutions, d, w)
             if f_val < LARGE_PENALTY:
                 neg_f_val = -f_val
                 evaluated_U_np_list.append(new_random_U)
                 evaluated_f_vals.append(f_val)
                 train_Y_list.append(neg_f_val)
                 best_obj_so_far = min(best_obj_so_far, f_val)
                 print(f" Evaluated random point: Obj = {f_val:.4f}")
             else:
                 print(" Evaluated random point: Infeasible")
        if not evaluated_U_np_list: # Still no points? Skip iteration.
             print("Skipping iteration as no valid points are available.")
             continue


    # a. Generate dictionary A for HED
    current_dictionary_A = generate_diverse_random_dictionary(T, m)

    # b. Embed ALL evaluated U vectors so far
    evaluated_U_np_array = np.array(evaluated_U_np_list)
    embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)

    # c. Scale the embedded training data
    scaler = MinMaxScaler()
    # Fit scaler only if there's data
    if embedded_train_X.shape[0] > 0:
        # Fit and transform
        embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)
    else:
        # Handle case with no data (should have been caught above)
        embedded_train_X_scaled = embedded_train_X # Will be empty

    # Ensure train_Y is a NumPy array for fitting
    train_Y_for_fit = np.array(train_Y_list) # Use the list directly

    # d. Fit GP Model using SCALED data
    print("Fitting GP model...")
    gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)

    if gp_model is None:
        print("Warning: Failed to fit GP model. Skipping acquisition function optimization.")
        continue # Skip if GP fitting failed

    print("GP model fitted.")

    # e. Determine current best value for Acquisition Function
    # We are maximizing the negative objective in the GP
    current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size > 0 else -float('inf')

    # Prevent potential issues if all points were infeasible (very large negative values)
    # Check if the best value is close to the negative penalty
    if current_best_neg_f_val <= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):
        print(f"Warning: Current best NEGATIVE value ({current_best_neg_f_val:.2f}) is very low, possibly indicating only infeasible points found.")
        # In EI, this might lead to near-zero acquisition values if xi is small.
        # Consider adjusting xi or handling this case if it causes issues.


    # f. Optimize Acquisition Function
    acqf_params = {}
    if ACQUISITION_FUNCTION == 'EI':
        acqf_params['xi'] = XI
        acqf_params['current_best_neg_f_val'] = current_best_neg_f_val
        print(f"Optimizing acquisition function ({ACQUISITION_FUNCTION} with xi={XI:.2f})...")
    elif ACQUISITION_FUNCTION == 'LCB':
        # Use fixed KAPPA or dynamic current_kappa
        kappa_to_use = KAPPA if KAPPA_INCREASE_FACTOR is None else current_kappa
        acqf_params['kappa'] = kappa_to_use
        print(f"Optimizing acquisition function ({ACQUISITION_FUNCTION} with Kappa={kappa_to_use:.3f})...")

    next_U_candidates_np = optimize_acqf_discrete_via_embedding(
        gp_model=gp_model,
        scaler=scaler, # Pass the fitted scaler
        dictionary_A=current_dictionary_A,
        T=T,
        q=BATCH_SIZE_q,
        num_candidates=NUM_CANDIDATES_Acqf,
        acquisition_func=ACQUISITION_FUNCTION,
        **acqf_params
    )

    print(f"Selected {next_U_candidates_np.shape[0]} candidate(s).")

    # g. Evaluate Objective for the selected candidate(s) & Update Kappa if needed
    newly_evaluated_U = []
    newly_evaluated_f = []
    newly_evaluated_neg_f = []
    improvement_found_in_batch = False

    if next_U_candidates_np.shape[0] == 0:
         print("Warning: No candidates selected by acquisition function.")

    for i in range(next_U_candidates_np.shape[0]):
        next_U = next_U_candidates_np[i, :]

        # Check if this candidate was already evaluated
        already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)

        if already_evaluated:
            print(f" Candidate {i+1} was already evaluated. Skipping re-evaluation.")
            continue # Skip to next candidate

        # Evaluate the objective
        next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)
        next_neg_f = -next_f # Negate for GP maximization

        # Calculate Y for printing/verification (optional)
        V_sum_eval = np.sum(v_star[next_U == 1, :], axis=0)
        Y_eval = X + V_sum_eval

        print(f" Candidate {i+1}: Y={Y_eval.astype(int)}, Obj = {next_f:.4f}")

        # Add to temporary lists for this iteration
        newly_evaluated_U.append(next_U)
        newly_evaluated_f.append(next_f)
        newly_evaluated_neg_f.append(next_neg_f) # Store negative value

        # Update overall best objective found AND KAPPA if improved (for LCB-IK)
        if next_f < best_obj_so_far:
             print(f"  ** Improvement found! Old best: {best_obj_so_far:.4f}, New best: {next_f:.4f}")
             best_obj_so_far = next_f
             # If using LCB-IK, increase Kappa
             if ACQUISITION_FUNCTION == 'LCB' and KAPPA_INCREASE_FACTOR is not None:
                 old_kappa = current_kappa
                 current_kappa *= KAPPA_INCREASE_FACTOR
                 # Optional: Cap Kappa
                 # current_kappa = min(current_kappa, MAX_KAPPA)
                 print(f"  ** Increasing Kappa from {old_kappa:.3f} to {current_kappa:.3f}")
                 improvement_found_in_batch = True

    # h. Augment Dataset for next iteration
    evaluated_U_np_list.extend(newly_evaluated_U)
    evaluated_f_vals.extend(newly_evaluated_f)
    train_Y_list.extend(newly_evaluated_neg_f) # Add negative values for next GP fit

    # Reporting
    iter_time = time.time() - start_time
    print(f"Best objective value found so far: {best_obj_so_far:.4f}")
    print(f"Total points evaluated: {len(evaluated_f_vals)}")
    if ACQUISITION_FUNCTION == 'LCB' and KAPPA_INCREASE_FACTOR is not None:
         print(f"Kappa for next iteration: {current_kappa:.3f}")
    print(f"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.")


# 5. Results Reporting and Verification
print("\n--- Optimization Finished ---")

if not evaluated_f_vals:
    print("No points were successfully evaluated.")
else:
    # Find the best point among all evaluated points
    valid_indices = [i for i, f in enumerate(evaluated_f_vals) if f < LARGE_PENALTY]
    if not valid_indices:
        print("No feasible points were found during the optimization.")
        final_best_f = min(evaluated_f_vals) # Report the penalty value
        final_best_idx_in_all = np.argmin(evaluated_f_vals)
        final_best_U = evaluated_U_np_list[final_best_idx_in_all]
        print(f"Best Objective Value Found (Penalty): {final_best_f}")
        print(f"Corresponding U vector: {final_best_U}")
    else:
        evaluated_f_vals_valid = np.array(evaluated_f_vals)[valid_indices]
        evaluated_U_np_list_valid = [evaluated_U_np_list[i] for i in valid_indices]

        final_best_idx_in_valid = np.argmin(evaluated_f_vals_valid) # Index within valid points
        final_best_U = evaluated_U_np_list_valid[final_best_idx_in_valid]
        final_best_f = evaluated_f_vals_valid[final_best_idx_in_valid]

        print(f"Total evaluations: {len(evaluated_f_vals)}")
        print(f"Best Feasible Objective Value Found: {final_best_f:.8f}") # More precision
        # Ensure U is printed correctly if it's long
        print(f"Best U vector Found: {''.join(map(str, final_best_U))}") # Print as string
        # print(f"Best U vector Found (Indices of 1s): {np.where(final_best_U == 1)[0]}") # Alternative print

        # Verification: Recalculate Y and objective for the best U found
        V_sum_best = np.sum(v_star[final_best_U == 1, :], axis=0)
        Y_best = X + V_sum_best
        is_feasible = np.all(Y_best >= 0)
        recalculated_obj = LARGE_PENALTY # Default to penalty

        print(f"\n--- Verification ---")
        print(f"Is the best U feasible? {is_feasible}")

        if is_feasible:
            try:
                Y_best_int = Y_best.astype(int)
                ewt, esp = calculate_objective_serv_time_lookup(Y_best_int, d, convolutions)
                recalculated_obj = w * ewt + (1 - w) * esp
                print(f"Resulting Y vector for best U: {Y_best_int}")
                print(f"Objective value (recalculated): {recalculated_obj:.8f}") # More precision
                if not np.isclose(final_best_f, recalculated_obj, atol=1e-6): # Use tolerance
                    print(f"Warning: Stored best objective ({final_best_f}) does not closely match recalculated ({recalculated_obj}).")
                else:
                    print("Recalculated objective matches stored value.")
            except Exception as e:
                 print(f"Error recalculating objective for verification: {e}")
                 print(f"Best Y vector was: {Y_best}")

        else:
            # This case should ideally not happen if we selected from valid points
            print(f"Resulting Y vector (infeasible): {Y_best}")
            print("Warning: The identified best U vector leads to an infeasible Y upon recalculation.")
```

## Results

The experiment was run three times, varying the acquisition function. The key results are summarized below:

-   **Run 1: Expected Improvement (EI)**
    -   Initial Best Objective: 47.9991
    -   Final Best Objective Found: **47.0549**
    -   Best U Vector Found: `0011101101110111`
    -   Resulting Y Vector: `[2 1 1 1 0 1 1 0 1 1 1 0 1 1 3]` (Feasible)
    -   Total Evaluations: 120
    -   Observations: Found improvements steadily, particularly in early iterations (iter 4, 8, 9). Many later iterations proposed candidates that were already evaluated or did not improve the objective. Several infeasible candidates (penalty value) were proposed throughout.
-   **Run 2: Lower Confidence Bound (LCB, fixed** $\kappa=2.576$)
    -   Initial Best Objective: 48.0272
    -   Final Best Objective Found: **47.2109**
    -   Best U Vector Found: `0011000001110111`
    -   Resulting Y Vector: `[2 1 1 0 1 0 1 1 1 1 1 0 1 1 3]` (Feasible)
    -   Total Evaluations: 117 (some duplicates skipped)
    -   Observations: Found improvements in iterations 6 and 9. Showed a tendency to explore, proposing many infeasible points or points that didn't improve the best found value, especially in later iterations.
-   **Run 3: LCB with Increasing Kappa (LCB-IK,** $\kappa_{start}=3.75, \text{factor}=1.3$)
    -   Initial Best Objective: 47.4702
    -   Final Best Objective Found: **46.9551**
    -   Best U Vector Found: `0011001001100111`
    -   Resulting Y Vector: `[2 1 1 0 1 1 0 1 1 1 0 1 1 1 3]` (Feasible)
    -   Total Evaluations: 105 (several duplicates skipped)
    -   Observations: Found improvements in iterations 7 (Kappa increased to 4.875) and 15 (Kappa increased to 6.338). The increasing kappa seemed to encourage finding better solutions later in the search compared to fixed LCB. Still proposed many non-improving or infeasible points. This variant achieved the lowest objective value among the three runs.

## Discussion

The experiment successfully applied Bayesian Optimization with Hamming Embedding via Dictionaries (HED) to the high-dimensional combinatorial scheduling problem. All three acquisition function variants (EI, LCB, LCB-IK) were able to find feasible solutions significantly better than the initial random points, demonstrating the effectiveness of the HED approach combined with BO for this problem type.

-   **Comparison of Acquisition Functions:**
    -   LCB with Increasing Kappa (LCB-IK) achieved the best final objective value (46.9551), suggesting that dynamically increasing the exploration parameter ($\kappa$) upon finding improvements helped escape local optima or explore more effectively later in the search process.
    -   Expected Improvement (EI) found a good solution (47.0549) relatively quickly but seemed to stagnate more in later iterations compared to LCB-IK.
    -   LCB with a fixed kappa found the worst solution among the three (47.2109), potentially indicating that the fixed exploration level was not optimal throughout the search.
-   **HED Effectiveness:** The ability of the GP model, built upon the HED embedding, to guide the search towards better solutions despite the $2^{16}$ (T=16 in LCB/LCB-IK runs) or $2^{15}$ (T=15 in EI run) size of the search space highlights the utility of the dictionary-based embedding for capturing relevant structure in the combinatorial space, as suggested by Deshwal et al. (2023). The use of ARD within the GP kernel likely helped focus on the more relevant dimensions of the embedding.
-   **Challenges:** All methods frequently proposed candidate solutions that were either infeasible (resulting in the `LARGE_PENALTY`) or duplicates of previously evaluated points. This indicates the difficulty of optimizing the acquisition function effectively in this discrete space, even with the embedding. The random sampling approach within `optimize_acqf_discrete_via_embedding` might benefit from more sophisticated search strategies.
-   **Feasibility:** The verification step confirmed that the best $U$ vectors found by each method corresponded to feasible schedules $Y_{best}$ and that the recalculated objective values matched the stored best values, validating the results.

In conclusion, the HED-based Bayesian Optimization approach proved effective for this scheduling problem. The LCB acquisition function with an adaptive exploration parameter (LCB-IK) demonstrated the best performance in finding the lowest objective value within the given evaluation budget.

## Timeline

-   **Experiment Start Date:** \[Specify Date\]
-   **Experiment End Date:** \[Specify Date\]
-   **Analysis Date:** 2025-05-05

## References

-   Deshwal, A., Ament, S., Balandat, M., Bakshy, E., Doppa, J. R., Eriksson, D. (2023). Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings. *Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)*, PMLR 206.
-   \[Add citation for source of EWT/ESP functions or scheduling problem, if applicable\]
-   \[Add citation for Gaussian Process library, e.g., Scikit-learn, GPyTorch/BoTorch if used\]
