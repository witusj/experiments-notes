<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Appointment Scheduling Experiments - 6&nbsp; Combinatorial Bayesian Optimization Experiments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./preferential-bayesian-optimization.html" rel="next">
<link href="./local-search-ranking-large.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./combinatorial-bayes-optimization.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Combinatorial Bayesian Optimization Experiments</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Appointment Scheduling Experiments</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./function-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Evaluator functions testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./xgboost-pairwise-ranking-large.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large instance XGBoost classification model for pairwise ranking</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./xgboost-pairwise-ranking-large-w-bailey-welch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./local-search-ranking-large.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Large instance local search with trained XGBoost regressor model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./combinatorial-bayes-optimization.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Combinatorial Bayesian Optimization Experiments</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preferential-bayesian-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filtered-solution-spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtered solution spaces for outpatient appointment scheduling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Function documentation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./service-time-with-no-shows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><code>service_time_with_no_shows</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./compute-convolutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><code>compute_convolutions</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calculate-objective-serv-time-lookup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><code>calculate_objective_serv_time_lookup</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./get-neighborhood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><code>get_neighborhood</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./local-search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><code>local_search</code></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#objective" id="toc-objective" class="nav-link active" data-scroll-target="#objective"><span class="header-section-number">6.1</span> Objective</a></li>
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background"><span class="header-section-number">6.2</span> Background</a></li>
  <li><a href="#hypothesis" id="toc-hypothesis" class="nav-link" data-scroll-target="#hypothesis"><span class="header-section-number">6.3</span> Hypothesis</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology"><span class="header-section-number">6.4</span> Methodology</a>
  <ul class="collapse">
  <li><a href="#tools-and-materials" id="toc-tools-and-materials" class="nav-link" data-scroll-target="#tools-and-materials"><span class="header-section-number">6.4.1</span> Tools and Materials</a></li>
  <li><a href="#experimental-design" id="toc-experimental-design" class="nav-link" data-scroll-target="#experimental-design"><span class="header-section-number">6.4.2</span> Experimental Design</a></li>
  <li><a href="#variables" id="toc-variables" class="nav-link" data-scroll-target="#variables"><span class="header-section-number">6.4.3</span> Variables</a></li>
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection"><span class="header-section-number">6.4.4</span> Data Collection</a></li>
  <li><a href="#sample-size-and-selection" id="toc-sample-size-and-selection" class="nav-link" data-scroll-target="#sample-size-and-selection"><span class="header-section-number">6.4.5</span> Sample Size and Selection</a></li>
  <li><a href="#experimental-procedure" id="toc-experimental-procedure" class="nav-link" data-scroll-target="#experimental-procedure"><span class="header-section-number">6.4.6</span> Experimental Procedure</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">6.5</span> Results</a>
  <ul class="collapse">
  <li><a href="#experiment-1-cbo-with-expected-improvement-ei-1" id="toc-experiment-1-cbo-with-expected-improvement-ei-1" class="nav-link" data-scroll-target="#experiment-1-cbo-with-expected-improvement-ei-1"><span class="header-section-number">6.5.1</span> Experiment 1: CBO with Expected Improvement (EI)</a></li>
  <li><a href="#experiment-2-cbo-with-lower-confidence-bound-lcb---kappa-2.576" id="toc-experiment-2-cbo-with-lower-confidence-bound-lcb---kappa-2.576" class="nav-link" data-scroll-target="#experiment-2-cbo-with-lower-confidence-bound-lcb---kappa-2.576"><span class="header-section-number">6.5.2</span> Experiment 2: CBO with Lower Confidence Bound (LCB) - <span class="math inline">\(\kappa =\)</span> 2.576</a></li>
  <li><a href="#summary-of-best-objectives" id="toc-summary-of-best-objectives" class="nav-link" data-scroll-target="#summary-of-best-objectives"><span class="header-section-number">6.5.3</span> Summary of Best Objectives</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">6.6</span> Discussion</a></li>
  <li><a href="#timeline" id="toc-timeline" class="nav-link" data-scroll-target="#timeline"><span class="header-section-number">6.7</span> Timeline</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">6.8</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Combinatorial Bayesian Optimization Experiments</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="objective" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="objective"><span class="header-section-number">6.1</span> Objective</h2>
<p>The objective of this experiment is to evaluate and compare the performance of two distinct Combinatorial Bayesian Optimization (CBO) strategies for an outpatient appointment scheduling problem. We investigate:</p>
<ol type="1">
<li>CBO utilizing Expected Improvement (EI) as the acquisition function.</li>
<li>CBO utilizing Lower Confidence Bound (LCB) as the acquisition function with a fixed kappa (<span class="math inline">\(\kappa\)</span>) value.</li>
</ol>
<p>We aim to determine which strategy is most effective in identifying an optimal or near-optimal schedule, as measured by the objective function value, leveraging dictionary-based embeddings for the high-dimensional combinatorial space <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span>.</p>
</section>
<section id="background" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="background"><span class="header-section-number">6.2</span> Background</h2>
<p>We consider an outpatient appointment scheduling problem as described by <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span> where the schedule is represented by a vector <span class="math inline">\(\mathbf{x} = (x_0, x_1, \ldots, x_{T-1})^T\)</span>. This vector comprises <span class="math inline">\(T\)</span> components, where <span class="math inline">\(x_j\)</span> denotes the non-negative allocation (number of patients) to time slot <span class="math inline">\(j\)</span>, for <span class="math inline">\(j = 0, \ldots, T-1\)</span>. A fundamental constraint is that the total allocation across all time slots must equal a fixed constant <span class="math inline">\(N\)</span>: <span class="math display">\[\sum_{j=0}^{T-1} x_j = N\]</span> We require <span class="math inline">\(x_j \ge 0\)</span> for all <span class="math inline">\(j = 0, \ldots, T-1\)</span>. Consequently, a valid schedule <span class="math inline">\(\mathbf{x}\)</span> belongs to the feasible set <span class="math inline">\(\mathcal{F} = \{ \mathbf{z} \in \mathbb{D}^{T} \mid \sum_{j=0}^{T-1} z_j = N, z_j \ge 0 \text{ for all } j\}\)</span>, where <span class="math inline">\(\mathbb{D}\)</span> is the set of non-negative integers (<span class="math inline">\(\mathbb{Z}_{\ge 0}\)</span>).</p>
<p><span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span> define a neighborhood structure for local search based on perturbation vectors derived from a set of <span class="math inline">\(T\)</span> basis change vectors, <span class="math inline">\(v_i \in \mathbb{D}^{T}\)</span>, for <span class="math inline">\(i = 0, \ldots, T-1\)</span>. These basis vectors represent elementary shifts of allocation between time slots:</p>
<ul>
<li><span class="math inline">\(v_0 = (-1, 0, \ldots, 0, 1)\)</span> (Shift unit <em>from</em> slot 0 <em>to</em> slot <span class="math inline">\(T-1\)</span>)</li>
<li><span class="math inline">\(v_1 = (1, -1, 0, \ldots, 0)\)</span> (Shift unit <em>from</em> slot 1 <em>to</em> slot 0)</li>
<li><span class="math inline">\(v_i = (0, \ldots, 0, \underbrace{1}_{\text{pos } i-1}, \underbrace{-1}_{\text{pos } i}, 0, \ldots, 0)\)</span> for <span class="math inline">\(i = 2, \ldots, T-1\)</span> (Shift unit <em>from</em> slot <span class="math inline">\(i\)</span> <em>to</em> slot <span class="math inline">\(i-1\)</span>)</li>
</ul>
<p>A key property of these basis vectors is that the sum of components for each vector is zero: <span class="math inline">\(\sum_{j=0}^{T-1} v_{ij} = 0\)</span> for all <span class="math inline">\(i=0, \ldots, T-1\)</span>.</p>
<p>Perturbations are constructed using a binary selection vector <span class="math inline">\(\mathbf{U} = (u_0, u_1, \ldots, u_{T-1})\)</span>, where <span class="math inline">\(u_i \in \{0, 1\}\)</span>. Each <span class="math inline">\(u_i\)</span> indicates whether the basis change <span class="math inline">\(v_i\)</span> is included in the perturbation. The resulting perturbation vector <span class="math inline">\(\mathbf{r}(\mathbf{U}) \in \mathbb{D}^{T}\)</span> is the linear combination: <span class="math display">\[\mathbf{r}(\mathbf{U}) := \sum_{i=0}^{T-1} u_i v_i\]</span></p>
<p>Since each <span class="math inline">\(v_i\)</span> sums to zero, any perturbation <span class="math inline">\(\mathbf{r}(\mathbf{U})\)</span> also sums to zero: <span class="math inline">\(\sum_{j=0}^{T-1} r_j(\mathbf{U}) = 0\)</span>. This ensures that applying such a perturbation to a valid schedule <span class="math inline">\(\mathbf{x}\)</span> preserves the total allocation <span class="math inline">\(N\)</span>.</p>
<p>The neighborhood of a schedule <span class="math inline">\(\mathbf{x} \in \mathcal{F}\)</span>, denoted by <span class="math inline">\(\mathcal{N}(\mathbf{x})\)</span>, comprises all distinct, feasible schedules <span class="math inline">\(\mathbf{x}'\)</span> reachable by applying a non-zero perturbation <span class="math inline">\(\mathbf{r}(\mathbf{U})\)</span> (<span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>, use a slightly different but related neighborhood definition based on combinations of these basis vectors).</p>
<p>The objective function to be minimized is a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP), as defined by <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>: <span class="math display">\[C(\mathbf{x}) = w \cdot EWT(\mathbf{x}) + (1-w) \cdot ESP(\mathbf{x})\]</span> <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span> prove that this objective function is multimodular, which guarantees that a local search algorithm using their defined neighborhood converges to the global optimum.</p>
<p>However, evaluating <span class="math inline">\(C(\mathbf{x})\)</span> can be computationally expensive, especially for large <span class="math inline">\(N\)</span> and <span class="math inline">\(T\)</span>. Furthermore, the search space defined by the binary vectors <span class="math inline">\(\mathbf{U}\)</span> is high-dimensional (<span class="math inline">\(2^T - 2\)</span> possibilities, excluding <span class="math inline">\(\mathbf{0}\)</span> and <span class="math inline">\(\mathbf{1}\)</span>). Bayesian Optimization (BO) is a suitable framework for optimizing such expensive black-box functions. Standard BO methods often struggle with high-dimensional combinatorial spaces. <span class="citation" data-cites="deshwal_bayesian_2023">Deshwal et al. (<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">2023</a>)</span> propose a method using dictionary-based embeddings (Hamming Embedding via Dictionaries - HED) to map the high-dimensional binary space of <span class="math inline">\(\mathbf{U}\)</span> vectors into a lower-dimensional continuous space, where standard Gaussian Process (GP) models can be effectively applied. This experiment applies the HED approach within a BO framework to solve the scheduling problem formulated by <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>.</p>
</section>
<section id="hypothesis" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="hypothesis"><span class="header-section-number">6.3</span> Hypothesis</h2>
<p>We hypothesize that:</p>
<ol type="1">
<li>Both CBO strategies, leveraging the HED embedding <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span>, will be capable of finding schedules superior to the initial schedule derived from the Bailey-Welch method (@).</li>
<li>CBO strategies employing Lower Confidence Bound (LCB) may exhibit superior performance or faster convergence compared to Expected Improvement (EI), due to the explicit exploration-exploitation trade-off inherent in LCB.</li>
</ol>
</section>
<section id="methodology" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="methodology"><span class="header-section-number">6.4</span> Methodology</h2>
<section id="tools-and-materials" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="tools-and-materials"><span class="header-section-number">6.4.1</span> Tools and Materials</h3>
<ul>
<li>Programming Language: Python 3</li>
<li>Core Libraries: NumPy, SciPy</li>
<li>Machine Learning: Scikit-learn (for <code>GaussianProcessRegressor</code>, <code>MinMaxScaler</code>)</li>
<li>Data Structures: Standard Python lists and dictionaries, NumPy arrays.</li>
<li>Imported functions: <code>bailey_welch_schedule</code>, <code>get_v_star</code>, <code>compute_convolutions</code>, <code>calculate_objective_serv_time_lookup</code> (implementing the logic from <span class="citation" data-cites="bailey1952study">Bailey (<a href="combinatorial-bayes-optimization.html#ref-bailey1952study" role="doc-biblioref">1952</a>)</span>, assumed to be in an external <code>functions.py</code> file).</li>
</ul>
</section>
<section id="experimental-design" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="experimental-design"><span class="header-section-number">6.4.2</span> Experimental Design</h3>
<p>Three distinct Bayesian optimization experiments are conducted, applying the HED embedding approach <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span> to the scheduling problem:</p>
<ol type="1">
<li><strong>Experiment 1: Expected Improvement (EI)</strong>
<ul>
<li>Acquisition Function: Expected Improvement.</li>
<li>Objective: Minimize <span class="math inline">\(C(\mathbf{x})\)</span> by iteratively selecting candidate vectors <span class="math inline">\(\mathbf{U}\)</span> (via their embeddings) that maximize the EI.</li>
</ul></li>
<li><strong>Experiment 2: Lower Confidence Bound (LCB) - Fixed Kappa</strong>
<ul>
<li>Acquisition Function: Lower Confidence Bound.</li>
<li>Objective: Minimize <span class="math inline">\(C(\mathbf{x})\)</span> using a fixed <code>kappa</code> (<span class="math inline">\(\kappa\)</span>) value in the LCB acquisition function applied to the GP model over the embedded space.</li>
</ul></li>
</ol>
<p>For all experiments, Hamming Distance Embedding (HED) with a “diverse random” dictionary construction strategy <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span> is employed to map the binary perturbation vectors <span class="math inline">\(\mathbf{U}\)</span> to a continuous embedding space. A Gaussian Process (GP) model with Automatic Relevance Determination (ARD) kernels models the (negative) objective function in this embedded space.</p>
</section>
<section id="variables" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="variables"><span class="header-section-number">6.4.3</span> Variables</h3>
<ul>
<li><strong>Independent Variables</strong>:
<ul>
<li>Type of acquisition function (EI, LCB).</li>
<li>The specific binary perturbation vector <span class="math inline">\(\mathbf{U}\)</span> selected in each iteration (chosen via optimizing the acquisition function over the embedded space).</li>
</ul></li>
<li><strong>Dependent Variables</strong>:
<ul>
<li>The objective function value <span class="math inline">\(C(\mathbf{x}')\)</span> for the resulting schedule <span class="math inline">\(\mathbf{x}' = \mathbf{x} + \mathbf{r}(\mathbf{U})\)</span> (calculated using the method from <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>).</li>
<li>The best objective function value found throughout the optimization process.</li>
</ul></li>
</ul>
</section>
<section id="data-collection" class="level3" data-number="6.4.4">
<h3 data-number="6.4.4" class="anchored" data-anchor-id="data-collection"><span class="header-section-number">6.4.4</span> Data Collection</h3>
<p>Data, comprising evaluated pairs <span class="math inline">\((\mathbf{U}, C(\mathbf{x}'))\)</span>, is collected iteratively:</p>
<ul>
<li>An initial set of <code>N_INITIAL</code> randomly generated <span class="math inline">\(\mathbf{U}\)</span> vectors is evaluated.</li>
<li>In each of the subsequent <code>N_ITERATIONS</code>, <code>BATCH_SIZE_q</code> new <span class="math inline">\(\mathbf{U}\)</span> vectors are selected by optimizing the respective acquisition function over <code>NUM_CANDIDATES_Acqf</code> randomly generated candidate vectors in the original binary space (evaluated via their embeddings). These newly selected vectors are then evaluated, and the results are added to the dataset.</li>
</ul>
</section>
<section id="sample-size-and-selection" class="level3" data-number="6.4.5">
<h3 data-number="6.4.5" class="anchored" data-anchor-id="sample-size-and-selection"><span class="header-section-number">6.4.5</span> Sample Size and Selection</h3>
<ul>
<li><strong>N_INITIAL</strong>: 20 (number of initial random evaluations)</li>
<li><strong>N_ITERATIONS</strong>: 20 (number of Bayesian optimization iterations)</li>
<li><strong>BATCH_SIZE_q</strong>: 5 (number of candidates selected and evaluated per iteration)</li>
<li><strong>NUM_CANDIDATES_Acqf</strong>: <span class="math inline">\(T \times 1024 = 20 \times 1024 = 20480\)</span> (number of random candidates generated for optimizing the acquisition function in each iteration)</li>
<li><strong>m</strong>: 128 (dimensionality of the HED embedding space, following <span class="citation" data-cites="deshwal_bayesian_2023">Deshwal et al. (<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">2023</a>)</span>)</li>
</ul>
<p>The selection of new points for evaluation is guided by the respective acquisition function (EI or LCB) optimized over the embedded space representation of candidate <span class="math inline">\(\mathbf{U}\)</span> vectors.</p>
</section>
<section id="experimental-procedure" class="level3" data-number="6.4.6">
<h3 data-number="6.4.6" class="anchored" data-anchor-id="experimental-procedure"><span class="header-section-number">6.4.6</span> Experimental Procedure</h3>
<section id="setup" class="level4" data-number="6.4.6.1">
<h4 data-number="6.4.6.1" class="anchored" data-anchor-id="setup"><span class="header-section-number">6.4.6.1</span> 1. Setup</h4>
<p>Import necessary libraries and configure warning filters.</p>
<div id="de7f16d9" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Core Libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Tuple, Callable, Optional, Union, Any, Iterable</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Scikit-learn for GP, Scaling, and potentially acquisition functions</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.gaussian_process <span class="im">import</span> GaussianProcessRegressor</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.gaussian_process.kernels <span class="im">import</span> Matern, ConstantKernel, WhiteKernel</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.exceptions <span class="im">import</span> ConvergenceWarning</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># SciPy for statistics (needed for Expected Improvement calculation)</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functions <span class="im">import</span> bailey_welch_schedule, get_v_star, compute_convolutions, calculate_objective_serv_time_lookup</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter warnings</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>, category<span class="op">=</span><span class="pp">RuntimeWarning</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>, category<span class="op">=</span>ConvergenceWarning) <span class="co"># GP fitting might not always converge perfectly</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="constants" class="level4" data-number="6.4.6.2">
<h4 data-number="6.4.6.2" class="anchored" data-anchor-id="constants"><span class="header-section-number">6.4.6.2</span> 2. Constants</h4>
<p>Definition of problem parameters and initial configuration.</p>
<div id="ae70f73b" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Problem Definition ---</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fixed Data (Use your actual data)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">24</span> <span class="co"># Total number of patients</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">20</span> <span class="co"># Dimension of the binary vector U</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">10</span> <span class="co"># Length of each interval</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>max_s <span class="op">=</span> <span class="dv">30</span> <span class="co"># Maximum service time</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="fl">0.20</span> <span class="co"># Probability of a scheduled patient not showing up</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># Weight for the waiting time in objective function</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>v_star <span class="op">=</span> get_v_star(T) <span class="co"># Get the V* matrix(T x T)</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create service time distribution</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_weighted_list(max_s: <span class="bu">int</span>, l: <span class="bu">float</span>, i: <span class="bu">int</span>) <span class="op">-&gt;</span> Optional[np.ndarray]:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Generates a service time probability distribution using optimization.</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">    This function creates a discrete probability distribution over max_s possible</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">    service times (from 1 to max_s). It uses optimization (SLSQP) to find a</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">    distribution whose weighted average service time is as close as possible</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">    to a target value 'l', subject to the constraint that the probabilities</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">    sum to 1 and each probability is between 0 and 1.</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">    After finding the distribution, it sorts the probabilities: the first 'i'</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co">    probabilities (corresponding to service times 1 to i) are sorted in</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">    ascending order, and the remaining probabilities (service times i+1 to max_s)</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co">    are sorted in descending order.</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Note:</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co">        - Requires NumPy and SciPy libraries (specifically scipy.optimize.minimize).</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co">        max_s (int): Maximum service time parameter (number of probability bins).</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co">                     Must be a positive integer.</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co">        l (float): The target weighted average service time for the distribution.</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co">                   Must be between 1 and max_s, inclusive.</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co">        i (int): The index determining the sorting split point. Probabilities</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="co">                 for service times 1 to 'i' are sorted ascendingly, and</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co">                 probabilities for service times 'i+1' to 'max_s' are sorted</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co">                 descendingly. Must be between 1 and max_s-1 for meaningful sorting.</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="co">        numpy.ndarray: An array of size max_s+1. The first element (index 0) is 0.</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="co">                       Elements from index 1 to max_s represent the calculated</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co">                       and sorted probability distribution, summing to 1.</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="co">                       Returns None if optimization fails or inputs are invalid.</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Input Validation ---</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(max_s, <span class="bu">int</span>) <span class="kw">or</span> max_s <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: max_s must be a positive integer, but got </span><span class="sc">{</span>max_s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(l, (<span class="bu">int</span>, <span class="bu">float</span>)) <span class="kw">or</span> <span class="kw">not</span> (<span class="dv">1</span> <span class="op">&lt;=</span> l <span class="op">&lt;=</span> max_s):</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: Target average 'l' (</span><span class="sc">{</span>l<span class="sc">}</span><span class="ss">) must be between 1 and max_s (</span><span class="sc">{</span>max_s<span class="sc">}</span><span class="ss">)."</span>)</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(i, <span class="bu">int</span>) <span class="kw">or</span> <span class="kw">not</span> (<span class="dv">0</span> <span class="op">&lt;</span> i <span class="op">&lt;</span> max_s):</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: Sorting index 'i' (</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">) must be between 1 and max_s-1 (</span><span class="sc">{</span>max_s<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">)."</span>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If clamping is desired instead of error:</span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(f"Warning: Index 'i' ({i}) is outside the valid range (1 to {max_s-1}). Clamping i.")</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># i = max(1, min(i, max_s - 1))</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span> <span class="co"># Strict check based on docstring requirement</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Inner helper function for optimization ---</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> objective(x: np.ndarray) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Objective function: Squared difference between weighted average and target l."""</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x represents probabilities P(1) to P(max_s)</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        service_times <span class="op">=</span> np.arange(<span class="dv">1</span>, max_s <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>        weighted_avg <span class="op">=</span> np.dot(service_times, x) <span class="co"># Equivalent to sum(k * P(k) for k=1 to max_s)</span></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (weighted_avg <span class="op">-</span> l) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Constraints for optimization ---</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Constraint 1: The sum of the probabilities must be 1</span></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    constraints <span class="op">=</span> ({</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">'type'</span>: <span class="st">'eq'</span>,</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">'fun'</span>: <span class="kw">lambda</span> x: np.<span class="bu">sum</span>(x) <span class="op">-</span> <span class="fl">1.0</span> <span class="co"># Ensure float comparison</span></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bounds: Each probability value x[k] must be between 0 and 1</span></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creates a list of max_s tuples, e.g., [(0, 1), (0, 1), ..., (0, 1)]</span></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    bounds <span class="op">=</span> [(<span class="dv">0</span>, <span class="dv">1</span>)] <span class="op">*</span> max_s</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initial guess: Use Dirichlet distribution to get a random distribution that sums to 1.</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Provides a starting point for the optimizer. np.ones(max_s) gives equal weights initially.</span></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    initial_guess <span class="op">=</span> np.random.dirichlet(np.ones(max_s))</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Perform Optimization ---</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> minimize(</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>            objective,</span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>            initial_guess,</span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>            method<span class="op">=</span><span class="st">'SLSQP'</span>,</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>            bounds<span class="op">=</span>bounds,</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>            constraints<span class="op">=</span>constraints,</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># options={'disp': False} # Set True for detailed optimizer output</span></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if optimization was successful</span></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> result.success:</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Warning: Optimization failed! Message: </span><span class="sc">{</span>result<span class="sc">.</span>message<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Optionally print result object for more details: print(result)</span></span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span> <span class="co"># Indicate failure</span></span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The optimized probabilities (P(1) to P(max_s))</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>        optimized_probs <span class="op">=</span> result.x</span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Post-process: Correct potential floating point inaccuracies ---</span></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure probabilities are non-negative and sum *exactly* to 1</span></span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>        optimized_probs[optimized_probs <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span> <span class="co"># Clamp small negatives to 0</span></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>        current_sum <span class="op">=</span> np.<span class="bu">sum</span>(optimized_probs)</span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> np.isclose(current_sum, <span class="fl">1.0</span>):</span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> current_sum <span class="op">&gt;</span> <span class="dv">0</span>: <span class="co"># Avoid division by zero</span></span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>                 optimized_probs <span class="op">/=</span> current_sum <span class="co"># Normalize to sum to 1</span></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>                 <span class="bu">print</span>(<span class="st">"Warning: Optimization resulted in zero sum probabilities after clamping negatives."</span>)</span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># Handle this case - maybe return uniform distribution or None</span></span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">return</span> <span class="va">None</span> <span class="co"># Or return uniform: np.ones(max_s) / max_s</span></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"An error occurred during optimization: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Reorder the probabilities based on the index 'i' ---</span></span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the probabilities P(1)...P(i) and P(i+1)...P(max_s)</span></span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Note: Python slicing is exclusive of the end index, array indexing is 0-based.</span></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># result.x[0] corresponds to P(1), result.x[i-1] to P(i).</span></span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a>    <span class="co"># result.x[i] corresponds to P(i+1), result.x[max_s-1] to P(max_s).</span></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a>    first_part_probs <span class="op">=</span> optimized_probs[:i]   <span class="co"># Probabilities P(1) to P(i)</span></span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>    second_part_probs <span class="op">=</span> optimized_probs[i:]  <span class="co"># Probabilities P(i+1) to P(max_s)</span></span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the first part ascending, the second part descending</span></span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>    sorted_first_part <span class="op">=</span> np.sort(first_part_probs)</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>    sorted_second_part <span class="op">=</span> np.sort(second_part_probs)[::<span class="op">-</span><span class="dv">1</span>] <span class="co"># [::-1] reverses</span></span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Create final output array ---</span></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Array of size max_s + 1, initialized to zeros. Index 0 unused.</span></span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> np.zeros(max_s <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assign the sorted probabilities back into the correct slots (index 1 onwards)</span></span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>    values[<span class="dv">1</span> : i <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> sorted_first_part      <span class="co"># Assign P(1)...P(i)</span></span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>    values[i <span class="op">+</span> <span class="dv">1</span> : max_s <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> sorted_second_part <span class="co"># Assign P(i+1)...P(max_s)</span></span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Final check on sum after potential normalization/sorting</span></span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> np.isclose(np.<span class="bu">sum</span>(values[<span class="dv">1</span>:]), <span class="fl">1.0</span>):</span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="ss">f"Warning: Final distribution sum is </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(values[<span class="dv">1</span>:])<span class="sc">}</span><span class="ss">, not 1.0. Check logic."</span>)</span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the final array with the sorted probability distribution</span></span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> values</span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">10</span>  <span class="co"># First 5 highest values in ascending order, rest in descending order</span></span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> generate_weighted_list(max_s, l, i)</span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average generated service time: </span><span class="sc">{</span>np<span class="sc">.</span>dot(np.arange(<span class="bu">len</span>(s)), s)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a>convolutions <span class="op">=</span> compute_convolutions(s, N, q)</span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(bailey_welch_schedule(T, d, N, s))</span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial schedule: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a><span class="co"># Objective Function Calculation</span></span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a>LARGE_PENALTY <span class="op">=</span> <span class="fl">1e10</span> <span class="co"># Penalty for infeasible solutions</span></span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a>ewt, esp <span class="op">=</span> calculate_objective_serv_time_lookup(X, d, convolutions)</span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a>initial_objective_value <span class="op">=</span> w <span class="op">*</span> ewt <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> esp</span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial objective value: </span><span class="sc">{</span>initial_objective_value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Average generated service time: 12.942391896136673
Initial schedule: [2 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 8]
Initial objective value: 120.67426858005447</code></pre>
</div>
</div>
</section>
<section id="common-functions-objective-evaluation-and-hed" class="level4" data-number="6.4.6.3">
<h4 data-number="6.4.6.3" class="anchored" data-anchor-id="common-functions-objective-evaluation-and-hed"><span class="header-section-number">6.4.6.3</span> 3. Common Functions (Objective Evaluation and HED)</h4>
<p>Objective evaluation implements <span class="math inline">\(C(\mathbf{x})\)</span> from <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>. HED implementation follows <span class="citation" data-cites="deshwal_bayesian_2023">Deshwal et al. (<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">2023</a>)</span>.</p>
<div id="d907211c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_objective(U_np, X_vec, v_star, convolutions, d, w):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Target function: Evaluates objective for a single binary numpy array U.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns a float.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input validation (same as before)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(U_np, np.ndarray):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="st">"Input U must be a numpy array"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> U_np.ndim <span class="op">!=</span> <span class="dv">1</span>:</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>         <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Input U must be 1-dimensional"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> U_np.shape[<span class="dv">0</span>] <span class="op">!=</span> v_star.shape[<span class="dv">0</span>]:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>         <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Dimension mismatch: U length </span><span class="sc">{</span>U_np<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> != V* rows </span><span class="sc">{</span>v_star<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> X_vec.shape[<span class="dv">0</span>] <span class="op">!=</span> v_star.shape[<span class="dv">1</span>]:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>         <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Dimension mismatch: X length must match V* columns."</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> np.<span class="bu">all</span>((U_np <span class="op">==</span> <span class="dv">0</span>) <span class="op">|</span> (U_np <span class="op">==</span> <span class="dv">1</span>)):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>         <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Input U must be binary (0s and 1s)."</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate Y based on selected rows of V_star</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    V_sum <span class="op">=</span> np.<span class="bu">sum</span>(v_star[U_np <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> X_vec <span class="op">+</span> V_sum</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check feasibility and calculate objective</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.<span class="bu">all</span>(Y <span class="op">&gt;=</span> <span class="dv">0</span>):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        ewt, esp <span class="op">=</span> calculate_objective_serv_time_lookup(Y, d, convolutions)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        objective_value <span class="op">=</span> w <span class="op">*</span> ewt <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> esp</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> objective_value</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Infeasible solution</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LARGE_PENALTY</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># --- HED Implementation ---</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hamming_distance(u1, u2):</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculates Hamming distance between two binary numpy arrays."""</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(u1 <span class="op">!=</span> u2)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_diverse_random_dictionary(T, m):</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generates the random dictionary A for HED."""</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    dictionary_A <span class="op">=</span> np.zeros((m, T), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m):</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sample theta for density of 1s in this dictionary vector</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        theta <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> (np.random.rand(T) <span class="op">&lt;</span> theta).astype(<span class="bu">int</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        dictionary_A[i, :] <span class="op">=</span> row</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dictionary_A</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _generate_binary_hadamard_matrix_recursive(dim):</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="co">    Generates a binary (0/1) Hadamard-like matrix of size dim x dim.</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="co">    'dim' must be a power of 2.</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co">    This uses the Sylvester's construction H_2n = [[H_n, H_n], [H_n, 1-H_n]]</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co">    starting with H_1 = [[1]].</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> (dim <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> (dim <span class="op">&amp;</span> (dim <span class="op">-</span> <span class="dv">1</span>) <span class="op">==</span> <span class="dv">0</span>)): <span class="co"># Checks if dim is a power of 2</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Dimension must be a power of 2."</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.array([[<span class="dv">1</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        h_prev <span class="op">=</span> _generate_binary_hadamard_matrix_recursive(dim <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>        h_top <span class="op">=</span> np.hstack((h_prev, h_prev))</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>        h_bottom <span class="op">=</span> np.hstack((h_prev, <span class="dv">1</span> <span class="op">-</span> h_prev)) <span class="co"># 1-H_n for binary</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.vstack((h_top, h_bottom))</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_wavelet_dictionary(T, m):</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="co">    Generates a dictionary A of size m x T using the subsampled binary wavelet approach.</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a><span class="co">        T (int): The dimensionality of the input space (number of columns in dictionary).</span></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a><span class="co">        m (int): The desired number of dictionary elements (number of rows).</span></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a><span class="co">        np.ndarray: An m x T integer numpy array representing the dictionary.</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> T <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"T (dimensionality) must be positive."</span>)</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> m <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"m (dictionary size) must be positive."</span>)</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Determine the smallest power of 2 &gt;= T for the full wavelet matrix</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> T <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>        n_wavelet <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> (T <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> (T <span class="op">&amp;</span> (T <span class="op">-</span> <span class="dv">1</span>) <span class="op">==</span> <span class="dv">0</span>)): <span class="co"># T is already a power of 2</span></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        n_wavelet <span class="op">=</span> T</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        n_wavelet <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>math.ceil(math.log2(T))</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Generate the full n_wavelet x n_wavelet binary Hadamard matrix</span></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f"Generating full wavelet matrix of size: {n_wavelet}x{n_wavelet}")</span></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>    full_wavelet_matrix <span class="op">=</span> _generate_binary_hadamard_matrix_recursive(n_wavelet)</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Subsample T columns if n_wavelet &gt; T</span></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_wavelet <span class="op">&gt;</span> T:</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(f"Subsampling {T} columns from {n_wavelet} columns.")</span></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>        col_indices <span class="op">=</span> np.random.choice(n_wavelet, size<span class="op">=</span>T, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>        col_indices.sort() <span class="co"># Optional: for deterministic testing if seed is set</span></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>        wavelet_matrix_T_cols <span class="op">=</span> full_wavelet_matrix[:, col_indices]</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>        wavelet_matrix_T_cols <span class="op">=</span> full_wavelet_matrix <span class="co"># n_wavelet == T</span></span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Subsample m rows</span></span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>    num_available_rows <span class="op">=</span> wavelet_matrix_T_cols.shape[<span class="dv">0</span>]</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> m <span class="op">&gt;</span> num_available_rows:</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Requested dictionary size m (</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">) is greater than "</span></span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"available unique wavelet rows (</span><span class="sc">{</span>num_available_rows<span class="sc">}</span><span class="ss">). "</span></span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>              <span class="ss">f"Using all available rows and repeating if necessary, or consider reducing m."</span>)</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For simplicity, if m &gt; num_available_rows, we'll sample with replacement</span></span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># or you could choose to error, or return fewer rows.</span></span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The paper implies m should be less than or equal to the rows of B_d.</span></span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If sampling with replacement is needed:</span></span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>        row_indices <span class="op">=</span> np.random.choice(num_available_rows, size<span class="op">=</span>m, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If strictly no replacement and m &gt; num_available_rows, one might error or cap m</span></span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># row_indices = np.random.choice(num_available_rows, size=min(m, num_available_rows), replace=False)</span></span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if m &gt; num_available_rows:</span></span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     # Handle the case where more rows are needed than available unique ones</span></span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     # This might involve repeating rows or another strategy</span></span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     pass</span></span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(f"Subsampling {m} rows from {num_available_rows} available rows.")</span></span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>        row_indices <span class="op">=</span> np.random.choice(num_available_rows, size<span class="op">=</span>m, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>    row_indices.sort() <span class="co"># Optional: for deterministic testing if seed is set</span></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>    dictionary_A <span class="op">=</span> wavelet_matrix_T_cols[row_indices, :]</span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dictionary_A</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> embed_vector(U_np, dictionary_A):</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Embeds a single binary vector U using HED."""</span></span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> dictionary_A.shape[<span class="dv">0</span>]</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>    embedding_phi <span class="op">=</span> np.zeros(m, dtype<span class="op">=</span><span class="bu">float</span>) <span class="co"># Use float for GP</span></span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m):</span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>        embedding_phi[i] <span class="op">=</span> hamming_distance(U_np, dictionary_A[i, :])</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embedding_phi</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> embed_batch(U_batch_np, dictionary_A):</span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Embeds a batch of binary vectors U."""</span></span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input U_batch_np is expected to be a NumPy array</span></span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> dictionary_A.shape[<span class="dv">0</span>]</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> U_batch_np.ndim <span class="op">==</span> <span class="dv">1</span>: <span class="co"># Handle single vector case</span></span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>        U_batch_np <span class="op">=</span> U_batch_np.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> U_batch_np.shape[<span class="dv">0</span>]</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>    embeddings_np <span class="op">=</span> np.zeros((batch_size, m), dtype<span class="op">=</span><span class="bu">float</span>) <span class="co"># Use float for GP</span></span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>        embeddings_np[j, :] <span class="op">=</span> embed_vector(U_batch_np[j, :], dictionary_A)</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return NumPy array directly</span></span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embeddings_np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="experiment-1-cbo-with-expected-improvement-ei" class="level4" data-number="6.4.6.4">
<h4 data-number="6.4.6.4" class="anchored" data-anchor-id="experiment-1-cbo-with-expected-improvement-ei"><span class="header-section-number">6.4.6.4</span> 4. Experiment 1: CBO with Expected Improvement (EI)</h4>
<p>Applies the methodology from <span class="citation" data-cites="deshwal_bayesian_2023">Deshwal et al. (<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">2023</a>)</span> using EI.</p>
<div id="36134b7d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Helper Functions ---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_fitted_model(train_X_embedded_scaled, train_Y, m):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Fits a GaussianProcessRegressor model to the SCALED embedded data.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes train_Y contains negative objective values for maximization.</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_Y.ndim <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> train_Y.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        train_Y <span class="op">=</span> train_Y.ravel() <span class="co"># sklearn GP expects 1D target array</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the kernel for the Gaussian Process</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Matern kernel is a common choice, nu=2.5 is smooth (twice differentiable)</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ConstantKernel handles the overall variance scaling</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># WhiteKernel handles the observation noise</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">=</span> ConstantKernel(<span class="fl">1.0</span>, constant_value_bounds<span class="op">=</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>)) <span class="op">*</span> <span class="op">\</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>             Matern(length_scale<span class="op">=</span>np.ones(m), <span class="co"># Enable ARD, initialize length scales to 1</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>                    length_scale_bounds<span class="op">=</span>(<span class="fl">1e-2</span>, <span class="fl">1e2</span>),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>                    nu<span class="op">=</span><span class="fl">2.5</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>             WhiteKernel(noise_level<span class="op">=</span><span class="fl">1e-10</span>, <span class="co"># Small value for numerical stability</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                         noise_level_bounds<span class="op">=</span><span class="st">"fixed"</span>) <span class="co"># Bounds for noise optimization</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Instantiate the Gaussian Process Regressor</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># alpha: Value added to the diagonal of the kernel matrix during fitting</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#        for numerical stability (can also be seen as additional noise)</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># n_restarts_optimizer: Restarts optimizer to find better hyperparameters</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    gp_model <span class="op">=</span> GaussianProcessRegressor(</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        kernel<span class="op">=</span>kernel,</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="fl">1e-10</span>, <span class="co"># Small value for numerical stability</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        n_restarts_optimizer<span class="op">=</span><span class="dv">10</span>, <span class="co"># More restarts -&gt; better hyperparams but slower</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span> <span class="co"># For reproducibility of optimizer restarts</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the GP model</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    gp_model.fit(train_X_embedded_scaled, train_Y)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gp_model</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expected_improvement(mu, sigma, f_best, xi<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the Expected Improvement acquisition function.</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes maximization (f_best is the current maximum observed value).</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co">    mu, sigma: Predicted mean and standard deviation (NumPy arrays).</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="co">    f_best: Current best observed function value (scalar).</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co">    xi: Exploration-exploitation trade-off parameter.</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure sigma is positive and non-zero to avoid division errors</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.maximum(sigma, <span class="fl">1e-9</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> (mu <span class="op">-</span> f_best <span class="op">-</span> xi) <span class="op">/</span> sigma</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    ei <span class="op">=</span> (mu <span class="op">-</span> f_best <span class="op">-</span> xi) <span class="op">*</span> norm.cdf(Z) <span class="op">+</span> sigma <span class="op">*</span> norm.pdf(Z)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set EI to 0 where variance is negligible</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    ei[sigma <span class="op">&lt;=</span> <span class="fl">1e-9</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ei</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a><span class="co"># MODIFIED: Accepts the scaler and uses scikit-learn GP + EI</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, current_best_neg_f_val):</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a><span class="co">    Optimizes acquisition function (Expected Improvement) by sampling random</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a><span class="co">    binary candidates, embedding, SCALING, predicting with GP, and calculating EI.</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a><span class="co">    Selects the top q candidates based on EI.</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns candidates as a numpy array (q x T).</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> dictionary_A.shape[<span class="dv">0</span>]</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Generate Random Binary Candidates</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>    candidate_u_vectors_np <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>(num_candidates, T))</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optional: Ensure unique candidates if needed (adds overhead)</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># candidate_u_vectors_np = np.unique(candidate_u_vectors_np, axis=0)</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># num_candidates = candidate_u_vectors_np.shape[0] # Update count</span></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Embed the Candidates</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_np <span class="op">=</span> embed_batch(candidate_u_vectors_np, dictionary_A)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Scale the Embedded Candidates</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle potential warning if scaler expects float64 (already float here)</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use the *fitted* scaler from the training data</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_scaled_np <span class="op">=</span> scaler.transform(embedded_candidates_np)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Predict Mean and Std Dev using the GP Model</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>    mu, std <span class="op">=</span> gp_model.predict(embedded_candidates_scaled_np, return_std<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Calculate Acquisition Function (Expected Improvement)</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># current_best_neg_f_val is the maximum of the (negative) objectives seen so far</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>    acq_values <span class="op">=</span> expected_improvement(mu, std, current_best_neg_f_val, xi<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Select Top Candidates</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use np.argsort to find indices that would sort the array (ascending)</span></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the last q indices for the highest EI values</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If q=1, np.argmax(acq_values) is simpler but argsort works generally</span></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> np.argsort(acq_values)[<span class="op">-</span>q:]</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure indices are returned in descending order of acquisition value (optional but nice)</span></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> top_indices[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> candidate_u_vectors_np[top_indices, :]</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Loop ---</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>N_INITIAL <span class="op">=</span> <span class="dv">49</span></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>N_ITERATIONS <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE_q <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>NUM_CANDIDATES_Acqf <span class="op">=</span> T<span class="op">*</span><span class="dv">3</span><span class="op">*</span><span class="dv">1024</span> <span class="co"># Might need more for higher T</span></span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> math.ceil(T<span class="op">/</span><span class="dv">4</span>) <span class="co"># Dimension of the embedding space</span></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Store evaluated points (using NumPy arrays)</span></span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>evaluated_U_np_list <span class="op">=</span> [] <span class="co"># List to store evaluated U vectors (binary)</span></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>evaluated_f_vals <span class="op">=</span> []    <span class="co"># List to store raw objective values (lower is better)</span></span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a>train_Y_list <span class="op">=</span> []        <span class="co"># List to store NEGATED objective values for GP (higher is better)</span></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialization</span></span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Generating </span><span class="sc">{</span>N_INITIAL<span class="sc">}</span><span class="ss"> initial points..."</span>)</span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a>initial_candidates <span class="op">=</span> [np.zeros(T, dtype<span class="op">=</span><span class="bu">int</span>)]</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="bu">len</span>(initial_candidates) <span class="op">&lt;</span> N_INITIAL <span class="op">+</span> <span class="dv">1</span>: <span class="co"># +1 for the zero vector = initial X</span></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>    U_init <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>T)</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure unique initial points</span></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>    is_duplicate <span class="op">=</span> <span class="bu">any</span>(np.array_equal(U_init, u) <span class="cf">for</span> u <span class="kw">in</span> initial_candidates)</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> is_duplicate:</span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>        initial_candidates.append(U_init)</span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> U_init <span class="kw">in</span> initial_candidates:</span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a>    f_val <span class="op">=</span> evaluate_objective(U_init, X, v_star, convolutions, d, w)</span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>    neg_f_val <span class="op">=</span> <span class="op">-</span>f_val</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.append(U_init)</span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a>    evaluated_f_vals.append(f_val)</span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a>    train_Y_list.append(neg_f_val)</span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert lists to NumPy arrays for GP fitting</span></span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a>train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Keep as column vector initially</span></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a>best_obj_so_far <span class="op">=</span> <span class="bu">min</span>(evaluated_f_vals) <span class="cf">if</span> evaluated_f_vals <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a>initial_best_obj_so_far_ei <span class="op">=</span> best_obj_so_far</span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial best objective value: </span><span class="sc">{</span>best_obj_so_far<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> np.isfinite(best_obj_so_far):</span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span>(<span class="st">"Warning: Initial best objective is infinite, possibly all initial points were infeasible."</span>)</span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. BO Iterations</span></span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(N_ITERATIONS):</span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>N_ITERATIONS<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-143"><a href="#cb5-143" aria-hidden="true" tabindex="-1"></a>    <span class="co"># a. Generate dictionary A for HED</span></span>
<span id="cb5-144"><a href="#cb5-144" aria-hidden="true" tabindex="-1"></a>    current_dictionary_A <span class="op">=</span> generate_diverse_random_dictionary(T, m)</span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a>    <span class="co"># b. Embed ALL evaluated U vectors so far</span></span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> evaluated_U_np_list:</span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Warning: No points evaluated yet. Skipping iteration."</span>)</span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_array <span class="op">=</span> np.array(evaluated_U_np_list)</span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a>    embedded_train_X <span class="op">=</span> embed_batch(evaluated_U_np_array, current_dictionary_A)</span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c. Scale the embedded training data</span></span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit scaler only if there's data</span></span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit and transform</span></span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a>        embedded_train_X_scaled <span class="op">=</span> scaler.fit_transform(embedded_train_X)</span>
<span id="cb5-159"><a href="#cb5-159" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-160"><a href="#cb5-160" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle case with no data (shouldn't happen after init)</span></span>
<span id="cb5-161"><a href="#cb5-161" aria-hidden="true" tabindex="-1"></a>        embedded_train_X_scaled <span class="op">=</span> embedded_train_X <span class="co"># Will be empty</span></span>
<span id="cb5-162"><a href="#cb5-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-163"><a href="#cb5-163" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure train_Y is a NumPy array for fitting</span></span>
<span id="cb5-164"><a href="#cb5-164" aria-hidden="true" tabindex="-1"></a>    train_Y_for_fit <span class="op">=</span> np.array(train_Y_list) <span class="co"># Use the list directly</span></span>
<span id="cb5-165"><a href="#cb5-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-166"><a href="#cb5-166" aria-hidden="true" tabindex="-1"></a>    <span class="co"># d. Fit GP Model using SCALED data</span></span>
<span id="cb5-167"><a href="#cb5-167" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Fitting GP model..."</span>)</span>
<span id="cb5-168"><a href="#cb5-168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X_scaled.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> train_Y_for_fit.shape[<span class="dv">0</span>] <span class="op">==</span> embedded_train_X_scaled.shape[<span class="dv">0</span>]:</span>
<span id="cb5-169"><a href="#cb5-169" aria-hidden="true" tabindex="-1"></a>        gp_model <span class="op">=</span> get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)</span>
<span id="cb5-170"><a href="#cb5-170" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"GP model fitted."</span>)</span>
<span id="cb5-171"><a href="#cb5-171" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-172"><a href="#cb5-172" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="st">"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration."</span>)</span>
<span id="cb5-173"><a href="#cb5-173" aria-hidden="true" tabindex="-1"></a>         <span class="cf">continue</span> <span class="co"># Skip if no data or mismatch</span></span>
<span id="cb5-174"><a href="#cb5-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-175"><a href="#cb5-175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e. Determine current best value for Acquisition Function</span></span>
<span id="cb5-176"><a href="#cb5-176" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We are maximizing the negative objective in the GP</span></span>
<span id="cb5-177"><a href="#cb5-177" aria-hidden="true" tabindex="-1"></a>    current_best_neg_f_val <span class="op">=</span> np.<span class="bu">max</span>(train_Y_for_fit) <span class="cf">if</span> train_Y_for_fit.size <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb5-178"><a href="#cb5-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-179"><a href="#cb5-179" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prevent potential issues if all points were infeasible (very large negative best_f)</span></span>
<span id="cb5-180"><a href="#cb5-180" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_best_neg_f_val <span class="op">&lt;=</span> <span class="op">-</span>LARGE_PENALTY <span class="op">/</span> <span class="dv">2</span> <span class="kw">and</span> np.isfinite(current_best_neg_f_val):</span>
<span id="cb5-181"><a href="#cb5-181" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="ss">f"Warning: Current best value (</span><span class="sc">{</span>current_best_neg_f_val<span class="sc">:.2f}</span><span class="ss">) is very low (likely from penalties). Acqf might behave unexpectedly."</span>)</span>
<span id="cb5-182"><a href="#cb5-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-183"><a href="#cb5-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-184"><a href="#cb5-184" aria-hidden="true" tabindex="-1"></a>    <span class="co"># f. Optimize Acquisition Function (Expected Improvement)</span></span>
<span id="cb5-185"><a href="#cb5-185" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Optimizing acquisition function..."</span>)</span>
<span id="cb5-186"><a href="#cb5-186" aria-hidden="true" tabindex="-1"></a>    next_U_candidates_np <span class="op">=</span> optimize_acqf_discrete_via_embedding(</span>
<span id="cb5-187"><a href="#cb5-187" aria-hidden="true" tabindex="-1"></a>        gp_model<span class="op">=</span>gp_model,</span>
<span id="cb5-188"><a href="#cb5-188" aria-hidden="true" tabindex="-1"></a>        scaler<span class="op">=</span>scaler, <span class="co"># Pass the fitted scaler</span></span>
<span id="cb5-189"><a href="#cb5-189" aria-hidden="true" tabindex="-1"></a>        dictionary_A<span class="op">=</span>current_dictionary_A,</span>
<span id="cb5-190"><a href="#cb5-190" aria-hidden="true" tabindex="-1"></a>        T<span class="op">=</span>T,</span>
<span id="cb5-191"><a href="#cb5-191" aria-hidden="true" tabindex="-1"></a>        q<span class="op">=</span>BATCH_SIZE_q,</span>
<span id="cb5-192"><a href="#cb5-192" aria-hidden="true" tabindex="-1"></a>        num_candidates<span class="op">=</span>NUM_CANDIDATES_Acqf,</span>
<span id="cb5-193"><a href="#cb5-193" aria-hidden="true" tabindex="-1"></a>        current_best_neg_f_val<span class="op">=</span>current_best_neg_f_val</span>
<span id="cb5-194"><a href="#cb5-194" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-195"><a href="#cb5-195" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Selected </span><span class="sc">{</span>next_U_candidates_np<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> candidate(s)."</span>)</span>
<span id="cb5-196"><a href="#cb5-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-197"><a href="#cb5-197" aria-hidden="true" tabindex="-1"></a>    <span class="co"># g. Evaluate Objective for the selected candidate(s)</span></span>
<span id="cb5-198"><a href="#cb5-198" aria-hidden="true" tabindex="-1"></a>    newly_evaluated_U <span class="op">=</span> []</span>
<span id="cb5-199"><a href="#cb5-199" aria-hidden="true" tabindex="-1"></a>    newly_evaluated_f <span class="op">=</span> []</span>
<span id="cb5-200"><a href="#cb5-200" aria-hidden="true" tabindex="-1"></a>    newly_evaluated_neg_f <span class="op">=</span> []</span>
<span id="cb5-201"><a href="#cb5-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-202"><a href="#cb5-202" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(next_U_candidates_np.shape[<span class="dv">0</span>]):</span>
<span id="cb5-203"><a href="#cb5-203" aria-hidden="true" tabindex="-1"></a>        next_U <span class="op">=</span> next_U_candidates_np[i, :]</span>
<span id="cb5-204"><a href="#cb5-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-205"><a href="#cb5-205" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if this candidate was already evaluated</span></span>
<span id="cb5-206"><a href="#cb5-206" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use a tolerance for floating point comparisons if U were continuous</span></span>
<span id="cb5-207"><a href="#cb5-207" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For binary, exact comparison is fine</span></span>
<span id="cb5-208"><a href="#cb5-208" aria-hidden="true" tabindex="-1"></a>        already_evaluated <span class="op">=</span> <span class="bu">any</span>(np.array_equal(next_U, u) <span class="cf">for</span> u <span class="kw">in</span> evaluated_U_np_list)</span>
<span id="cb5-209"><a href="#cb5-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-210"><a href="#cb5-210" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> already_evaluated:</span>
<span id="cb5-211"><a href="#cb5-211" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> was already evaluated. Skipping re-evaluation."</span>)</span>
<span id="cb5-212"><a href="#cb5-212" aria-hidden="true" tabindex="-1"></a>            <span class="co"># </span><span class="al">TODO</span><span class="co">: Optionally, could try to generate a *different* candidate here</span></span>
<span id="cb5-213"><a href="#cb5-213" aria-hidden="true" tabindex="-1"></a>            <span class="co">#       e.g., by running optimize_acqf again excluding this one,</span></span>
<span id="cb5-214"><a href="#cb5-214" aria-hidden="true" tabindex="-1"></a>            <span class="co">#       or sampling randomly near it. For now, just skip.</span></span>
<span id="cb5-215"><a href="#cb5-215" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span> <span class="co"># Skip to next candidate</span></span>
<span id="cb5-216"><a href="#cb5-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-217"><a href="#cb5-217" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate the objective</span></span>
<span id="cb5-218"><a href="#cb5-218" aria-hidden="true" tabindex="-1"></a>        next_f <span class="op">=</span> evaluate_objective(next_U, X, v_star, convolutions, d, w)</span>
<span id="cb5-219"><a href="#cb5-219" aria-hidden="true" tabindex="-1"></a>        next_neg_f <span class="op">=</span> <span class="op">-</span>next_f</span>
<span id="cb5-220"><a href="#cb5-220" aria-hidden="true" tabindex="-1"></a>        V_sum <span class="op">=</span> np.<span class="bu">sum</span>(v_star[next_U <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-221"><a href="#cb5-221" aria-hidden="true" tabindex="-1"></a>        Y <span class="op">=</span> X <span class="op">+</span> V_sum</span>
<span id="cb5-222"><a href="#cb5-222" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: Obj = </span><span class="sc">{</span>next_f<span class="sc">:.4f}</span><span class="ss">, schedule = </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-223"><a href="#cb5-223" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add to temporary lists for this iteration</span></span>
<span id="cb5-224"><a href="#cb5-224" aria-hidden="true" tabindex="-1"></a>        newly_evaluated_U.append(next_U)</span>
<span id="cb5-225"><a href="#cb5-225" aria-hidden="true" tabindex="-1"></a>        newly_evaluated_f.append(next_f)</span>
<span id="cb5-226"><a href="#cb5-226" aria-hidden="true" tabindex="-1"></a>        newly_evaluated_neg_f.append(next_neg_f)</span>
<span id="cb5-227"><a href="#cb5-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-228"><a href="#cb5-228" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update overall best objective found</span></span>
<span id="cb5-229"><a href="#cb5-229" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> next_f <span class="op">&lt;</span> best_obj_so_far:</span>
<span id="cb5-230"><a href="#cb5-230" aria-hidden="true" tabindex="-1"></a>            best_obj_so_far <span class="op">=</span> next_f</span>
<span id="cb5-231"><a href="#cb5-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-232"><a href="#cb5-232" aria-hidden="true" tabindex="-1"></a>    <span class="co"># h. Augment Dataset for next iteration</span></span>
<span id="cb5-233"><a href="#cb5-233" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.extend(newly_evaluated_U)</span>
<span id="cb5-234"><a href="#cb5-234" aria-hidden="true" tabindex="-1"></a>    evaluated_f_vals.extend(newly_evaluated_f)</span>
<span id="cb5-235"><a href="#cb5-235" aria-hidden="true" tabindex="-1"></a>    train_Y_list.extend(newly_evaluated_neg_f) <span class="co"># Add negative values for next GP fit</span></span>
<span id="cb5-236"><a href="#cb5-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-237"><a href="#cb5-237" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert train_Y_list back to array for potential use (though we rebuild it next iter)</span></span>
<span id="cb5-238"><a href="#cb5-238" aria-hidden="true" tabindex="-1"></a>    train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb5-239"><a href="#cb5-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-240"><a href="#cb5-240" aria-hidden="true" tabindex="-1"></a>    iter_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb5-241"><a href="#cb5-241" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best objective value found so far: </span><span class="sc">{</span>best_obj_so_far<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-242"><a href="#cb5-242" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total points evaluated: </span><span class="sc">{</span><span class="bu">len</span>(evaluated_f_vals)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-243"><a href="#cb5-243" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> completed in </span><span class="sc">{</span>iter_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb5-244"><a href="#cb5-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-245"><a href="#cb5-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-246"><a href="#cb5-246" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Results ---</span></span>
<span id="cb5-247"><a href="#cb5-247" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Optimization Finished ---"</span>)</span>
<span id="cb5-248"><a href="#cb5-248" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> evaluated_f_vals:</span>
<span id="cb5-249"><a href="#cb5-249" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No points were successfully evaluated."</span>)</span>
<span id="cb5-250"><a href="#cb5-250" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb5-251"><a href="#cb5-251" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the best point among all evaluated points</span></span>
<span id="cb5-252"><a href="#cb5-252" aria-hidden="true" tabindex="-1"></a>    final_best_idx_ei <span class="op">=</span> np.argmin(evaluated_f_vals) <span class="co"># Index of minimum raw objective</span></span>
<span id="cb5-253"><a href="#cb5-253" aria-hidden="true" tabindex="-1"></a>    final_best_U_ei <span class="op">=</span> evaluated_U_np_list[final_best_idx_ei]</span>
<span id="cb5-254"><a href="#cb5-254" aria-hidden="true" tabindex="-1"></a>    final_best_f_ei <span class="op">=</span> evaluated_f_vals[final_best_idx_ei]</span>
<span id="cb5-255"><a href="#cb5-255" aria-hidden="true" tabindex="-1"></a>    nr_evaluated_f_vals_ei <span class="op">=</span> <span class="bu">len</span>(evaluated_f_vals) <span class="co"># Saved for reporting results</span></span>
<span id="cb5-256"><a href="#cb5-256" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total evaluations: </span><span class="sc">{</span><span class="bu">len</span>(evaluated_f_vals)<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb5-257"><a href="#cb5-257" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Objective Value Found: </span><span class="sc">{</span>final_best_f_ei<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-258"><a href="#cb5-258" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure U is printed correctly if it's long</span></span>
<span id="cb5-259"><a href="#cb5-259" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best U vector Found: </span><span class="sc">{</span>final_best_U_ei<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-260"><a href="#cb5-260" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f"Best U vector Found (Indices of 1s): {np.where(final_best_U_ei == 1)[0]}")</span></span>
<span id="cb5-261"><a href="#cb5-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-262"><a href="#cb5-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-263"><a href="#cb5-263" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verification - Recalculate Y for the best U found</span></span>
<span id="cb5-264"><a href="#cb5-264" aria-hidden="true" tabindex="-1"></a>    V_sum_best <span class="op">=</span> np.<span class="bu">sum</span>(v_star[final_best_U_ei <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-265"><a href="#cb5-265" aria-hidden="true" tabindex="-1"></a>    Y_best_ei <span class="op">=</span> X <span class="op">+</span> V_sum_best</span>
<span id="cb5-266"><a href="#cb5-266" aria-hidden="true" tabindex="-1"></a>    is_feasible <span class="op">=</span> np.<span class="bu">all</span>(Y_best_ei <span class="op">&gt;=</span> <span class="dv">0</span>)</span>
<span id="cb5-267"><a href="#cb5-267" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb5-268"><a href="#cb5-268" aria-hidden="true" tabindex="-1"></a>        ewt, esp <span class="op">=</span> calculate_objective_serv_time_lookup(Y_best_ei, d, convolutions)</span>
<span id="cb5-269"><a href="#cb5-269" aria-hidden="true" tabindex="-1"></a>        recalculated_obj <span class="op">=</span> w <span class="op">*</span> ewt <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> esp</span>
<span id="cb5-270"><a href="#cb5-270" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-271"><a href="#cb5-271" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-272"><a href="#cb5-272" aria-hidden="true" tabindex="-1"></a>        LARGE_PENALTY</span>
<span id="cb5-273"><a href="#cb5-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-274"><a href="#cb5-274" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Verification ---"</span>)</span>
<span id="cb5-275"><a href="#cb5-275" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Is the best U feasible? </span><span class="sc">{</span>is_feasible<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-276"><a href="#cb5-276" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb5-277"><a href="#cb5-277" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Resulting Y vector for best U: </span><span class="sc">{</span>Y_best_ei<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-278"><a href="#cb5-278" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Objective value (recalculated): </span><span class="sc">{</span>recalculated_obj<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-279"><a href="#cb5-279" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> np.isclose(final_best_f_ei, recalculated_obj):</span>
<span id="cb5-280"><a href="#cb5-280" aria-hidden="true" tabindex="-1"></a>             <span class="bu">print</span>(<span class="ss">f"Warning: Stored best objective (</span><span class="sc">{</span>final_best_f_ei<span class="sc">}</span><span class="ss">) does not match recalculation (</span><span class="sc">{</span>recalculated_obj<span class="sc">}</span><span class="ss">)!"</span>)</span>
<span id="cb5-281"><a href="#cb5-281" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> final_best_f <span class="op">&lt;</span> LARGE_PENALTY:</span>
<span id="cb5-282"><a href="#cb5-282" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="ss">f"Warning: Best objective (</span><span class="sc">{</span>final_best_f_ei<span class="sc">}</span><span class="ss">) is not the penalty value, but feasibility check failed."</span>)</span>
<span id="cb5-283"><a href="#cb5-283" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="ss">f"Resulting Y vector (infeasible): </span><span class="sc">{</span>Y_best_ei<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-284"><a href="#cb5-284" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-285"><a href="#cb5-285" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="st">"Best solution found corresponds to an infeasible penalty value."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generating 49 initial points...
Initial best objective value: 118.87100166955729

--- Iteration 1/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 114.9636, schedule = [2 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 2 0 1 7]
  Candidate 1: Obj = 130.2052, schedule = [1 1 1 1 1 1 1 0 1 1 0 2 1 0 1 0 2 0 0 9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  1  1  1 -1  2  0  2  1  0  1  1  0  1  0  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  1  0  1  2  1  0  1  0  2  1  0  1  0  2 -1  1  9]
  Candidate 4: Obj = 131.1795, schedule = [1 1 2 1 0 1 1 1 0 1 0 2 0 1 1 0 2 0 0 9]
Best objective value found so far: 114.9636
Total points evaluated: 55
Iteration 1 completed in 2.91 seconds.

--- Iteration 2/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 124.1641, schedule = [3 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 2 0 0 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1 -1  1  1  1  2  0  0  1  2  0  0  8]
  Candidate 2: Obj = 123.1027, schedule = [3 0 1 2 0 1 1 1 0 0 1 1 1 1 0 1 2 0 0 8]
  Candidate 3: Obj = 124.6251, schedule = [3 0 2 1 0 1 0 1 0 1 1 2 1 0 0 1 2 0 0 8]
  Candidate 4: Obj = 124.1919, schedule = [3 1 0 2 0 1 1 0 1 0 2 0 1 0 1 1 2 0 0 8]
Best objective value found so far: 114.9636
Total points evaluated: 60
Iteration 2 completed in 2.75 seconds.

--- Iteration 3/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  1  1  1 -1  2  1  0  2 -1  1  2  1 -1  2  8]
  Candidate 1: Obj = 126.5321, schedule = [2 1 1 0 1 1 0 2 0 1 1 0 1 0 1 2 1 0 1 8]
  Candidate 2: Obj = 122.9236, schedule = [2 1 2 0 1 1 1 0 1 0 2 1 1 0 1 0 2 0 0 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  0  0  2  1  0  1  0  1  2  1 -1  2  0  2  0  1  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  0  0  2  0  2  1 -1  1  1  2  0  1  7]
Best objective value found so far: 114.9636
Total points evaluated: 65
Iteration 3 completed in 2.41 seconds.

--- Iteration 4/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  2  0  1  0  2  0  2  1  0  0  1  2 -1  2  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  1  1  0  0  2  1  1  1  0  0  1  2 -1  1  9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  1  1  1  1  1  1  1  0  0  1  2 -1  2  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  0  1  1  1  1  1  1  0  0  1  2 -1  2  8]
  Candidate 4: Obj = 132.3160, schedule = [2 0 2 1 0 1 0 1 1 1 0 2 1 0 0 1 2 0 0 9]
Best objective value found so far: 114.9636
Total points evaluated: 70
Iteration 4 completed in 2.65 seconds.

--- Iteration 5/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  1  0  1  1  1  1 -1  2  1  1  0  1  7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  2  0  1  1  1  0  1  2 -1  1  1  1  1  1  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  1  1  1  1  0  2  0  2 -1  2  0  2  0  1  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  1  0  0  2  1 -1  1  1  2  0  1  0  2  0  0  1  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  2 -1  2  1  0  1  0  1  2  1 -1  2  7]
Best objective value found so far: 114.9636
Total points evaluated: 75
Iteration 5 completed in 2.52 seconds.

--- Iteration 6/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  1  1  0  0  1  1  1  0  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  1  2  0  1  1  0  1  1  1  0  1  1  1  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  1  1  0  1  1  0  0  1  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  1  0  1  1  1  0  1  2  0  0  2  1 -1  2  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  1  1  1  1  0  2 -1  2  0  1  1  0  8]
Best objective value found so far: 114.9636
Total points evaluated: 80
Iteration 6 completed in 2.68 seconds.

--- Iteration 7/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 116.6354, schedule = [3 0 2 0 1 1 0 1 1 1 1 1 1 0 1 0 2 0 1 7]
  Candidate 1: Obj = 116.6189, schedule = [3 1 1 1 0 1 0 1 1 1 1 0 2 0 1 1 1 0 1 7]
  Candidate 2: Obj = 124.8705, schedule = [2 0 1 2 0 1 1 0 1 1 1 1 0 1 0 1 2 0 1 8]
  Candidate 3: Obj = 123.0720, schedule = [3 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  1  1  0  1  1  1  1 -1  2  0  2 -1  2  8]
Best objective value found so far: 114.9636
Total points evaluated: 85
Iteration 7 completed in 2.61 seconds.

--- Iteration 8/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 125.8226, schedule = [2 1 1 0 1 0 1 2 0 0 2 0 1 1 1 0 2 0 1 8]
  Candidate 1: Obj = 122.2661, schedule = [2 1 1 1 1 1 0 1 0 1 2 0 1 0 2 1 1 0 0 8]
  Candidate 2: Obj = 126.1646, schedule = [3 1 1 0 0 2 0 1 0 1 1 2 1 0 0 2 0 0 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  0  2  0  1  0  2  1 -1  2  0  1  1  0  9]
  Candidate 4: Obj = 125.4905, schedule = [2 1 2 1 0 0 1 1 0 2 0 2 1 0 0 2 0 0 1 8]
Best objective value found so far: 114.9636
Total points evaluated: 90
Iteration 8 completed in 2.83 seconds.

--- Iteration 9/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  2  1 -1  2  0  1  1  0  2  0  2 -1  2  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  1  0  0  2  1 -1  2  0  1  1  0  2  0  2 -1  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  0  2  0  0  2  0  2  1 -1  1  2  1 -1  1  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  0  2  1 -1  1  1  2  0  0  1  2  1 -1  2  8]
  Candidate 4: Obj = 132.6410, schedule = [2 0 2 1 0 0 2 0 1 1 0 2 0 0 1 1 1 0 2 8]
Best objective value found so far: 114.9636
Total points evaluated: 95
Iteration 9 completed in 2.84 seconds.

--- Iteration 10/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 122.2296, schedule = [2 2 0 1 1 0 2 0 1 1 0 2 0 1 0 2 0 0 2 7]
  Candidate 1: Obj = 119.2311, schedule = [3 1 0 1 1 0 2 0 0 1 1 2 1 0 0 1 1 1 1 7]
  Candidate 2: Obj = 121.8186, schedule = [3 1 0 1 0 1 1 1 1 0 1 2 1 0 1 1 0 1 0 8]
  Candidate 3: Obj = 130.3095, schedule = [1 2 0 1 1 1 0 1 1 0 1 2 0 1 1 0 1 0 2 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  0  1  1  1  0  1  2  1 -1  1  2  0  1  1  7]
Best objective value found so far: 114.9636
Total points evaluated: 100
Iteration 10 completed in 2.78 seconds.

--- Iteration 11/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  1  0  1  0  2  0  2 -1  1  1  2 -1  1  9]
  Candidate 1: Obj = 132.3651, schedule = [2 0 1 1 1 1 1 0 0 2 0 2 0 1 0 1 2 0 0 9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  0  1  1  1  0  2  1 -1  2  0  2 -1  1  9]
  Candidate 3: Obj = 132.7032, schedule = [1 1 1 2 0 0 2 0 1 1 0 2 0 0 2 0 2 0 0 9]
  Candidate 4: Obj = 133.3754, schedule = [2 0 1 2 0 1 1 0 0 2 0 2 0 0 2 0 1 1 0 9]
Best objective value found so far: 114.9636
Total points evaluated: 105
Iteration 11 completed in 2.70 seconds.

--- Iteration 12/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  1  0  0  1  1  1  1  1  0  2 -1  1  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  0  0  2  0  2  0  0  1  2  1  0  1  0  2 -1  1  9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  0  1  0  1  2 -1  1  2  1  0  1  0  2  1  0  1  8]
  Candidate 3: Obj = 127.0694, schedule = [2 0 2 0 0 1 2 1 0 0 1 2 0 1 1 0 2 0 1 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  1  1  1  0  0  1  1  1  1  0  1  2 -1  2  8]
Best objective value found so far: 114.9636
Total points evaluated: 110
Iteration 12 completed in 2.93 seconds.

--- Iteration 13/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 134.6761, schedule = [1 2 1 0 0 1 2 0 0 1 1 2 0 0 1 1 1 0 1 9]
  Candidate 1: Obj = 134.2275, schedule = [1 1 1 2 0 0 2 0 0 2 0 1 1 0 2 0 1 0 1 9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  2  1  1 -1  1  1  2  1 -1  1  1  1  0  1  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  0  1  0  2  0  2 -1  1  1  1  1  0  2  0  1  1  0  9]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  1 -1  2  0  1  1  0  1  2  0  1  0  9]
Best objective value found so far: 114.9636
Total points evaluated: 115
Iteration 13 completed in 3.68 seconds.

--- Iteration 14/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  0  1  2 -1  1  2  1  0  0  2  0  1  0  2  7]
  Candidate 1: Obj = 122.5544, schedule = [3 1 1 0 1 0 1 1 0 2 0 1 1 0 1 1 1 1 0 8]
  Candidate 2: Obj = 119.2175, schedule = [2 1 2 0 1 1 1 0 0 2 1 0 1 0 1 1 2 0 1 7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  2  0  1  1  0  2  0  2 -1  2  0  1  1  0  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  2  1  0  1  0  2  0  1  1  1  0  2 -1  1  1  1  1  1  7]
Best objective value found so far: 114.9636
Total points evaluated: 120
Iteration 14 completed in 3.42 seconds.

--- Iteration 15/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  1  1 -1  2  1  1  0  0  2  0  2  0  0  9]
  Candidate 1: Obj = 133.5979, schedule = [2 0 2 0 0 2 1 0 0 1 1 2 1 0 1 0 1 0 2 8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  1  0  1  1  1  1  0  1  0  2  1  1 -1  2  7]
  Candidate 3: Obj = 125.6929, schedule = [3 1 1 0 1 1 1 0 1 0 2 1 1 0 1 0 1 0 1 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  0  1  1  1  1  0  2 -1  2  1  0  1  1  8]
Best objective value found so far: 114.9636
Total points evaluated: 125
Iteration 15 completed in 4.66 seconds.

--- Iteration 16/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 131.6450, schedule = [2 0 1 1 0 1 2 0 1 1 0 1 2 0 0 1 2 0 0 9]
  Candidate 1: Obj = 131.8712, schedule = [2 1 0 1 0 2 0 1 1 1 0 1 2 0 0 1 2 0 0 9]
  Candidate 2: Obj = 132.0733, schedule = [2 1 0 1 0 2 0 2 0 1 0 1 2 0 1 0 2 0 0 9]
  Candidate 3: Obj = 130.7426, schedule = [2 0 1 1 0 1 2 0 1 1 0 1 2 0 1 1 1 0 0 9]
  Candidate 4: Obj = 131.2668, schedule = [2 1 0 1 0 1 1 2 0 1 0 1 2 0 1 1 1 0 0 9]
Best objective value found so far: 114.9636
Total points evaluated: 130
Iteration 16 completed in 3.87 seconds.

--- Iteration 17/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  1 -1  2  1  1 -1  1  1  2  0  0  1  1  2  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  0  2 -1  1  1  2  0  1  0  2  1 -1  1  9]
  Candidate 2: Obj = 126.8993, schedule = [1 1 1 1 1 1 0 1 0 2 0 2 1 0 0 2 0 1 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  1  1  1  1 -1  1  2  1  0  0  1  2  1  0  1  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  2  0  2 -1  2  0  2  1 -1  1  1  2  0  1  7]
Best objective value found so far: 114.9636
Total points evaluated: 135
Iteration 17 completed in 3.84 seconds.

--- Iteration 18/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  1  2  0  0  1  2  0  1  1  1  0  2 -1  2  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  0  0  2  1  1  0  1  0  1  2 -1  2  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  1  2  1 -1  1  2  1  0  1  1  0  2 -1  2  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  2  0  1  1  0  2  1  1  0  1  0  2 -1  2  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  1 -1  1  2  0  1  1  1  0  2 -1  2  7]
Best objective value found so far: 114.9636
Total points evaluated: 140
Iteration 18 completed in 4.55 seconds.

--- Iteration 19/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  1  2 -1  2  1  0  1  0  1  1  2 -1  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1  0  0  1  1  2 -1  1  1  2 -1  1  8]
  Candidate 2: Obj = 134.0474, schedule = [1 2 0 1 0 1 2 0 0 1 2 0 1 1 1 1 0 0 1 9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  0  1  2 -1  2  1  1  0  0  1  1  1  1  1  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  0  1  1  0  1  2  0  1  1  1  0  1  1  8]
Best objective value found so far: 114.9636
Total points evaluated: 145
Iteration 19 completed in 5.49 seconds.

--- Iteration 20/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  0  1  0  1  2  0  0  1  1  2  0  1  0  1  2 -1  1  8]
  Candidate 1: Obj = 132.0745, schedule = [1 1 2 0 0 1 2 0 0 1 1 1 2 0 0 1 1 1 0 9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  1  2  0  0  1  1  1  0  1  1  1  0  2  7]
  Candidate 3: Obj = 123.1035, schedule = [2 1 2 0 0 1 1 1 0 1 2 1 0 0 1 1 1 0 1 8]
  Candidate 4: Obj = 130.1952, schedule = [1 1 1 1 0 1 1 1 0 2 0 1 1 1 0 1 1 0 2 8]
Best objective value found so far: 114.9636
Total points evaluated: 150
Iteration 20 completed in 4.79 seconds.

--- Iteration 21/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  0  1  2  1  0  0  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  1  0  1  2  0  1  1  0  1  2 -1  1  1  2  0  0  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  2  0  0  1  2  1  0  1  1  1  0  1  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  1  1  0  0  1  1  1  1  1  0  2  0  0  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  1  2  0  0  2  1  0  1  1  0  1  1  0  1  8]
Best objective value found so far: 114.9636
Total points evaluated: 155
Iteration 21 completed in 6.42 seconds.

--- Iteration 22/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  1  2  0  0  1  1  2  0  1  0  1  2 -1  2  7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  1  2  1 -1  2  1  1  0  0  1  1  1  1  0  9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  0  2  1 -1  2  1  0  2  0  1  0  1  0  2  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  1  0  1  1  1  0  2  0  1  1  0  1  0  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  1  1  0  1  1  0  0  1  2  0  2 -1  2  1  1  0  1  7]
Best objective value found so far: 114.9636
Total points evaluated: 160
Iteration 22 completed in 4.67 seconds.

--- Iteration 23/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  2  0  1  0  2 -1  2  0  2  1  0  1  0  2  0  1  8]
  Candidate 1: Obj = 126.1819, schedule = [2 1 0 2 0 1 0 2 0 0 2 1 0 1 1 0 2 0 1 8]
  Candidate 2: Obj = 131.9391, schedule = [2 1 0 2 0 1 0 2 0 1 0 2 1 0 1 0 2 0 0 9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  0  2 -1  2  0  2  1  0  1  0  2  0  1  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  2  1  0  1  1  0  2  0  1  8]
Best objective value found so far: 114.9636
Total points evaluated: 165
Iteration 23 completed in 4.24 seconds.

--- Iteration 24/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  1  2 -1  2  0  2  0  0  1  1  2 -1  2  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  2  0  0  2  0  2  1  0  0  1  2 -1  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  1  1  0  2  0  1  1  0  2  0  0  1  1  2 -1  2  8]
  Candidate 3: Obj = 132.0435, schedule = [1 2 0 1 0 1 1 1 0 2 0 2 0 0 1 1 1 0 2 8]
  Candidate 4: Obj = 128.0151, schedule = [1 2 0 1 0 1 2 0 0 1 1 2 0 0 1 1 1 1 1 8]
Best objective value found so far: 114.9636
Total points evaluated: 170
Iteration 24 completed in 3.59 seconds.

--- Iteration 25/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  1  0  1  1  1  1  1 -1  1  2  1 -1  2  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  2  0  2 -1  2  1  0  2  0  0  2  1 -1  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  2  1  0  0  2  1  0  2  0  1  1  1 -1  2  8]
  Candidate 3: Obj = 126.7964, schedule = [2 1 0 1 1 1 0 1 0 2 0 1 2 0 0 2 1 0 1 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  0  2 -1  2  0  1  2  0  0  2  1  0  1  8]
Best objective value found so far: 114.9636
Total points evaluated: 175
Iteration 25 completed in 4.78 seconds.

--- Optimization Finished ---
Total evaluations: 175
Best Objective Value Found: 114.96364292044709
Best U vector Found: [0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1]

--- Verification ---
Is the best U feasible? True
Resulting Y vector for best U: [2 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 2 0 1 7]
Objective value (recalculated): 114.9636</code></pre>
</div>
</div>
</section>
<section id="experiment-2-cbo-with-lower-confidence-bound-lcb---fixed-kappa" class="level4" data-number="6.4.6.5">
<h4 data-number="6.4.6.5" class="anchored" data-anchor-id="experiment-2-cbo-with-lower-confidence-bound-lcb---fixed-kappa"><span class="header-section-number">6.4.6.5</span> 5. Experiment 2: CBO with Lower Confidence Bound (LCB) - Fixed Kappa</h4>
<p>Applies the methodology from <span class="citation" data-cites="deshwal_bayesian_2023">Deshwal et al. (<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">2023</a>)</span> using LCB with fixed <span class="math inline">\(\kappa\)</span>.</p>
<div id="8822f3f6" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Helper Functions ---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># --- get_fitted_model function remains the same ---</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_fitted_model(train_X_embedded_scaled, train_Y, m):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... (implementation is unchanged) ...</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_Y.ndim <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> train_Y.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>: train_Y <span class="op">=</span> train_Y.ravel()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">=</span> ConstantKernel(<span class="fl">1.0</span>, constant_value_bounds<span class="op">=</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>)) <span class="op">*</span> <span class="op">\</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>             Matern(length_scale<span class="op">=</span>np.ones(m), length_scale_bounds<span class="op">=</span>(<span class="fl">1e-2</span>, <span class="fl">1e2</span>), nu<span class="op">=</span><span class="fl">2.5</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>             WhiteKernel(noise_level<span class="op">=</span><span class="fl">1e-10</span>, <span class="co"># Small value for numerical stability</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                         noise_level_bounds<span class="op">=</span><span class="st">"fixed"</span>) <span class="co"># Bounds for noise optimization</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    gp_model <span class="op">=</span> GaussianProcessRegressor(kernel<span class="op">=</span>kernel, alpha<span class="op">=</span><span class="fl">1e-10</span>, n_restarts_optimizer<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    gp_model.fit(train_X_embedded_scaled, train_Y)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gp_model</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lower_confidence_bound(mu, sigma, kappa<span class="op">=</span><span class="fl">2.576</span>):</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the Lower Confidence Bound (LCB) acquisition function.</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes maximization of this value guides the search (since mu is neg objective).</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Higher LCB means lower predicted objective or lower penalty for uncertainty.</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co">    mu, sigma: Predicted mean and standard deviation (NumPy arrays).</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">    kappa: Controls the balance between exploitation (high mu -&gt; low original objective)</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co">           and exploration (low sigma).</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure sigma is non-negative</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.maximum(sigma, <span class="dv">0</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mu <span class="op">-</span> kappa <span class="op">*</span> sigma <span class="co"># &lt;&lt;&lt; Sign flipped from UCB</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, kappa):</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Optimizes LCB acquisition function by sampling random binary candidates,</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co">    embedding, SCALING, predicting with GP, and calculating LCB.</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Selects the top q candidates based on LCB.</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns candidates as a numpy array (q x T).</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> dictionary_A.shape[<span class="dv">0</span>]</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Generate Random Binary Candidates</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    candidate_u_vectors_np <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>(num_candidates, T))</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Embed the Candidates</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_np <span class="op">=</span> embed_batch(candidate_u_vectors_np, dictionary_A)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Scale the Embedded Candidates</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_scaled_np <span class="op">=</span> scaler.transform(embedded_candidates_np)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Predict Mean and Std Dev using the GP Model</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    mu, std <span class="op">=</span> gp_model.predict(embedded_candidates_scaled_np, return_std<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Calculate Acquisition Function (Lower Confidence Bound) &lt;&lt;&lt; CHANGED HERE</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    acq_values <span class="op">=</span> lower_confidence_bound(mu, std, kappa<span class="op">=</span>kappa) <span class="co"># Use LCB</span></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Select Top Candidates (based on highest LCB) &lt;&lt;&lt; COMMENT UPDATED</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We maximize LCB = mu - kappa*sigma, where mu is neg_objective</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> np.argsort(acq_values)[<span class="op">-</span>q:]</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> top_indices[::<span class="op">-</span><span class="dv">1</span>] <span class="co"># Ensure descending order of LCB</span></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> candidate_u_vectors_np[top_indices, :]</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Loop ---</span></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>KAPPA <span class="op">=</span> <span class="fl">2.576</span> <span class="co"># Exploration parameter for LCB. Adjust as needed.</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>N_INITIAL <span class="op">=</span> <span class="dv">49</span> <span class="co"># The initial schedule will always be included</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>N_ITERATIONS <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE_q <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>NUM_CANDIDATES_Acqf <span class="op">=</span> T<span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">1024</span> <span class="co"># Might need more for higher T</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> math.ceil(T<span class="op">/</span><span class="dv">4</span>) <span class="co"># Dimension of the embedding space</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Store evaluated points (using NumPy arrays)</span></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>evaluated_U_np_list <span class="op">=</span> [] <span class="co"># List to store evaluated U vectors (binary)</span></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>evaluated_f_vals <span class="op">=</span> []    <span class="co"># List to store raw objective values (lower is better)</span></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>train_Y_list <span class="op">=</span> []        <span class="co"># List to store NEGATED objective values for GP (higher is better)</span></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialization</span></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> U_init <span class="kw">in</span> initial_candidates:</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>    f_val <span class="op">=</span> evaluate_objective(U_init, X, v_star, convolutions, d, w)</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>    neg_f_val <span class="op">=</span> <span class="op">-</span>f_val</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.append(U_init)</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>    evaluated_f_vals.append(f_val)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>    train_Y_list.append(neg_f_val)</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert lists to NumPy arrays for GP fitting</span></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Keep as column vector initially</span></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>best_obj_so_far <span class="op">=</span> <span class="bu">min</span>(evaluated_f_vals) <span class="cf">if</span> evaluated_f_vals <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>initial_best_obj_so_far_lcb <span class="op">=</span> best_obj_so_far <span class="co"># Saved for reporting results</span></span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial best objective value: </span><span class="sc">{</span>best_obj_so_far<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> np.isfinite(best_obj_so_far):</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span>(<span class="st">"Warning: Initial best objective is infinite, possibly all initial points were infeasible."</span>)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. BO Iterations</span></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(N_ITERATIONS):</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>N_ITERATIONS<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># a. Generate dictionary A (remains the same)</span></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>    current_dictionary_A <span class="op">=</span> generate_diverse_random_dictionary(T, m)</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># b. Embed ALL evaluated U vectors (remains the same)</span></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> evaluated_U_np_list: <span class="cf">continue</span></span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_array <span class="op">=</span> np.array(evaluated_U_np_list)</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>    embedded_train_X <span class="op">=</span> embed_batch(evaluated_U_np_array, current_dictionary_A)</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c. Scale the embedded training data (remains the same)</span></span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>: embedded_train_X_scaled <span class="op">=</span> scaler.fit_transform(embedded_train_X)</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: embedded_train_X_scaled <span class="op">=</span> embedded_train_X</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure train_Y is NumPy array</span></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>    train_Y_for_fit <span class="op">=</span> np.array(train_Y_list)</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># d. Fit GP Model (remains the same)</span></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Fitting GP model..."</span>)</span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X_scaled.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> train_Y_for_fit.shape[<span class="dv">0</span>] <span class="op">==</span> embedded_train_X_scaled.shape[<span class="dv">0</span>]:</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>        gp_model <span class="op">=</span> get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)</span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"GP model fitted."</span>)</span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration."</span>)</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e. Determine current best neg value (useful for tracking, not directly used in LCB calculation)</span></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a>    current_best_neg_f_val <span class="op">=</span> np.<span class="bu">max</span>(train_Y_for_fit) <span class="cf">if</span> train_Y_for_fit.size <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_best_neg_f_val <span class="op">&lt;=</span> <span class="op">-</span>LARGE_PENALTY <span class="op">/</span> <span class="dv">2</span> <span class="kw">and</span> np.isfinite(current_best_neg_f_val):</span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Current best NEGATIVE objective value (</span><span class="sc">{</span>current_best_neg_f_val<span class="sc">:.2f}</span><span class="ss">) is very low (likely from penalties)."</span>)</span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>    <span class="co"># f. Optimize Acquisition Function (LCB) &lt;&lt;&lt; MODIFIED CALL &amp; COMMENT</span></span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Optimizing acquisition function (LCB)..."</span>) <span class="co"># Comment updated</span></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a>    next_U_candidates_np <span class="op">=</span> optimize_acqf_discrete_via_embedding(</span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>        gp_model<span class="op">=</span>gp_model,</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>        scaler<span class="op">=</span>scaler,</span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>        dictionary_A<span class="op">=</span>current_dictionary_A,</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>        T<span class="op">=</span>T,</span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a>        q<span class="op">=</span>BATCH_SIZE_q,</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a>        num_candidates<span class="op">=</span>NUM_CANDIDATES_Acqf,</span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a>        kappa<span class="op">=</span>KAPPA <span class="co"># Pass kappa</span></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Selected </span><span class="sc">{</span>next_U_candidates_np<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> candidate(s)."</span>)</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>    <span class="co"># g. Evaluate Objective (remains the same)</span></span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a>    newly_evaluated_U <span class="op">=</span> []<span class="op">;</span> newly_evaluated_f <span class="op">=</span> []<span class="op">;</span> newly_evaluated_neg_f <span class="op">=</span> []</span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(next_U_candidates_np.shape[<span class="dv">0</span>]):</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a>        next_U <span class="op">=</span> next_U_candidates_np[i, :]</span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>        already_evaluated <span class="op">=</span> <span class="bu">any</span>(np.array_equal(next_U, u) <span class="cf">for</span> u <span class="kw">in</span> evaluated_U_np_list)</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> already_evaluated: <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> was already evaluated. Skipping."</span>)<span class="op">;</span> <span class="cf">continue</span></span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>        next_f <span class="op">=</span> evaluate_objective(next_U, X, v_star, convolutions, d, w)</span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>        next_neg_f <span class="op">=</span> <span class="op">-</span>next_f</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a>        V_sum <span class="op">=</span> np.<span class="bu">sum</span>(v_star[next_U <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a>        Y <span class="op">=</span> X <span class="op">+</span> V_sum</span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: Obj = </span><span class="sc">{</span>next_f<span class="sc">:.4f}</span><span class="ss">, schedule = </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a>        newly_evaluated_U.append(next_U)<span class="op">;</span> newly_evaluated_f.append(next_f)<span class="op">;</span> newly_evaluated_neg_f.append(next_neg_f)</span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> next_f <span class="op">&lt;</span> best_obj_so_far: best_obj_so_far <span class="op">=</span> next_f</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># h. Augment Dataset (remains the same)</span></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.extend(newly_evaluated_U)<span class="op">;</span> evaluated_f_vals.extend(newly_evaluated_f)<span class="op">;</span> train_Y_list.extend(newly_evaluated_neg_f)</span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a>    train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a>    iter_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best objective value found so far: </span><span class="sc">{</span>best_obj_so_far<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total points evaluated: </span><span class="sc">{</span><span class="bu">len</span>(evaluated_f_vals)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> completed in </span><span class="sc">{</span>iter_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Results ---</span></span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Optimization Finished ---"</span>)</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> evaluated_f_vals: <span class="bu">print</span>(<span class="st">"No points were successfully evaluated."</span>)</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a>    final_best_idx_lcb <span class="op">=</span> np.argmin(evaluated_f_vals)</span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a>    final_best_U_lcb <span class="op">=</span> evaluated_U_np_list[final_best_idx_lcb]</span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a>    final_best_f_lcb <span class="op">=</span> evaluated_f_vals[final_best_idx_lcb]</span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a>    nr_evaluated_f_vals_lcb <span class="op">=</span> <span class="bu">len</span>(evaluated_f_vals) <span class="co"># Saved for reporting results</span></span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total evaluations: </span><span class="sc">{</span>nr_evaluated_f_vals_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Objective Value Found: </span><span class="sc">{</span>final_best_f_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best U vector Found: </span><span class="sc">{</span>final_best_U_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verification</span></span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a>    V_sum_best <span class="op">=</span> np.<span class="bu">sum</span>(v_star[final_best_U_lcb <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a>    Y_best_lcb <span class="op">=</span> X <span class="op">+</span> V_sum_best</span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>    is_feasible <span class="op">=</span> np.<span class="bu">all</span>(Y_best_lcb <span class="op">&gt;=</span> <span class="dv">0</span>)</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a>    recalculated_obj <span class="op">=</span> LARGE_PENALTY</span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a>        ewt, esp <span class="op">=</span> calculate_objective_serv_time_lookup(Y_best_lcb, d, convolutions)</span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a>        recalculated_obj <span class="op">=</span> w <span class="op">*</span> ewt <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> esp</span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Verification ---"</span>)</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Is the best U feasible? </span><span class="sc">{</span>is_feasible<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Resulting Y vector for best U: </span><span class="sc">{</span>Y_best_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Objective value (recalculated): </span><span class="sc">{</span>recalculated_obj<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> np.isclose(final_best_f_lcb, recalculated_obj): <span class="bu">print</span>(<span class="ss">f"Warning: Stored best objective (</span><span class="sc">{</span>final_best_f<span class="sc">:.4f}</span><span class="ss">) does not match recalculation (</span><span class="sc">{</span>recalculated_obj<span class="sc">:.4f}</span><span class="ss">)!"</span>)</span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> final_best_f_lcb <span class="op">&lt;</span> LARGE_PENALTY: <span class="bu">print</span>(<span class="ss">f"Warning: Best objective (</span><span class="sc">{</span>final_best_f_lcb<span class="sc">:.4f}</span><span class="ss">) is not the penalty value, but feasibility check failed."</span>)<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f"Resulting Y vector (infeasible): </span><span class="sc">{</span>Y_best_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"Best solution found corresponds to an infeasible penalty value."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial best objective value: 118.87100166955729

--- Iteration 1/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  1  0  0  2  1  1  0  1  0  1  2 -1  1  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  0  2 -1  1  1  2  0  0  1  1  1  1  1  8]
  Candidate 2: Obj = 133.2394, schedule = [1 2 0 2 0 1 1 0 0 2 1 0 1 0 2 0 1 1 0 9]
  Candidate 3: Obj = 134.0944, schedule = [2 1 1 0 0 2 0 1 0 2 0 2 0 0 2 1 0 1 0 9]
  Candidate 4: Obj = 135.2522, schedule = [2 1 1 1 0 1 1 0 0 1 2 1 0 0 1 1 1 0 1 9]
Best objective value found so far: 118.8710
Total points evaluated: 55
Iteration 1 completed in 4.63 seconds.

--- Iteration 2/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 129.3169, schedule = [1 2 1 1 0 0 1 1 0 2 1 1 0 0 1 2 1 0 1 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  0  1  1  0  2  1  1  1 -1  1  2  1  0  1  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  2  0  2 -1  2  1  1  1  0  0  1  2  0  1  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  0  2  0  0  1  2 -1  2  1  1  1 -1  1  2  1  0  1  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  0  1  2 -1  2  1  1  1 -1  1  1  2  0  1  7]
Best objective value found so far: 118.8710
Total points evaluated: 60
Iteration 2 completed in 4.04 seconds.

--- Iteration 3/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  0  2  1 -1  2  0  1  1  1  0  2  0  1  0  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  2 -1  2  1  1  1  0  1  1  0  1  0  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  2  1  0  1  1  1  1  0  1  1  1  0  1  0  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  1  1  1  0  2  0  1  2 -1  2  0  2  0  1  7]
  Candidate 4: Obj = 117.6316, schedule = [2 1 1 1 0 1 2 0 0 1 2 0 1 0 1 2 1 0 1 7]
Best objective value found so far: 117.6316
Total points evaluated: 65
Iteration 3 completed in 4.27 seconds.

--- Iteration 4/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  1  0  1  0  2  0  0  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  1  1  1  1  0  0  8]
  Candidate 2: Obj = 117.4455, schedule = [2 1 1 2 0 1 1 0 1 0 2 0 2 0 1 0 2 0 1 7]
  Candidate 3: Obj = 118.6866, schedule = [3 0 1 2 0 1 1 0 1 0 2 1 0 1 0 2 0 1 1 7]
  Candidate 4: Obj = 115.6020, schedule = [2 1 2 0 1 1 0 1 1 0 2 0 2 0 1 1 1 0 1 7]
Best objective value found so far: 115.6020
Total points evaluated: 70
Iteration 4 completed in 4.70 seconds.

--- Iteration 5/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  1 -1  1  1  2  1  0  1  0  2  0  1  7]
  Candidate 1: Obj = 120.3275, schedule = [3 1 1 1 0 1 1 1 0 0 1 1 1 0 2 1 0 1 1 7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  1  0  1  1  1  1 -1  2  0  2  1 -1  2  1  0  1  0  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  2  1 -1  2  1  1  1 -1  2  0  1  0  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  1  0  1  1  0  0  2  0  2  1 -1  2  0  2  0  1  8]
Best objective value found so far: 115.6020
Total points evaluated: 75
Iteration 5 completed in 3.88 seconds.

--- Iteration 6/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  1  0  1  0  1  1  1  0  1  2  1  0  1  8]
  Candidate 1: Obj = 128.5334, schedule = [2 1 1 0 0 1 2 1 0 0 1 1 1 0 1 2 1 0 1 8]
  Candidate 2: Obj = 127.5458, schedule = [2 0 2 0 0 2 1 0 1 1 0 1 1 0 1 2 1 0 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  1  2  0  1  1  1  0  2 -1  1  2  1  0  1  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  0  1  1  0  1  1  0  1  2  1 -1  1  9]
Best objective value found so far: 115.6020
Total points evaluated: 80
Iteration 6 completed in 3.95 seconds.

--- Iteration 7/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  0  1  1  1  0  1  1  0  1  2 -1  2  0  1  1  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  0  2 -1  2  0  1  2  0  0  2  1  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  1 -1  2  0  1  2 -1  1  2  1  0  1  8]
  Candidate 3: Obj = 125.7593, schedule = [2 0 2 0 0 2 0 1 1 1 0 1 2 0 1 0 2 0 1 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  0  2  0  1  0  1  2 -1  1  2  1  0  1  8]
Best objective value found so far: 115.6020
Total points evaluated: 85
Iteration 7 completed in 4.11 seconds.

--- Iteration 8/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 123.2298, schedule = [2 1 2 0 1 0 2 0 1 0 1 1 2 0 0 1 1 0 1 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  0  2  0  1  0  2  0  2 -1  1  1  1  0  1  8]
  Candidate 2: Obj = 123.1074, schedule = [2 1 2 0 0 1 2 0 1 1 0 1 2 0 0 1 1 0 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  0  1  0  1  2  1 -1  1  1  1  0  1  8]
  Candidate 4: Obj = 124.3234, schedule = [2 1 2 0 0 2 1 0 1 0 2 1 0 0 1 1 1 0 1 8]
Best objective value found so far: 115.6020
Total points evaluated: 90
Iteration 8 completed in 3.96 seconds.

--- Iteration 9/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 130.8021, schedule = [1 2 0 2 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 9]
  Candidate 1: Obj = 130.5450, schedule = [2 1 0 2 0 1 1 1 0 1 0 1 2 0 1 0 1 1 0 9]
  Candidate 2: Obj = 124.2772, schedule = [2 1 0 2 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 8]
  Candidate 3: Obj = 126.1602, schedule = [1 2 0 2 0 1 1 1 0 1 0 2 0 1 0 1 2 0 1 8]
  Candidate 4: Obj = 132.6468, schedule = [2 1 0 2 0 1 1 1 0 0 2 1 1 0 0 1 1 1 0 9]
Best objective value found so far: 115.6020
Total points evaluated: 95
Iteration 9 completed in 4.18 seconds.

--- Iteration 10/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  2 -1  2  1  0  1  1  0  2  1  0  1  1  0  1  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  1  2  1  0  1  0  2  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  1  2  1  0  1  0  2  0  1  8]
  Candidate 3: Obj = 128.4867, schedule = [1 1 2 0 0 2 1 1 0 0 2 1 1 0 0 2 1 0 1 8]
  Candidate 4: Obj = 130.2438, schedule = [1 1 1 1 0 2 1 1 0 1 1 1 1 0 1 1 1 0 0 9]
Best objective value found so far: 115.6020
Total points evaluated: 100
Iteration 10 completed in 5.25 seconds.

--- Iteration 11/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 130.5600, schedule = [2 0 1 1 1 0 2 0 1 1 0 1 1 1 0 2 0 0 2 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  2  0  1  1  1  1  0  0  1  1  1  0  2  8]
  Candidate 2: Obj = 134.2707, schedule = [2 0 1 1 0 2 1 0 1 1 1 1 0 0 1 2 0 0 1 9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  1  2  0  1  0  1  2  1 -1  1  2  1 -1  1  9]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  1  0  1  2  1  0  0  2  0  0  2  8]
Best objective value found so far: 115.6020
Total points evaluated: 105
Iteration 11 completed in 4.73 seconds.

--- Iteration 12/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  1  1  0  1  1  1  0  0  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  2  1 -1  2  1  0  2  0  1  1  1  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  1  1  1  0  1  0  2  1 -1  2  1  1  0  1  7]
  Candidate 3: Obj = 125.1870, schedule = [1 2 0 2 0 0 2 1 0 1 1 1 1 0 1 0 2 0 1 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  1  1 -1  2  1  0  2  0  1  1  1  0  1  8]
Best objective value found so far: 115.6020
Total points evaluated: 110
Iteration 12 completed in 5.29 seconds.

--- Iteration 13/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 131.4070, schedule = [2 1 1 0 1 0 1 1 0 1 1 2 0 1 0 1 1 1 0 9]
  Candidate 1: Obj = 122.3589, schedule = [2 2 1 0 1 0 1 2 0 0 1 2 0 1 0 1 1 1 0 8]
  Candidate 2: Obj = 131.4070, schedule = [2 1 1 0 1 0 1 1 0 1 1 2 0 1 0 1 1 1 0 9]
  Candidate 3: Obj = 131.4662, schedule = [2 1 1 0 1 0 1 1 1 0 1 2 0 0 1 1 1 1 0 9]
  Candidate 4: Obj = 122.4985, schedule = [3 1 0 1 1 0 1 2 0 0 1 2 0 1 0 1 1 0 2 7]
Best objective value found so far: 115.6020
Total points evaluated: 115
Iteration 13 completed in 8.04 seconds.

--- Iteration 14/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 122.3147, schedule = [3 0 2 0 0 1 2 0 0 1 2 0 1 1 1 1 0 1 0 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  1  1  2 -1  1  1  1  1  0  2  1  0  1  0  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  1 -1  2  1  0  1  0  2  0  1  1  0  8]
  Candidate 3: Obj = 115.1129, schedule = [2 1 1 1 0 1 2 0 0 1 2 0 1 1 1 1 1 0 1 7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  1  2  0  0  1  1  2  0  0  2  0  1  1  0  8]
Best objective value found so far: 115.1129
Total points evaluated: 120
Iteration 14 completed in 7.87 seconds.

--- Iteration 15/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 123.3545, schedule = [2 1 2 0 0 2 1 1 0 1 0 1 1 0 2 0 2 0 0 8]
  Candidate 1: Obj = 118.9808, schedule = [2 1 2 0 0 2 1 1 0 0 1 1 1 0 2 0 2 0 1 7]
  Candidate 2: Obj = 124.7961, schedule = [3 1 0 2 0 0 2 0 0 2 0 2 0 1 0 2 0 0 2 7]
  Candidate 3: Obj = 122.3054, schedule = [2 2 0 2 0 0 1 1 1 1 1 1 1 0 0 1 1 0 2 7]
  Candidate 4: Obj = 133.7135, schedule = [2 0 2 0 0 2 1 0 0 2 0 1 1 0 2 1 0 1 0 9]
Best objective value found so far: 115.1129
Total points evaluated: 125
Iteration 15 completed in 6.16 seconds.

--- Iteration 16/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 124.3527, schedule = [3 1 0 2 0 0 2 0 1 1 0 2 0 0 1 1 2 0 0 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  2  0  0  1  2  1  1 -1  2  0  2 -1  2  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  1  1  1  0  2  1  0  0  2  0  2 -1  1  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  0  2 -1  2  1  1  0  0  1  1  2  0  0  8]
  Candidate 4: Obj = 132.6420, schedule = [2 0 1 2 0 0 1 1 0 1 2 0 1 0 1 2 0 0 2 8]
Best objective value found so far: 115.1129
Total points evaluated: 130
Iteration 16 completed in 6.82 seconds.

--- Iteration 17/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  1  1  0  1  0  1  2  0  1  0  1  1  2 -1  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  0  1  1  1  0  1  0  1  2  0  1  0  1  1  2 -1  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  0  1  1  0  1  1  1  0  2  1  1  0  0  1  2 -1  1  8]
  Candidate 3: Obj = 123.5410, schedule = [2 2 0 1 1 1 1 0 0 1 2 0 1 1 0 1 1 0 1 8]
  Candidate 4: Obj = 122.4941, schedule = [2 2 0 1 1 0 1 1 1 1 0 1 2 0 0 1 1 0 1 8]
Best objective value found so far: 115.1129
Total points evaluated: 135
Iteration 17 completed in 7.43 seconds.

--- Iteration 18/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  1  0  1  0  2  1 -1  2  0  1  1  0  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  2 -1  2  1  1  0  1  0  2  0  1  0  1  1  1  0  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  1  1 -1  2  1  1  0  0  1  1  1  1  0  2  0  1  0  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  0  2  0  1  0  1  1  0  1  2  0  1  0  9]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  0  2 -1  2  1  1  0  0  1  1  1  0  2  1  0  1  0  8]
Best objective value found so far: 115.1129
Total points evaluated: 140
Iteration 18 completed in 8.02 seconds.

--- Iteration 19/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  1  0  0  2  1  1 -1  2  1  1  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  1  0  1  1  2 -1  1  1  1  1  0  1  1  1  1  1  7]
  Candidate 2: Obj = 132.4621, schedule = [2 1 1 0 1 1 0 2 0 0 2 1 1 0 1 1 0 0 2 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  1  2 -1  2  1  0  1  0  2  0  1  0  1  8]
  Candidate 4: Obj = 133.4902, schedule = [1 1 1 1 0 1 2 0 0 2 0 1 1 0 2 0 1 0 1 9]
Best objective value found so far: 115.1129
Total points evaluated: 145
Iteration 19 completed in 6.84 seconds.

--- Iteration 20/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  2  0  1  0  1  0  2  1  1  1 -1  2  1  0  1  0  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  1  2  0  1  0  2 -1  2  0  2  0  1  0  1  1  0  2  8]
  Candidate 2: Obj = 126.6556, schedule = [1 2 0 1 0 1 1 2 0 1 1 0 1 0 2 1 0 1 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  0  0  2  1  1  0  0  1  1  1  1  0  1  2 -1  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  2  1  0  0  1  2 -1  2  0  1  1  0  2  1  0  1  1  7]
Best objective value found so far: 115.1129
Total points evaluated: 150
Iteration 20 completed in 8.16 seconds.

--- Iteration 21/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 123.3261, schedule = [2 1 2 1 0 1 0 2 0 0 1 1 2 0 1 0 2 0 0 8]
  Candidate 1: Obj = 123.2211, schedule = [2 1 2 1 0 1 0 2 0 0 1 2 0 1 1 0 2 0 0 8]
  Candidate 2: Obj = 122.8762, schedule = [2 1 2 1 0 1 1 1 0 0 1 1 2 0 1 0 1 1 0 8]
  Candidate 3: Obj = 132.0113, schedule = [1 1 2 1 0 1 0 2 0 0 1 1 2 0 1 0 1 0 2 8]
  Candidate 4: Obj = 118.8922, schedule = [2 2 0 2 0 1 1 0 0 1 1 2 1 0 1 0 1 1 1 7]
Best objective value found so far: 115.1129
Total points evaluated: 155
Iteration 21 completed in 7.71 seconds.

--- Iteration 22/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 124.9031, schedule = [3 0 2 1 0 0 2 1 0 1 1 0 1 0 2 0 2 0 0 8]
  Candidate 1: Obj = 120.0952, schedule = [3 0 2 1 0 0 2 1 0 1 0 1 1 0 2 0 2 0 1 7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  0  1  1  1  0  2 -1  1  2  1  0  0  8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1  0  1  1  0  2 -1  2  0  1  1  0  8]
  Candidate 4: Obj = 119.4426, schedule = [2 1 2 1 0 0 2 1 0 1 1 0 1 0 2 0 2 0 1 7]
Best objective value found so far: 115.1129
Total points evaluated: 160
Iteration 22 completed in 6.18 seconds.

--- Iteration 23/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  1  1  0  1  0  2  0  2 -1  2  0  2  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  2 -1  2  1  1  0  1  1  1  0  1  1  0  2  0  1  7]
  Candidate 2: Obj = 123.1513, schedule = [1 1 1 1 1 1 0 2 0 1 0 2 0 1 1 1 0 1 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  1  1  1  1  0  1  1  1  1  1 -1  2  0  2 -1  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  2  1  1  0  1  1  0  1  1  1  1  1 -1  2  8]
Best objective value found so far: 115.1129
Total points evaluated: 165
Iteration 23 completed in 4.94 seconds.

--- Iteration 24/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 125.8798, schedule = [2 1 1 1 0 0 1 1 1 1 1 1 1 0 0 2 1 0 1 8]
  Candidate 1: Obj = 127.9569, schedule = [2 1 1 1 0 0 2 0 1 0 2 1 1 0 0 2 1 0 1 8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  2  0  1  1  1  1  1  0  0  2  1 -1  2  8]
  Candidate 3: Obj = 127.9569, schedule = [2 1 1 1 0 0 2 0 1 0 2 1 1 0 0 2 1 0 1 8]
  Candidate 4: Obj = 126.5368, schedule = [2 1 1 1 0 0 2 0 1 1 1 1 1 0 0 1 1 1 1 8]
Best objective value found so far: 115.1129
Total points evaluated: 170
Iteration 24 completed in 6.99 seconds.

--- Iteration 25/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  0  2  1 -1  2  0  2  1 -1  1  2  1  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  1  0  1  1  1  1 -1  1  1  2  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  1  0  1  1  1  1 -1  1  2  1  0  1  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  0  2  1  0  1  1  1  1 -1  1  2  1  0  1  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  1 -1  2  1  1  0  1  1  1  1 -1  1  2  1  0  0  9]
Best objective value found so far: 115.1129
Total points evaluated: 175
Iteration 25 completed in 6.32 seconds.

--- Optimization Finished ---
Total evaluations: 175
Best Objective Value Found: 115.11287490459011
Best U vector Found: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1]

--- Verification ---
Is the best U feasible? True
Resulting Y vector for best U: [2 1 1 1 0 1 2 0 0 1 2 0 1 1 1 1 1 0 1 7]
Objective value (recalculated): 115.1129</code></pre>
</div>
</div>
</section>
<section id="experiment-3-cbo-with-lcb-and-wavelet-dictionary." class="level4" data-number="6.4.6.6">
<h4 data-number="6.4.6.6" class="anchored" data-anchor-id="experiment-3-cbo-with-lcb-and-wavelet-dictionary."><span class="header-section-number">6.4.6.6</span> 6. Experiment 3: CBO with LCB and wavelet dictionary.</h4>
<div id="aaade903" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Helper Functions ---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># --- get_fitted_model function remains the same ---</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_fitted_model(train_X_embedded_scaled, train_Y, m):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... (implementation is unchanged) ...</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_Y.ndim <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> train_Y.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>: train_Y <span class="op">=</span> train_Y.ravel()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">=</span> ConstantKernel(<span class="fl">1.0</span>, constant_value_bounds<span class="op">=</span>(<span class="fl">1e-3</span>, <span class="fl">1e3</span>)) <span class="op">*</span> <span class="op">\</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>             Matern(length_scale<span class="op">=</span>np.ones(m), length_scale_bounds<span class="op">=</span>(<span class="fl">1e-2</span>, <span class="fl">1e2</span>), nu<span class="op">=</span><span class="fl">2.5</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>             WhiteKernel(noise_level<span class="op">=</span><span class="fl">1e-10</span>, <span class="co"># Small value for numerical stability</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                         noise_level_bounds<span class="op">=</span><span class="st">"fixed"</span>) <span class="co"># Bounds for noise optimization</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    gp_model <span class="op">=</span> GaussianProcessRegressor(kernel<span class="op">=</span>kernel, alpha<span class="op">=</span><span class="fl">1e-10</span>, n_restarts_optimizer<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    gp_model.fit(train_X_embedded_scaled, train_Y)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gp_model</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lower_confidence_bound(mu, sigma, kappa<span class="op">=</span><span class="fl">2.576</span>):</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the Lower Confidence Bound (LCB) acquisition function.</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes maximization of this value guides the search (since mu is neg objective).</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Higher LCB means lower predicted objective or lower penalty for uncertainty.</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co">    mu, sigma: Predicted mean and standard deviation (NumPy arrays).</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co">    kappa: Controls the balance between exploitation (high mu -&gt; low original objective)</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co">           and exploration (low sigma).</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure sigma is non-negative</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.maximum(sigma, <span class="dv">0</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mu <span class="op">-</span> kappa <span class="op">*</span> sigma <span class="co"># &lt;&lt;&lt; Sign flipped from UCB</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, kappa):</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Optimizes LCB acquisition function by sampling random binary candidates,</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co">    embedding, SCALING, predicting with GP, and calculating LCB.</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Selects the top q candidates based on LCB.</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns candidates as a numpy array (q x T).</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> dictionary_A.shape[<span class="dv">0</span>]</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Generate Random Binary Candidates</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>    candidate_u_vectors_np <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>(num_candidates, T))</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Embed the Candidates</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_np <span class="op">=</span> embed_batch(candidate_u_vectors_np, dictionary_A)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Scale the Embedded Candidates</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    embedded_candidates_scaled_np <span class="op">=</span> scaler.transform(embedded_candidates_np)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Predict Mean and Std Dev using the GP Model</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    mu, std <span class="op">=</span> gp_model.predict(embedded_candidates_scaled_np, return_std<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Calculate Acquisition Function (Lower Confidence Bound) &lt;&lt;&lt; CHANGED HERE</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    acq_values <span class="op">=</span> lower_confidence_bound(mu, std, kappa<span class="op">=</span>kappa) <span class="co"># Use LCB</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Select Top Candidates (based on highest LCB) &lt;&lt;&lt; COMMENT UPDATED</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We maximize LCB = mu - kappa*sigma, where mu is neg_objective</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> np.argsort(acq_values)[<span class="op">-</span>q:]</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> top_indices[::<span class="op">-</span><span class="dv">1</span>] <span class="co"># Ensure descending order of LCB</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> candidate_u_vectors_np[top_indices, :]</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a><span class="co"># --- BO Loop ---</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>KAPPA <span class="op">=</span> <span class="fl">2.576</span> <span class="co"># Exploration parameter for LCB. Adjust as needed.</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>N_INITIAL <span class="op">=</span> <span class="dv">49</span> <span class="co"># The initial schedule will always be included</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>N_ITERATIONS <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE_q <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>NUM_CANDIDATES_Acqf <span class="op">=</span> T<span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">1024</span> <span class="co"># Might need more for higher T</span></span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> math.ceil(T<span class="op">/</span><span class="dv">4</span>) <span class="co"># Dimension of the embedding space</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Store evaluated points (using NumPy arrays)</span></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>evaluated_U_np_list <span class="op">=</span> [] <span class="co"># List to store evaluated U vectors (binary)</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>evaluated_f_vals <span class="op">=</span> []    <span class="co"># List to store raw objective values (lower is better)</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>train_Y_list <span class="op">=</span> []        <span class="co"># List to store NEGATED objective values for GP (higher is better)</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialization</span></span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> U_init <span class="kw">in</span> initial_candidates:</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>    f_val <span class="op">=</span> evaluate_objective(U_init, X, v_star, convolutions, d, w)</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>    neg_f_val <span class="op">=</span> <span class="op">-</span>f_val</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.append(U_init)</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>    evaluated_f_vals.append(f_val)</span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>    train_Y_list.append(neg_f_val)</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert lists to NumPy arrays for GP fitting</span></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Keep as column vector initially</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>best_obj_so_far <span class="op">=</span> <span class="bu">min</span>(evaluated_f_vals) <span class="cf">if</span> evaluated_f_vals <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>initial_best_obj_so_far_lcb <span class="op">=</span> best_obj_so_far <span class="co"># Saved for reporting results</span></span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial best objective value: </span><span class="sc">{</span>best_obj_so_far<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> np.isfinite(best_obj_so_far):</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span>(<span class="st">"Warning: Initial best objective is infinite, possibly all initial points were infeasible."</span>)</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. BO Iterations</span></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(N_ITERATIONS):</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>N_ITERATIONS<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># a. Generate dictionary A (remains the same)</span></span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>    current_dictionary_A <span class="op">=</span> generate_wavelet_dictionary(T, m)</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># b. Embed ALL evaluated U vectors (remains the same)</span></span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> evaluated_U_np_list: <span class="cf">continue</span></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_array <span class="op">=</span> np.array(evaluated_U_np_list)</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>    embedded_train_X <span class="op">=</span> embed_batch(evaluated_U_np_array, current_dictionary_A)</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c. Scale the embedded training data (remains the same)</span></span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>: embedded_train_X_scaled <span class="op">=</span> scaler.fit_transform(embedded_train_X)</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: embedded_train_X_scaled <span class="op">=</span> embedded_train_X</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure train_Y is NumPy array</span></span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>    train_Y_for_fit <span class="op">=</span> np.array(train_Y_list)</span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># d. Fit GP Model (remains the same)</span></span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Fitting GP model..."</span>)</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> embedded_train_X_scaled.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> train_Y_for_fit.shape[<span class="dv">0</span>] <span class="op">==</span> embedded_train_X_scaled.shape[<span class="dv">0</span>]:</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>        gp_model <span class="op">=</span> get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"GP model fitted."</span>)</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration."</span>)</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e. Determine current best neg value (useful for tracking, not directly used in LCB calculation)</span></span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>    current_best_neg_f_val <span class="op">=</span> np.<span class="bu">max</span>(train_Y_for_fit) <span class="cf">if</span> train_Y_for_fit.size <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_best_neg_f_val <span class="op">&lt;=</span> <span class="op">-</span>LARGE_PENALTY <span class="op">/</span> <span class="dv">2</span> <span class="kw">and</span> np.isfinite(current_best_neg_f_val):</span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Current best NEGATIVE objective value (</span><span class="sc">{</span>current_best_neg_f_val<span class="sc">:.2f}</span><span class="ss">) is very low (likely from penalties)."</span>)</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a>    <span class="co"># f. Optimize Acquisition Function (LCB) &lt;&lt;&lt; MODIFIED CALL &amp; COMMENT</span></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Optimizing acquisition function (LCB)..."</span>) <span class="co"># Comment updated</span></span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>    next_U_candidates_np <span class="op">=</span> optimize_acqf_discrete_via_embedding(</span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a>        gp_model<span class="op">=</span>gp_model,</span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a>        scaler<span class="op">=</span>scaler,</span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>        dictionary_A<span class="op">=</span>current_dictionary_A,</span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a>        T<span class="op">=</span>T,</span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>        q<span class="op">=</span>BATCH_SIZE_q,</span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a>        num_candidates<span class="op">=</span>NUM_CANDIDATES_Acqf,</span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a>        kappa<span class="op">=</span>KAPPA <span class="co"># Pass kappa</span></span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Selected </span><span class="sc">{</span>next_U_candidates_np<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> candidate(s)."</span>)</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a>    <span class="co"># g. Evaluate Objective (remains the same)</span></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a>    newly_evaluated_U <span class="op">=</span> []<span class="op">;</span> newly_evaluated_f <span class="op">=</span> []<span class="op">;</span> newly_evaluated_neg_f <span class="op">=</span> []</span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(next_U_candidates_np.shape[<span class="dv">0</span>]):</span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a>        next_U <span class="op">=</span> next_U_candidates_np[i, :]</span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a>        already_evaluated <span class="op">=</span> <span class="bu">any</span>(np.array_equal(next_U, u) <span class="cf">for</span> u <span class="kw">in</span> evaluated_U_np_list)</span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> already_evaluated: <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> was already evaluated. Skipping."</span>)<span class="op">;</span> <span class="cf">continue</span></span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a>        next_f <span class="op">=</span> evaluate_objective(next_U, X, v_star, convolutions, d, w)</span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a>        next_neg_f <span class="op">=</span> <span class="op">-</span>next_f</span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>        V_sum <span class="op">=</span> np.<span class="bu">sum</span>(v_star[next_U <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a>        Y <span class="op">=</span> X <span class="op">+</span> V_sum</span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Candidate </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: Obj = </span><span class="sc">{</span>next_f<span class="sc">:.4f}</span><span class="ss">, schedule = </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a>        newly_evaluated_U.append(next_U)<span class="op">;</span> newly_evaluated_f.append(next_f)<span class="op">;</span> newly_evaluated_neg_f.append(next_neg_f)</span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> next_f <span class="op">&lt;</span> best_obj_so_far: best_obj_so_far <span class="op">=</span> next_f</span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># h. Augment Dataset (remains the same)</span></span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>    evaluated_U_np_list.extend(newly_evaluated_U)<span class="op">;</span> evaluated_f_vals.extend(newly_evaluated_f)<span class="op">;</span> train_Y_list.extend(newly_evaluated_neg_f)</span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a>    train_Y <span class="op">=</span> np.array(train_Y_list).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a>    iter_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best objective value found so far: </span><span class="sc">{</span>best_obj_so_far<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total points evaluated: </span><span class="sc">{</span><span class="bu">len</span>(evaluated_f_vals)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> completed in </span><span class="sc">{</span>iter_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Results ---</span></span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Optimization Finished ---"</span>)</span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> evaluated_f_vals: <span class="bu">print</span>(<span class="st">"No points were successfully evaluated."</span>)</span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a>    final_best_idx_lcb <span class="op">=</span> np.argmin(evaluated_f_vals)</span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a>    final_best_U_lcb <span class="op">=</span> evaluated_U_np_list[final_best_idx_lcb]</span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a>    final_best_f_lcb <span class="op">=</span> evaluated_f_vals[final_best_idx_lcb]</span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a>    nr_evaluated_f_vals_lcb <span class="op">=</span> <span class="bu">len</span>(evaluated_f_vals) <span class="co"># Saved for reporting results</span></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total evaluations: </span><span class="sc">{</span>nr_evaluated_f_vals_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Objective Value Found: </span><span class="sc">{</span>final_best_f_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best U vector Found: </span><span class="sc">{</span>final_best_U_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verification</span></span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a>    V_sum_best <span class="op">=</span> np.<span class="bu">sum</span>(v_star[final_best_U_lcb <span class="op">==</span> <span class="dv">1</span>, :], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a>    Y_best_lcb <span class="op">=</span> X <span class="op">+</span> V_sum_best</span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a>    is_feasible <span class="op">=</span> np.<span class="bu">all</span>(Y_best_lcb <span class="op">&gt;=</span> <span class="dv">0</span>)</span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a>    recalculated_obj <span class="op">=</span> LARGE_PENALTY</span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a>        ewt, esp <span class="op">=</span> calculate_objective_serv_time_lookup(Y_best_lcb, d, convolutions)</span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a>        recalculated_obj <span class="op">=</span> w <span class="op">*</span> ewt <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> esp</span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Verification ---"</span>)</span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Is the best U feasible? </span><span class="sc">{</span>is_feasible<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_feasible:</span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Resulting Y vector for best U: </span><span class="sc">{</span>Y_best_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Objective value (recalculated): </span><span class="sc">{</span>recalculated_obj<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> np.isclose(final_best_f_lcb, recalculated_obj): <span class="bu">print</span>(<span class="ss">f"Warning: Stored best objective (</span><span class="sc">{</span>final_best_f<span class="sc">:.4f}</span><span class="ss">) does not match recalculation (</span><span class="sc">{</span>recalculated_obj<span class="sc">:.4f}</span><span class="ss">)!"</span>)</span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> final_best_f_lcb <span class="op">&lt;</span> LARGE_PENALTY: <span class="bu">print</span>(<span class="ss">f"Warning: Best objective (</span><span class="sc">{</span>final_best_f_lcb<span class="sc">:.4f}</span><span class="ss">) is not the penalty value, but feasibility check failed."</span>)<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f"Resulting Y vector (infeasible): </span><span class="sc">{</span>Y_best_lcb<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"Best solution found corresponds to an infeasible penalty value."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial best objective value: 118.87100166955729

--- Iteration 1/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  1  0  0  2  0  2  1  0  0  1  1  1  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  0  1  0  1  1  2  1  0  1  1  0  0  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  1  1  1  1  1  1 -1  2  0  1  1  1  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  1  1  0  2  0  1  1  1  0  2  1 -1  1  8]
  Candidate 4: Obj = 123.5187, schedule = [2 1 1 1 0 2 1 0 0 1 1 2 0 1 1 1 0 0 1 8]
Best objective value found so far: 118.8710
Total points evaluated: 55
Iteration 1 completed in 3.57 seconds.

--- Iteration 2/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 130.8475, schedule = [1 2 0 1 1 1 0 2 0 1 1 0 1 1 0 2 1 0 0 9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  1  0  2 -1  2  0  2  0  1  0  2  1  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  0  1  1  1  1  0  1  0  2  0  0  1  2  1 -1  1  9]
  Candidate 3: Obj = 121.4522, schedule = [2 1 2 0 1 1 1 0 1 1 0 2 0 1 1 1 1 0 0 8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  1  1  0  1  0  2  1 -1  1  2  0  1  1  8]
Best objective value found so far: 118.8710
Total points evaluated: 60
Iteration 2 completed in 3.65 seconds.

--- Iteration 3/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 131.7503, schedule = [1 2 0 2 0 1 0 2 0 1 1 1 0 1 0 2 1 0 0 9]
  Candidate 1: Obj = 124.4007, schedule = [3 1 0 1 1 1 1 1 0 1 0 2 1 0 0 2 1 0 0 8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  1  1  1  1 -1  1  2  1 -1  2  8]
  Candidate 3: Obj = 123.8613, schedule = [3 1 0 1 1 1 0 2 0 1 1 1 1 0 0 2 1 0 0 8]
  Candidate 4: Obj = 127.0363, schedule = [2 1 0 1 0 2 1 1 0 1 0 1 2 0 0 2 1 0 1 8]
Best objective value found so far: 118.8710
Total points evaluated: 65
Iteration 3 completed in 3.93 seconds.

--- Iteration 4/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  0  1  2 -1  2  1  0  2 -1  2  0  2  0  0  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  1  0  1  1  0  1  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  0  1  0  1  1  1  0  2  1  1  0  0  2  0  2 -1  2  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  0  2 -1  1  2  0  0  2  1  0  2 -1  2  1  0  1  0  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  0  1  0  2  0  2 -1  1  9]
Best objective value found so far: 118.8710
Total points evaluated: 70
Iteration 4 completed in 4.20 seconds.

--- Iteration 5/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  1  1  1  1  1  0  0  2  1  0  1  0  9]
  Candidate 1: Obj = 128.2031, schedule = [2 1 1 0 0 1 2 1 0 1 0 2 1 0 0 2 0 1 1 8]
  Candidate 2: Obj = 125.0659, schedule = [1 1 1 1 0 1 2 0 1 1 1 1 0 1 0 2 0 1 1 8]
  Candidate 3: Obj = 131.4179, schedule = [2 1 0 1 0 1 2 1 0 1 1 0 2 0 1 1 1 0 0 9]
  Candidate 4: Obj = 132.0015, schedule = [2 0 1 1 0 1 1 1 1 1 1 1 0 0 2 1 1 0 0 9]
Best objective value found so far: 118.8710
Total points evaluated: 75
Iteration 5 completed in 4.52 seconds.

--- Iteration 6/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  0  1  0  1  2  1  1 -1  1  1  2  0  0  9]
  Candidate 1: Obj = 123.5175, schedule = [2 1 1 1 0 2 0 1 0 1 1 2 0 0 2 1 0 0 1 8]
  Candidate 2: Obj = 123.2617, schedule = [3 0 1 1 0 1 1 1 0 2 1 0 1 0 2 0 1 0 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  1  0  2  0  1  1  1  0  1  0  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  1  2  0  1  1  0  2  0  0  2  0  2 -1  1  9]
Best objective value found so far: 118.8710
Total points evaluated: 80
Iteration 6 completed in 4.32 seconds.

--- Iteration 7/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  0  1  0  2  0  1  1  0  9]
  Candidate 1: Obj = 133.3148, schedule = [2 1 1 0 0 2 0 1 0 1 2 0 1 0 2 0 1 0 2 8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  2  1  0  1  1  0  2  0  1  0  1  1  1  1  7]
  Candidate 3: Obj = 124.1344, schedule = [3 1 1 0 1 1 1 0 0 2 0 1 1 1 0 2 0 0 2 7]
  Candidate 4: Obj = 132.5415, schedule = [1 1 1 2 0 1 0 2 0 1 0 1 1 1 1 1 0 0 1 9]
Best objective value found so far: 118.8710
Total points evaluated: 85
Iteration 7 completed in 4.17 seconds.

--- Iteration 8/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  0  0  1  2  1  1 -1  2  1  0  0  2  7]
  Candidate 1: Obj = 124.7751, schedule = [3 0 1 2 0 0 2 0 1 0 1 2 1 0 1 0 1 0 1 8]
  Candidate 2: Obj = 122.3063, schedule = [2 1 2 0 0 1 2 1 0 1 1 1 1 0 1 0 1 0 2 7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  0  1  1  0  1  1  2  0  0  1  1  2 -1  1  8]
  Candidate 4: Obj = 132.8389, schedule = [2 0 2 1 0 1 0 1 1 0 1 2 0 0 1 2 0 0 2 8]
Best objective value found so far: 118.8710
Total points evaluated: 90
Iteration 8 completed in 4.06 seconds.

--- Iteration 9/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  0  2 -1  1  1  2  1  0  0  2  1  0  1  8]
  Candidate 1: Obj = 132.6826, schedule = [2 1 0 2 0 0 2 1 0 0 1 1 1 1 0 2 0 0 2 8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  1  2  1  0  1  0  1  2  0  0  1  1  1  1  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  2  0  2  0  0  1  1  2 -1  1  1  1  1  0  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  2  0  1  0  1  2 -1  2  0  1  0  2  7]
Best objective value found so far: 118.8710
Total points evaluated: 95
Iteration 9 completed in 3.84 seconds.

--- Iteration 10/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  1 -1  2  0  1  2  0  1  0  1  1  1  7]
  Candidate 1: Obj = 131.3891, schedule = [2 0 1 1 1 1 1 0 0 2 0 1 2 0 1 0 1 1 0 9]
  Candidate 2: Obj = 132.6630, schedule = [2 0 1 2 0 1 1 0 0 1 1 1 2 0 0 2 0 1 0 9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  2  1  0  1  1  0  0  2  0  1  1  1  0  2  1 -1  2  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  0  1  1  0  1  1  0  1  9]
Best objective value found so far: 118.8710
Total points evaluated: 100
Iteration 10 completed in 4.38 seconds.

--- Iteration 11/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 119.2401, schedule = [2 1 2 0 1 1 1 0 0 1 2 1 0 0 1 1 1 1 1 7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  1  0  0  1  2  1  1 -1  1  1  1  0  2  8]
  Candidate 2: Obj = 129.2138, schedule = [1 1 2 0 0 2 1 0 0 1 2 1 0 0 1 1 1 1 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  2  0  2  0  0  1  2  1 -1  1  1  1  0  2  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  2 -1  1  1  2  0  0  2  0  1  0  2  7]
Best objective value found so far: 118.8710
Total points evaluated: 105
Iteration 11 completed in 4.10 seconds.

--- Iteration 12/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  1  2  0  0  2  1  0  1  0  1  1  1  0  2  7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  2 -1  2  1  0  0  2  1  0  2 -1  2  0  1  1  0  9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  0  2  1 -1  2  1  0  2 -1  2  0  1  1  0  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  1  1 -1  2  1  0  2 -1  1  2  0  0  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  1  1 -1  2  1  0  1  0  2  1  0  0  2  8]
Best objective value found so far: 118.8710
Total points evaluated: 110
Iteration 12 completed in 4.41 seconds.

--- Iteration 13/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 118.2240, schedule = [3 0 1 2 0 0 1 1 1 0 2 0 1 0 2 0 1 1 1 7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  2 -1  2  0  1  1  0  2  0  1  1  1  8]
  Candidate 2: Obj = 117.9711, schedule = [3 0 1 2 0 0 1 1 1 0 1 1 1 0 2 0 2 0 1 7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  2 -1  2  0  1  1  1  1  0  1  0  2  8]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  0  1  1  1  1  0  2  0  0  2  0  2 -1  1  8]
Best objective value found so far: 117.9711
Total points evaluated: 115
Iteration 13 completed in 4.59 seconds.

--- Iteration 14/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 123.3827, schedule = [3 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 2 0 0 8]
  Candidate 1: Obj = 132.5767, schedule = [2 1 1 0 1 0 2 1 0 0 2 1 1 0 1 1 1 0 0 9]
  Candidate 2: Obj = 124.9912, schedule = [3 1 1 1 0 0 2 1 0 1 0 2 1 0 1 1 1 0 0 8]
  Candidate 3: Obj = 119.2593, schedule = [3 1 1 1 0 1 1 0 1 1 1 0 2 0 0 2 1 0 1 7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  1  2  0  0  2  1  1 -1  2  1  1  0  1  8]
Best objective value found so far: 117.9711
Total points evaluated: 120
Iteration 14 completed in 4.59 seconds.

--- Iteration 15/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 132.2421, schedule = [2 1 1 0 0 1 1 2 0 0 1 1 1 1 0 1 2 0 0 9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  2  0  1  0  2  1  1 -1  1  2  0  1  1  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  0  2  0  1  0  1  1  0  1  1  2 -1  2  7]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  2  1  1  0  1  1  1  1 -1  2  0  2 -1  2  7]
  Candidate 4: Obj = 117.2325, schedule = [3 0 1 1 0 2 0 1 1 1 1 0 2 0 0 2 1 0 1 7]
Best objective value found so far: 117.2325
Total points evaluated: 125
Iteration 15 completed in 4.36 seconds.

--- Iteration 16/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  0  0  2  1  0  1  1  0  1  2  0  0  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  1  0  2  1  0  2  0  0  1  2  0  0  8]
  Candidate 2: Obj = 120.2212, schedule = [3 1 1 0 0 2 0 1 0 2 1 0 1 0 1 1 2 0 1 7]
  Candidate 3: Obj = 122.3628, schedule = [2 2 0 1 0 2 0 1 0 2 1 0 1 1 0 1 2 0 0 8]
  Candidate 4: Obj = 118.6656, schedule = [2 2 1 0 0 2 0 1 0 2 1 0 1 1 0 1 2 0 1 7]
Best objective value found so far: 117.2325
Total points evaluated: 130
Iteration 16 completed in 4.65 seconds.

--- Iteration 17/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 133.4606, schedule = [1 2 0 2 0 0 1 1 1 0 1 2 0 1 1 1 0 0 1 9]
  Candidate 1: Obj = 124.3333, schedule = [3 1 0 2 0 0 2 0 1 1 0 2 0 0 2 1 0 1 0 8]
  Candidate 2: Obj = 124.4456, schedule = [3 1 0 1 0 1 2 0 1 0 1 2 0 1 0 2 0 0 1 8]
  Candidate 3: Obj = 122.1176, schedule = [2 1 1 2 0 0 1 1 0 2 0 2 0 1 1 1 0 0 2 7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  1  1  0  2  0  2  0  1  0  1  1  0  1  8]
Best objective value found so far: 117.2325
Total points evaluated: 135
Iteration 17 completed in 5.23 seconds.

--- Iteration 18/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  1  2  0  1  1  0  2  0  0  1  2  1  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  0  1  1  0  1  1  0  1  2  1 -1  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  1  2  0  1  0  1  2  0  0  1  2  1  0  0  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  1  1  0  2  0  1  0  1  2  0  0  1  2  1 -1  2  8]
  Candidate 4: Obj = 132.6467, schedule = [2 0 2 1 0 1 1 0 1 1 0 2 0 0 1 2 0 0 2 8]
Best objective value found so far: 117.2325
Total points evaluated: 140
Iteration 18 completed in 5.33 seconds.

--- Iteration 19/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 132.7635, schedule = [1 2 1 0 1 1 0 1 1 0 1 2 0 1 0 1 1 0 1 9]
  Candidate 1: Obj = 134.0218, schedule = [1 2 0 2 0 1 0 1 1 0 2 0 1 0 1 2 0 0 1 9]
  Candidate 2: Obj = 132.6921, schedule = [1 2 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 9]
  Candidate 3: Obj = 134.3468, schedule = [1 2 1 1 0 1 0 1 1 1 0 2 0 0 1 2 0 0 1 9]
  Candidate 4: Obj = 131.9700, schedule = [2 1 1 1 0 1 0 1 0 1 1 2 0 1 0 1 1 1 0 9]
Best objective value found so far: 117.2325
Total points evaluated: 145
Iteration 19 completed in 5.02 seconds.

--- Iteration 20/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 124.8142, schedule = [2 1 0 2 0 1 0 2 0 0 1 2 1 0 1 1 1 0 1 8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  1  0  1  1  0  1  2 -1  2  0  1  1  0  9]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  1  0  0  2  0  1  2  0  0  2  1 -1  1  9]
  Candidate 3: Obj = 133.0355, schedule = [2 1 0 2 0 1 1 1 0 0 1 2 0 0 1 2 0 1 0 9]
  Candidate 4: Obj = 127.4777, schedule = [2 1 1 1 0 0 2 0 0 1 1 1 1 1 0 2 1 0 1 8]
Best objective value found so far: 117.2325
Total points evaluated: 150
Iteration 20 completed in 5.28 seconds.

--- Iteration 21/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  2  1  0  0  1  1  1  1  0  1  2 -1  2  7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  2  0  1  0  1  1  1  0  2  0  0  2  7]
  Candidate 2: Obj = 118.8553, schedule = [2 2 1 0 0 2 0 1 1 0 1 2 0 0 2 1 0 1 1 7]
  Candidate 3: Obj = 123.2719, schedule = [3 1 0 1 1 0 2 0 1 0 1 1 1 0 1 1 1 0 1 8]
  Candidate 4: Obj = 122.1658, schedule = [3 1 0 1 1 0 2 1 0 1 1 0 1 1 0 1 1 1 0 8]
Best objective value found so far: 117.2325
Total points evaluated: 155
Iteration 21 completed in 5.98 seconds.

--- Iteration 22/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 121.0466, schedule = [3 0 1 1 1 1 0 1 1 0 2 0 1 1 1 0 1 0 2 7]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  1  2  1  0  0  2  1  1 -1  1  1  1  0  2  8]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  0  2 -1  1  1  2  1  0  1  1  1  0  1  7]
  Candidate 3: Obj = 134.6840, schedule = [1 2 1 0 0 1 1 2 0 1 0 1 2 0 0 2 0 0 1 9]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  1  0  1  0  2  0  1  0  1  1  0  1  8]
Best objective value found so far: 117.2325
Total points evaluated: 160
Iteration 22 completed in 5.36 seconds.

--- Iteration 23/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  1  2 -1  1  2  0  1  1  0  2  1  0  1  8]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  1  1  0  1  0  2  0  2  0  1  1  0  2 -1  2  8]
  Candidate 2: Obj = 128.1131, schedule = [2 1 0 1 0 1 2 1 0 0 2 0 2 0 0 2 0 1 1 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  0  1  0  1  2 -1  1  1  1  2 -1  1  1  1  1  1  7]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  1  1  1 -1  1  2  1  0  1  0  2  1  0  1  7]
Best objective value found so far: 117.2325
Total points evaluated: 165
Iteration 23 completed in 5.23 seconds.

--- Iteration 24/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  0  1  2  0  1  0  2  1  1  0  0  9]
  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  2  1 -1  2  1  0  1  0  1  1  2  0  1  7]
  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  1  2  1  0  1  1  0  2  0  1  0  2 -1  1  9]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  0  2  0  0  2  1 -1  2  1  1  1  0  0  1  2 -1  1  9]
  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  1  1  0  2  1  0  1  0  2  0  2  0  1  8]
Best objective value found so far: 117.2325
Total points evaluated: 170
Iteration 24 completed in 5.52 seconds.

--- Iteration 25/25 ---
Fitting GP model...
GP model fitted.
Optimizing acquisition function (LCB)...
Selected 5 candidate(s).
  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  1  0  2  0  0  2  0  1  0  2  1  1 -1  2  8]
  Candidate 1: Obj = 124.5451, schedule = [3 0 2 0 0 1 2 0 1 0 2 0 2 0 1 0 1 0 1 8]
  Candidate 2: Obj = 124.2147, schedule = [3 0 1 1 1 0 2 0 0 2 0 2 1 0 0 2 1 0 0 8]
  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  1  0  2  0  2  0  0  1  1  1  1  1  7]
  Candidate 4: Obj = 123.0855, schedule = [2 2 0 1 1 1 1 0 0 1 2 0 1 0 1 1 2 0 0 8]
Best objective value found so far: 117.2325
Total points evaluated: 175
Iteration 25 completed in 6.93 seconds.

--- Optimization Finished ---
Total evaluations: 175
Best Objective Value Found: 117.23250201869716
Best U vector Found: [0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1]

--- Verification ---
Is the best U feasible? True
Resulting Y vector for best U: [3 0 1 1 0 2 0 1 1 1 1 0 2 0 0 2 1 0 1 7]
Objective value (recalculated): 117.2325</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="results" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="results"><span class="header-section-number">6.5</span> Results</h2>
<p>The initial schedule, derived using the Bailey-Welch method (bailey1952study), serves as a baseline. The objective function <span class="math inline">\(C(\mathbf{x})\)</span> combines Expected Waiting Time (<span class="math inline">\(EWT\)</span>) and Expected Staff Penalty (<span class="math inline">\(ESP\)</span>). Lower values of <span class="math inline">\(C(\mathbf{x})\)</span> are preferable. Each experiment consisted of <span class="math inline">\(N_{INITIAL} = 20\)</span> initial random evaluations followed by <span class="math inline">\(N_{ITERATIONS} =20\)</span> Bayesian optimization iterations, with <span class="math inline">\(BATCH\_SIZE_q = 5\)</span> evaluations per iteration, totaling approximately <span class="math inline">\(20 + 20 \times 5 = 120\)</span> evaluations per experiment. The optimization operates on the binary perturbation vector <span class="math inline">\(\mathbf{U}\)</span>, using the HED embedding <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span>.</p>
<p>The key performance metric is the best (minimum) objective function value found.</p>
<section id="experiment-1-cbo-with-expected-improvement-ei-1" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1" class="anchored" data-anchor-id="experiment-1-cbo-with-expected-improvement-ei-1"><span class="header-section-number">6.5.1</span> Experiment 1: CBO with Expected Improvement (EI)</h3>
<ul>
<li><strong>Initial Best Objective (after random search)</strong>: 118.87100166955729</li>
<li><strong>Final Best Objective Found</strong>: 114.96364292044709</li>
<li><strong>Total Evaluations</strong>: 175</li>
<li><strong>Best Perturbation Vector <span class="math inline">\(\mathbf{U}_{EI}^*\)</span></strong>: array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])</li>
<li><strong>Resulting Optimal Schedule <span class="math inline">\(\mathbf{x}_{EI}^*\)</span></strong>: array([2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 1, 7])</li>
</ul>
</section>
<section id="experiment-2-cbo-with-lower-confidence-bound-lcb---kappa-2.576" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2" class="anchored" data-anchor-id="experiment-2-cbo-with-lower-confidence-bound-lcb---kappa-2.576"><span class="header-section-number">6.5.2</span> Experiment 2: CBO with Lower Confidence Bound (LCB) - <span class="math inline">\(\kappa =\)</span> 2.576</h3>
<ul>
<li><strong>Initial Best Objective (after random search)</strong>: 118.87100166955729</li>
<li><strong>Final Best Objective Found</strong>: 117.23250201869716</li>
<li><strong>Total Evaluations</strong>: 175</li>
<li><strong>Best Perturbation Vector <span class="math inline">\(\mathbf{U}_{LCB\_fixed}^*\)</span></strong>: array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])</li>
<li><strong>Resulting Optimal Schedule <span class="math inline">\(\mathbf{x}_{LCB\_fixed}^*\)</span></strong>: array([3, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 7])</li>
</ul>
</section>
<section id="summary-of-best-objectives" class="level3" data-number="6.5.3">
<h3 data-number="6.5.3" class="anchored" data-anchor-id="summary-of-best-objectives"><span class="header-section-number">6.5.3</span> Summary of Best Objectives</h3>
<table class="table">
<colgroup>
<col style="width: 49%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Experiment</th>
<th>Best Objective <span class="math inline">\(C(\mathbf{x}^*)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CBO with EI</td>
<td>114.96364292044709</td>
</tr>
<tr class="even">
<td>CBO with LCB (Fixed <span class="math inline">\(\kappa=\)</span> 2.576)</td>
<td>117.23250201869716</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="discussion" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="discussion"><span class="header-section-number">6.6</span> Discussion</h2>
<p>The experiments aimed to compare two CBO strategies, leveraging the HED embedding technique <span class="citation" data-cites="deshwal_bayesian_2023">(<a href="combinatorial-bayes-optimization.html#ref-deshwal_bayesian_2023" role="doc-biblioref">Deshwal et al. 2023</a>)</span>, for optimizing the outpatient appointment scheduling problem formulated by <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span>. Both methods successfully improved upon their respective initial random search results, demonstrating the applicability of BO with HED to this combinatorial problem.</p>
<ol type="1">
<li><p><strong>Performance Comparison</strong>:</p></li>
<li><p><strong>Hypothesis Evaluation</strong>:</p>
<ul>
<li>Hypothesis 1</li>
<li>Hypothesis 2</li>
</ul></li>
<li><p><strong>Exploration vs.&nbsp;Exploitation</strong>:</p></li>
<li><p><strong>Computational Effort</strong>:</p></li>
<li><p><strong>Limitations and Future Work</strong>:</p>
<ul>
<li>The optimality guarantee mentioned by <span class="citation" data-cites="kaandorp_optimal_2007">Kaandorp and Koole (<a href="combinatorial-bayes-optimization.html#ref-kaandorp_optimal_2007" role="doc-biblioref">2007</a>)</span> applies to their specific local search algorithm operating directly on the schedule space <span class="math inline">\(\mathcal{F}\)</span>, leveraging multimodularity. Our BO approach operates on the perturbation vector space <span class="math inline">\(\mathbf{U}\)</span> via HED embeddings. While BO aims for global optimization, it doesn’t inherit the same theoretical guarantee of finding the global optimum as the original local search, especially given the stochastic nature of GP modeling and acquisition function optimization.</li>
<li>The performance is likely sensitive to BO hyperparameters (dictionary size <span class="math inline">\(m\)</span>, <span class="math inline">\(\kappa\)</span> values, number of candidates for acquisition optimization).</li>
<li>Further investigation into different dictionary construction methods (e.g., binary wavelets as mentioned in Deshwal et al., 2023) or adaptive <span class="math inline">\(\kappa\)</span> schedules could be beneficial.</li>
</ul></li>
</ol>
<p>In conclusion, applying CBO with HED embeddings appears promising for this scheduling problem. The LCB acquisition function with a fixed, well-chosen <span class="math inline">\(\kappa\)</span> demonstrated the best performance in this study.</p>
</section>
<section id="timeline" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="timeline"><span class="header-section-number">6.7</span> Timeline</h2>
<ul>
<li><strong>Experiment Setup and Code Implementation</strong>: 30-04-2025</li>
<li><strong>Results Analysis and Report Compilation</strong>: 07-05-2025</li>
</ul>
</section>
<section id="references" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="references"><span class="header-section-number">6.8</span> References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aglietti_funbo_2024" class="csl-entry" role="listitem">
Aglietti, Virginia, Ira Ktena, Jessica Schrouff, Eleni Sgouritsa,
Francisco J. R. Ruiz, Alan Malek, Alexis Bellot, and Silvia Chiappa.
2024. <span>“<span>FunBO</span>: <span>Discovering</span>
<span>Acquisition</span> <span>Functions</span> for
<span>Bayesian</span> <span>Optimization</span> with
<span>FunSearch</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2406.04824">https://doi.org/10.48550/arXiv.2406.04824</a>.
</div>
<div id="ref-altman_multimodularity_2000" class="csl-entry" role="listitem">
Altman, Eitan, Bruno Gaujal, and Arie Hordijk. 2000.
<span>“Multimodularity, <span>Convexity</span>, and
<span>Optimization</span> <span>Properties</span>.”</span>
<em>Mathematics of Operations Research</em> 25 (2): 324–47. <a href="https://www.jstor.org/stable/3690584">https://www.jstor.org/stable/3690584</a>.
</div>
<div id="ref-bailey1952study" class="csl-entry" role="listitem">
Bailey, Norman TJ. 1952. <span>“A Study of Queues and Appointment
Systems in Hospital Out-Patient Departments, with Special Reference to
Waiting-Times.”</span> <em>Journal of the Royal Statistical Society
Series B: Statistical Methodology</em> 14 (2): 185–99.
</div>
<div id="ref-balandat2020botorch" class="csl-entry" role="listitem">
Balandat, Maximilian, Brian Karrer, Daniel R. Jiang, Samuel Daulton,
Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. 2020.
<span>“<span class="nocase">BoTorch: A Framework for Efficient
Monte-Carlo Bayesian Optimization</span>.”</span> In <em>Advances in
Neural Information Processing Systems 33</em>. <a href="http://arxiv.org/abs/1910.06403">http://arxiv.org/abs/1910.06403</a>.
</div>
<div id="ref-deshwal_bayesian_2023" class="csl-entry" role="listitem">
Deshwal, Aryan, Sebastian Ament, Maximilian Balandat, Eytan Bakshy,
Janardhan Rao Doppa, and David Eriksson. 2023. <span>“Bayesian
<span>Optimization</span> over
<span>High</span>-<span>Dimensional</span> <span>Combinatorial</span>
<span>Spaces</span> via <span>Dictionary</span>-Based
<span>Embeddings</span>.”</span> In <em>Proceedings of <span>The</span>
26th <span>International</span> <span>Conference</span> on
<span>Artificial</span> <span>Intelligence</span> and
<span>Statistics</span></em>, 7021–39. PMLR. <a href="https://proceedings.mlr.press/v206/deshwal23a.html">https://proceedings.mlr.press/v206/deshwal23a.html</a>.
</div>
<div id="ref-gonzalez_preferential_2017" class="csl-entry" role="listitem">
Gonzalez, Javier, Zhenwen Dai, Andreas Damianou, and Neil D. Lawrence.
2017. <span>“Preferential <span>Bayesian</span>
<span>Optimization</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1704.03651">https://doi.org/10.48550/arXiv.1704.03651</a>.
</div>
<div id="ref-kaandorp_optimal_2007" class="csl-entry" role="listitem">
Kaandorp, Guido C., and Ger Koole. 2007. <span>“Optimal Outpatient
Appointment Scheduling.”</span> <em>Health Care Management Science</em>
10 (3): 217–29. <a href="https://doi.org/10.1007/s10729-007-9015-x">https://doi.org/10.1007/s10729-007-9015-x</a>.
</div>
<div id="ref-swersky_amortized_2020" class="csl-entry" role="listitem">
Swersky, Kevin, Yulia Rubanova, David Dohan, and Kevin Murphy. 2020.
<span>“Amortized <span>Bayesian</span> <span>Optimization</span> over
<span>Discrete</span> <span>Spaces</span>.”</span> In <em>Proceedings of
the 36th <span>Conference</span> on <span>Uncertainty</span> in
<span>Artificial</span> <span>Intelligence</span>
(<span>UAI</span>)</em>, 769–78. PMLR. <a href="https://proceedings.mlr.press/v124/swersky20a.html">https://proceedings.mlr.press/v124/swersky20a.html</a>.
</div>
<div id="ref-zhang_pabbo_2025" class="csl-entry" role="listitem">
Zhang, Xinyu, Daolang Huang, Samuel Kaski, and Julien Martinelli. 2025.
<span>“<span>PABBO</span>: <span>Preferential</span>
<span>Amortized</span> <span>Black</span>-<span>Box</span>
<span>Optimization</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2503.00924">https://doi.org/10.48550/arXiv.2503.00924</a>.
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./local-search-ranking-large.html" class="pagination-link" aria-label="Large instance local search with trained XGBoost regressor model">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Large instance local search with trained XGBoost regressor model</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./preferential-bayesian-optimization.html" class="pagination-link" aria-label="Preferential Bayesian Optimization for Outpatient Appointment Scheduling">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>