[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Appointment Scheduling Experiments",
    "section": "",
    "text": "To do:\n\nAdd a brief introduction to the project\nAdd evaluator functions\n\nDocument and test the evaluator functions\nRun experiment with the evaluator functions\n\nAdd search functions\n\nDocument and test the search functions\nRun experiment with the search functions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "function-testing.html",
    "href": "function-testing.html",
    "title": "2  Evaluator functions testing",
    "section": "",
    "text": "2.1 Objective\nIn this experiment we will test whether the functions for calculating the objective values work properly and efficiently.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#background",
    "href": "function-testing.html#background",
    "title": "2  Evaluator functions testing",
    "section": "2.2 Background",
    "text": "2.2 Background\nFor developing new methods for optimizing appointment schedules it is necessary that the function for calculating objective values works properly. It is also important that the function is efficient, as it will be used in optimization algorithms that will be run many times.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#hypothesis",
    "href": "function-testing.html#hypothesis",
    "title": "2  Evaluator functions testing",
    "section": "2.3 Hypothesis",
    "text": "2.3 Hypothesis\nThe functions for calculating that have been developed are working fast and generate correct results.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#methodology",
    "href": "function-testing.html#methodology",
    "title": "2  Evaluator functions testing",
    "section": "2.4 Methodology",
    "text": "2.4 Methodology\n\n2.4.1 Tools and Materials\nFor testing the correct working of the functions used to calculate objective values we will compare the exact calculation to results from Monte Carlo (MC) simulations. The MC simulations allow modeling the system and replicating closely the actual process of patients arriving and being served. The exact calculation is based on the convolution of the service time distribution and the number of patients arriving at each time slot.\n\n\n2.4.2 Experimental Design\nWe will define some typical instances of schedules and calculate the objective values for them both using the exact method as well as through MC simulations. We will then compare the results.\n\n\n2.4.3 Variables\n\nIndependent Variables:\n\nDifferent instances of appointment schedules.\n\nDependent Variables:\n\nObjective value results from exact calculations and simulations.\nSpeed indicators\n\n\n\n\n2.4.4 Setup\nWe have defined the following test cases:\n\nimport numpy as np\nimport pandas as pd\nimport time\nimport plotly.graph_objects as go\nfrom functions import service_time_with_no_shows, compute_convolutions, compute_convolutions_fft, calculate_objective_serv_time_lookup\n\n# Parameters\nd = 5\nq = 0.1\n    \n# Create service time distribution\nservice_time = np.zeros(11)\nservice_time[3] = 0.2\nservice_time[5] = 0.3\nservice_time[8] = 0.5\n\naverage_service_time = np.dot(range(len(service_time)), service_time)\nprint(f\"Average service time: {average_service_time}\")\n    \n# Different schedule patterns with the same total number of patients (except for test schedule)\nschedules = [\n    (\"Calibration\", [2, 0, 0, 0, 0, 1]),\n    (\"Uniform\", [2, 2, 2, 2]),\n    (\"Decreasing\", [5, 2, 1, 0]),\n    (\"Increasing\", [0, 1, 2, 5]),\n    (\"Front-heavy\", [4, 4, 0, 0]),\n    (\"Back-heavy\", [0, 0, 4, 4]),\n    (\"Alternating\", [4, 0, 4, 0]),\n    (\"Bailey-rule\", [2, 1, 1, 1, 1, 1, 1])  # Schedule 2 initially, then 1 each slot\n]\n\n# Set number of simulations for Monte Carlo simulation\nnr_simulations = 1000\n\n# Create dictionary for storing results\nresults_dict = {'schedule_name': [], 'average_waiting_time': [], 'average_overtime': [], 'expected_waiting_time': [], 'expected_overtime': [], 'average_computation_time': []}\nresults_dict['schedule_name'] = [s[0] for s in schedules]\n\nAverage service time: 6.1\n\n\nThe “Calibration” test set is used to calibrate the simulation results with the exact results. For this schedule, the exact results can be easily calculated by hand. The average service time after correcting for no-shows for one patient is 5.49 (see below) and only the second patient in this example will experience waiting times. So the average expected waiting time is 5.49 / 3 = 1.83.\nThe expected overtime is is the expected spillover time caused by the last patient in the schedule. As there are no patients before the last patient in the last interval, the spillover time distribution is simply distribution of the event that the (adjusted) service time will exceed the interval time. For the case that overtime is 3 (8 - 5), the probability is 0.45 and for other values it is 0.55. So the expected overtime is 0.45 * 3 + 0.55 * 0 = 1.35.\nThe other test sets are used to examine the performance of the functions for different schedule patterns.\n\n\n2.4.5 Sample Size and Selection\nSample Size: - For each schedule instance we will run 1000 simulations.\nSample Selection: - During each simulation for each patient a random service time will be sampled from the distribution (adjusted for no-shows).\n\n\n2.4.6 Experimental Procedure\n\n2.4.6.1 Step 1: Adjust the service time distribution for no-shows.\n\n# Adjust service time distribution for no-shows and compare to original\nservice_time_no_shows = service_time_with_no_shows(service_time, q)\nprint(f\"Service time distribution with no-shows: {service_time_no_shows}\")\n\naverage_service_time_no_shows = np.dot(range(len(service_time_no_shows)), service_time_no_shows)\nprint(f\"Average service time with no-shows: {average_service_time_no_shows}\")\n\nService time distribution with no-shows: [0.1, 0.0, 0.0, 0.18000000000000002, 0.0, 0.27, 0.0, 0.0, 0.45, 0.0, 0.0]\nAverage service time with no-shows: 5.49\n\n\n\n\n2.4.6.2 Step 2: Monte carlo simulation\nFor each schedule instance:\n\nCalculate \\(N\\) and \\(T\\), the total number of patients and the total time of the schedule.\nFor each simulation:\n\nSample random service times for each of the \\(N\\) patient from service times distribution with no-shows.\nCalculate the the average waiting time and the overtime for the schedule using a Lindley recursion, starting at \\(t = 0\\) and ending at \\(t = T - 1\\).\n\n\n\nimport numpy as np\nfrom typing import List, Tuple, Union\n\ndef simulate_schedule(\n    schedule: List[int],\n    service_time_no_shows: Union[List[float], np.ndarray],\n    d: int,\n    nr_simulations: int\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Runs a Monte Carlo simulation for a single schedule.\n\n    This function simulates patient scheduling over multiple time slots and computes the average waiting \n    time per patient and the average overtime across all simulation iterations. Each time slot has a duration \n    threshold `d`. Service times for patients are sampled based on the provided probability mass function.\n\n    Parameters:\n        schedule (List[int]): A list where each element represents the number of patients scheduled in each time slot.\n        service_time_no_shows (Union[List[float], np.ndarray]): A probability mass function (PMF) for service times.\n        d (int): The duration threshold for a time slot.\n        nr_simulations (int): The number of simulation iterations to run.\n\n    Returns:\n        Tuple[float, float]: A tuple containing:\n            - The average waiting time per patient across simulations.\n            - The average overtime across simulations.\n    \"\"\"\n    N: int = sum(schedule)  # Total number of patients\n    T: int = len(schedule)  # Total number of time slots\n\n    total_waiting_time: float = 0.0\n    total_overtime: float = 0.0\n\n    for _ in range(nr_simulations):\n        cum_waiting_time: float = 0.0\n\n        # --- Process the first time slot ---\n        num_patients: int = schedule[0]\n        # Generate random service times for the first slot\n        sampled: np.ndarray = np.random.choice(\n            range(len(service_time_no_shows)),\n            size=num_patients,\n            p=service_time_no_shows\n        )\n\n        if num_patients == 0:\n            waiting_time: float = 0.0\n            spillover_time: float = 0.0\n        elif num_patients == 1:\n            waiting_time = 0.0\n            spillover_time = max(0, sampled[0])\n        else:\n            # For more than one patient, the waiting time is the cumulative sum\n            # of the service times for all but the last patient.\n            waiting_time = float(sum(np.cumsum(sampled[:-1])))\n            spillover_time = max(0, sum(sampled) - d)\n        cum_waiting_time += waiting_time\n\n        # --- Process the remaining time slots ---\n        for t in range(1, T):\n            num_patients = schedule[t]\n            # Generate random service times for time slot t\n            sampled = np.random.choice(\n                range(len(service_time_no_shows)),\n                size=num_patients,\n                p=service_time_no_shows\n            )\n            if num_patients == 0:\n                waiting_time = 0.0\n                spillover_time = max(0, spillover_time - d)\n            elif num_patients == 1:\n                waiting_time = spillover_time\n                spillover_time = max(0, spillover_time + sampled[0] - d)\n            else:\n                # Each patient waits the current spillover,\n                # plus additional waiting due to the service times of those ahead.\n                waiting_time = spillover_time * num_patients + sum(np.cumsum(sampled[:-1]))\n                spillover_time = max(0, spillover_time + sum(sampled) - d)\n            cum_waiting_time += waiting_time\n\n        # Accumulate normalized waiting time (per patient) and overtime\n        total_waiting_time += cum_waiting_time / N\n        total_overtime += spillover_time\n\n    avg_waiting_time: float = total_waiting_time / nr_simulations\n    avg_overtime: float = total_overtime / nr_simulations\n\n    return avg_waiting_time, avg_overtime\n\n\n# Loop through the schedules\nfor schedule_name, schedule in schedules:\n    N = sum(schedule)\n    T = len(schedule)\n    print(f\"Schedule: {schedule_name} {schedule}, N: {N}, T: {T}\")\n    \n    avg_waiting_time, avg_overtime = simulate_schedule(schedule, service_time_no_shows, d, nr_simulations)\n    \n    print(f\"Average waiting time: {avg_waiting_time}, average overtime: {avg_overtime}\")\n    results_dict['average_waiting_time'].append(avg_waiting_time)\n    results_dict['average_overtime'].append(avg_overtime)\n\nSchedule: Calibration [2, 0, 0, 0, 0, 1], N: 3, T: 6\nAverage waiting time: 1.839666666666684, average overtime: 1.29\nSchedule: Uniform [2, 2, 2, 2], N: 8, T: 4\nAverage waiting time: 11.808625, average overtime: 24.134\nSchedule: Decreasing [5, 2, 1, 0], N: 8, T: 4\nAverage waiting time: 16.8395, average overtime: 24.001\nSchedule: Increasing [0, 1, 2, 5], N: 8, T: 4\nAverage waiting time: 12.578375, average overtime: 29.827\nSchedule: Front-heavy [4, 4, 0, 0], N: 8, T: 4\nAverage waiting time: 16.736875, average overtime: 23.941\nSchedule: Back-heavy [0, 0, 4, 4], N: 8, T: 4\nAverage waiting time: 17.076625, average overtime: 34.765\nSchedule: Alternating [4, 0, 4, 0], N: 8, T: 4\nAverage waiting time: 14.033875, average overtime: 23.87\nSchedule: Bailey-rule [2, 1, 1, 1, 1, 1, 1], N: 8, T: 7\nAverage waiting time: 6.300125, average overtime: 9.616\n\n\n\n\n2.4.6.3 Step 3: Exact calculation\nFor each schedule instance run 10 evaluations of the objective value using the exact method and calculate the average waiting time and overtime.\n\n# Loop through the schedules, run 10 evaluations, calculate average waiting time and overtime for each schedule, calculate average computation times and store the results in the results dictionary\n\nfor schedule_name, schedule in schedules:\n    N = sum(schedule)\n    T = len(schedule)\n    print(f\"Schedule: {schedule_name} {schedule}, N: {N}, T: {T}\")\n    convolutions = compute_convolutions(service_time, N, q)\n    \n    total_time = 0\n    # Exact calculation over 10 evaluations\n    for i in range(10):\n        start_time = time.time()\n        # Calculate the objective value using the exact method\n        waiting_time, overtime = calculate_objective_serv_time_lookup(schedule, d, convolutions)\n        elapsed_time = time.time() - start_time\n        total_time += elapsed_time\n        \n    avg_time = total_time / 10\n    print(f\"Expected waiting time: {waiting_time / N}, Expected overtime: {overtime}\")\n    results_dict['expected_waiting_time'].append(waiting_time / N)\n    results_dict['expected_overtime'].append(overtime)\n    results_dict['average_computation_time'].append(avg_time)\n\nSchedule: Calibration [2, 0, 0, 0, 0, 1], N: 3, T: 6\nExpected waiting time: 1.83, Expected overtime: 1.35\nSchedule: Uniform [2, 2, 2, 2], N: 8, T: 4\nExpected waiting time: 11.816608810500004, Expected overtime: 24.064827562971374\nSchedule: Decreasing [5, 2, 1, 0], N: 8, T: 4\nExpected waiting time: 16.715096633250006, Expected overtime: 23.92331748953545\nSchedule: Increasing [0, 1, 2, 5], N: 8, T: 4\nExpected waiting time: 12.5150625, Expected overtime: 29.856120798600017\nSchedule: Front-heavy [4, 4, 0, 0], N: 8, T: 4\nExpected waiting time: 16.715970000000002, Expected overtime: 23.92482686022145\nSchedule: Back-heavy [0, 0, 4, 4], N: 8, T: 4\nExpected waiting time: 16.715970000000002, Expected overtime: 33.92194762296002\nSchedule: Alternating [4, 0, 4, 0], N: 8, T: 4\nExpected waiting time: 14.233406400000002, Expected overtime: 23.95841024194273\nSchedule: Bailey-rule [2, 1, 1, 1, 1, 1, 1], N: 8, T: 7\nExpected waiting time: 6.439653759761102, Expected overtime: 9.820826086143853",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#results",
    "href": "function-testing.html#results",
    "title": "2  Evaluator functions testing",
    "section": "2.5 Results",
    "text": "2.5 Results\nComparison of the results of the exact calculations with the results of the Monte Carlo simulations.\n\ndf_results = pd.DataFrame.from_dict(results_dict)\ndf_results\n\n\n\n\n\n\n\n\n\nschedule_name\naverage_waiting_time\naverage_overtime\nexpected_waiting_time\nexpected_overtime\naverage_computation_time\n\n\n\n\n0\nCalibration\n1.839667\n1.290\n1.830000\n1.350000\n0.000110\n\n\n1\nUniform\n11.808625\n24.134\n11.816609\n24.064828\n0.000111\n\n\n2\nDecreasing\n16.839500\n24.001\n16.715097\n23.923317\n0.000139\n\n\n3\nIncreasing\n12.578375\n29.827\n12.515063\n29.856121\n0.000110\n\n\n4\nFront-heavy\n16.736875\n23.941\n16.715970\n23.924827\n0.000058\n\n\n5\nBack-heavy\n17.076625\n34.765\n16.715970\n33.921948\n0.000066\n\n\n6\nAlternating\n14.033875\n23.870\n14.233406\n23.958410\n0.000059\n\n\n7\nBailey-rule\n6.300125\n9.616\n6.439654\n9.820826\n0.000126\n\n\n\n\n\n\n\n\n\n# Extract schedule names from the dataframe\nschedule_names = df_results['schedule_name'].tolist()\n\n# Create new x-values for simulation and exact results\nx_sim = [f\"{s}&lt;br&gt;Simulation\" for s in schedule_names]\nx_exact = [f\"{s}&lt;br&gt;Exact\" for s in schedule_names]\n\n# Extract values from the dataframe\nsim_wait = df_results['average_waiting_time'].tolist()\nsim_over = df_results['average_overtime'].tolist()\nexact_wait = df_results['expected_waiting_time'].tolist()\nexact_over = df_results['expected_overtime'].tolist()\n\n# Create a combined category list with an empty category between the two groups\ncategories = x_sim + [\"\"] + x_exact\n\n# Create the figure\nfig = go.Figure()\n\n# Simulation bar traces (stacked)\nfig.add_trace(go.Bar(\n    x=x_sim,\n    y=sim_wait,\n    name='Waiting Time',\n    marker_color='blue'\n))\nfig.add_trace(go.Bar(\n    x=x_sim,\n    y=sim_over,\n    name='Overtime',\n    marker_color='red'\n))\n\n# Exact bar traces (stacked)\nfig.add_trace(go.Bar(\n    x=x_exact,\n    y=exact_wait,\n    name='Waiting Time',\n    marker_color='blue',\n    showlegend=False  # legend already shown for waiting time above\n))\nfig.add_trace(go.Bar(\n    x=x_exact,\n    y=exact_over,\n    name='Overtime',\n    marker_color='red',\n    showlegend=False  # legend already shown for overtime above\n))\n\n# Update x-axis to use the full category array (which includes the gap)\nfig.update_xaxes(\n    tickangle=45,\n    categoryorder='array',\n    categoryarray=categories\n)\n\n# Optionally, adjust the vertical dotted line.\n# For example, you can remove it if the gap is sufficient or reposition it.\nfig.update_layout(\n    title=\"Comparison of Simulation vs. Exact Results\",\n    xaxis_title=\"Schedule Type\",\n    yaxis_title=\"Time\",\n    barmode='stack',\n    shapes=[\n        dict(\n            type=\"line\",\n            xref=\"paper\", x0=0.5, x1=0.5,\n            yref=\"paper\", y0=0, y1=1,\n            line=dict(\n                color=\"black\",\n                width=2,\n                dash=\"dot\"\n            )\n        )\n    ]\n)\n\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#discussion",
    "href": "function-testing.html#discussion",
    "title": "2  Evaluator functions testing",
    "section": "2.6 Discussion",
    "text": "2.6 Discussion\nThe results show that the exact calculations and the Monte Carlo simulations are in good agreement. The average waiting times and overtimes are very close for both methods. The computation times for the exact calculations are also reasonable, indicating that the functions are efficient - at least for these limited instances.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#timeline",
    "href": "function-testing.html#timeline",
    "title": "2  Evaluator functions testing",
    "section": "2.7 Timeline",
    "text": "2.7 Timeline\nThis experiment has been started on 07-03-2025 and is expected to be finished on 14-03-2025.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "3  References",
    "section": "",
    "text": "References",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "service-time-with-no-shows.html",
    "href": "service-time-with-no-shows.html",
    "title": "service_time_with_no_shows",
    "section": "",
    "text": "Function Documentation\nservice_time_with_no_shows(s: List[float], q: float) -&gt; List[float]",
    "crumbs": [
      "Function documentation",
      "`service_time_with_no_shows`"
    ]
  },
  {
    "objectID": "service-time-with-no-shows.html#function-documentation",
    "href": "service-time-with-no-shows.html#function-documentation",
    "title": "service_time_with_no_shows",
    "section": "",
    "text": "Description\nAdjusts a distribution of service times to account for no-shows. The function scales the original service time distribution by the probability of a patient showing up (i.e., 1 - q) and then adds the no-show probability q to the service time for zero time slots.\n\n\nParameters\n\ns (List[float]): The original service time probability distribution. This list represents the probabilities associated with different service times.\nq (float): The probability of no-shows. This value should be between 0 and 1.\n\n\n\nReturns\n\nList[float]: The adjusted service time probability distribution where the no-show probability has been incorporated into the probability of zero service time.\n\n\n\nExample\n\nfrom functions import service_time_with_no_shows\n\n# Example usage\noriginal_distribution = [0.0, 0.5, 0.3, 0.2]\nno_show_probability = 0.1\nadjusted_distribution = service_time_with_no_shows(original_distribution, no_show_probability)\nprint(\"Adjusted distribution:\", adjusted_distribution)\n\nAdjusted distribution: [0.1, 0.45, 0.27, 0.18000000000000002]\n\n\n\nimport unittest\n\nclass TestServiceTimeWithNoShows(unittest.TestCase):\n    def test_adjust_distribution(self):\n        # Test with a known distribution and no-show probability\n        original_distribution = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.1\n        \n        # Expected adjustment: second element 0.1, \n        # other elements: multiplied by 0.9\n        expected_distribution = [0.1, 0.45, 0.27, 0.18]\n        \n        result = service_time_with_no_shows(original_distribution, no_show_probability)\n        \n        # Using almost equal check due to floating point arithmetic\n        for r, e in zip(result, expected_distribution):\n            self.assertAlmostEqual(r, e, places=5)\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n.\n----------------------------------------------------------------------\nRan 1 test in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`service_time_with_no_shows`"
    ]
  },
  {
    "objectID": "compute-convolutions.html",
    "href": "compute-convolutions.html",
    "title": "compute_convolutions",
    "section": "",
    "text": "Function Documentation\ncompute_convolutions(probabilities: List[float], N: int, q: float = 0.0) -&gt; Dict[int, np.ndarray]",
    "crumbs": [
      "Function documentation",
      "`compute_convolutions`"
    ]
  },
  {
    "objectID": "compute-convolutions.html#function-documentation",
    "href": "compute-convolutions.html#function-documentation",
    "title": "compute_convolutions",
    "section": "",
    "text": "Description\nComputes the k-fold convolution of a given probability mass function (PMF) for k from 1 up to N. Before computing the convolutions, the PMF is adjusted for no-shows using the provided no-show probability q via the service_time_with_no_shows function. Convolution is performed using NumPy’s np.convolve.\n\n\nParameters\n\nprobabilities (List[float]): The original PMF represented as a list where the index corresponds to a value (for instance, a service time) and the value at that index is its probability. This function is generic and does not have to be used solely for service times.\nN (int): The maximum number of convolutions to compute.\nq (float, optional): The probability of a no-show. Defaults to 0.0.\n\n\n\nReturns\n\nDict[int, np.ndarray]: A dictionary where each key k (with 1 ≤ k ≤ N) corresponds to the PMF resulting from the k-fold convolution of the adjusted PMF.\n\n\n\nExample\n\nimport numpy as np\nfrom functions import compute_convolutions, service_time_with_no_shows\n\n# Example usage\noriginal_pmf = [0.0, 0.5, 0.3, 0.2]\nN = 3\nno_show_probability = 0.1\n\nconvs = compute_convolutions(original_pmf, N, no_show_probability)\nfor k, pmf in convs.items():\n    print(f\"{k}-fold convolution: {pmf}\")\n\n1-fold convolution: [0.1  0.45 0.27 0.18]\n2-fold convolution: [0.01   0.09   0.2565 0.279  0.2349 0.0972 0.0324]\n3-fold convolution: [0.001    0.0135   0.06885  0.169425 0.234495 0.236925 0.160623 0.083106\n 0.026244 0.005832]\n\n\n\nimport unittest\n\nclass TestComputeConvolutions(unittest.TestCase):\n    def test_single_convolution(self):\n        # When N = 1, the result should be the adjusted PMF\n        original_pmf = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.1\n        N = 1\n        expected = np.array(service_time_with_no_shows(original_pmf, no_show_probability))\n        result = compute_convolutions(original_pmf, N, no_show_probability)\n        self.assertTrue(np.allclose(result[1], expected), \"Single convolution test failed\")\n\n    def test_multiple_convolutions(self):\n        # Test for N = 3 using a simple PMF\n        original_pmf = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.0  # No adjustment for simplicity\n        N = 3\n        result = compute_convolutions(original_pmf, N, no_show_probability)\n\n        # For N=1, result is the original pmf\n        self.assertTrue(np.allclose(result[1], np.array(original_pmf)))\n\n        # For higher convolutions, ensure the sum of probabilities remains 1 (within numerical precision)\n        for k in range(1, N + 1):\n            self.assertAlmostEqual(np.sum(result[k]), 1.0, places=5, msg=f\"Sum of probabilities for {k}-fold convolution is not 1\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`compute_convolutions`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html",
    "href": "calculate-objective-serv-time-lookup.html",
    "title": "calculate_objective_serv_time_lookup",
    "section": "",
    "text": "Function Documentation\ncalculate_objective_serv_time_lookup(schedule: List[int], d: int, convolutions: dict) -&gt; Tuple[float, float]",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html#function-documentation",
    "href": "calculate-objective-serv-time-lookup.html#function-documentation",
    "title": "calculate_objective_serv_time_lookup",
    "section": "",
    "text": "Description\nThis notebook provides documentation for the function calculate_objective_serv_time_lookup, which calculates an objective value (in terms of expected waiting time and expected spillover) based on a given schedule and pre-computed convolutions of a probability mass function (PMF).\nThe function uses the following inputs:\n\nschedule: A list of integers representing the number of patients scheduled in each time slot.\nd: An integer indicating the duration threshold for a time slot.\nconvolutions: A dictionary of precomputed convolutions of the service time PMF. The key 1 should correspond to the adjusted service time distribution (for example, one adjusted for no-shows), while keys greater than 1 are used for multiple patients in a time slot.\n\nThe function returns a tuple:\n\newt: The sum of expected waiting times over the schedule.\nesp: The expected spillover time (or overtime) after the final time slot.",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html#example-usage",
    "href": "calculate-objective-serv-time-lookup.html#example-usage",
    "title": "calculate_objective_serv_time_lookup",
    "section": "Example Usage",
    "text": "Example Usage\nA trivial example using a precomputed convolution dictionary with a degenerate PMF (i.e. always zero service time) is provided in the unit tests below.\n\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom functions import service_time_with_no_shows, compute_convolutions, calculate_objective_serv_time_lookup\n\n# For demonstration purposes, we use a trivial convolution dictionary.\noriginal_distribution = [0.0, 0.5, 0.3, 0.2]\nno_show_probability = 0.1\nadjusted_distribution = service_time_with_no_shows(original_distribution, no_show_probability)\nschedule_example = [2, 0, 0, 0, 0, 0, 1]\nN = sum(schedule_example)\nconvolutions_example = compute_convolutions(original_distribution, N, no_show_probability)\nd_example = 1\newt, esp = calculate_objective_serv_time_lookup(schedule_example, d_example, convolutions_example)\nprint(\"Adjusted Service Time Distribution: \", adjusted_distribution)\nprint(\"Expected Adjusted Service Time: \", np.dot(range(len(adjusted_distribution)), adjusted_distribution))\nprint(\"Expected Waiting Time:\", ewt)\nprint(\"Expected Spillover:\", esp)\n\nAdjusted Service Time Distribution:  [0.1, 0.45, 0.27, 0.18000000000000002]\nExpected Adjusted Service Time:  1.53\nExpected Waiting Time: 1.53\nExpected Spillover: 0.6300000000000001\n\n\n\nimport unittest\n\nclass TestCalculateObjectiveServTimeLookup(unittest.TestCase):\n    def setUp(self):\n        # Create a convolution dictionary\n        self.convolutions = convolutions_example\n        self.d = d_example\n\n    def test_single_time_slot(self):\n        # With one patient there will be no waiting and spillover (overtime) can be calculated by hand.\n        schedule = [1]\n        ewt, esp = calculate_objective_serv_time_lookup(schedule, self.d, self.convolutions)\n        self.assertAlmostEqual(ewt, 0.0, places=5, msg=\"Expected waiting time should be 0\")\n        self.assertAlmostEqual(esp, 0.6300000000000001, places=5, msg=\"Expected spillover should be 0\")\n\n    def test_zero_patients(self):\n        # If no patients are scheduled in a time slot, the process simply advances in time.\n        schedule = [0]\n        ewt, esp = calculate_objective_serv_time_lookup(schedule, self.d, self.convolutions)\n        self.assertAlmostEqual(ewt, 0.0, places=5, msg=\"Expected waiting time should be 0 when no patients\")\n        self.assertAlmostEqual(esp, 0.0, places=5, msg=\"Expected spillover should be 0 when no patients\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "get-neighborhood.html",
    "href": "get-neighborhood.html",
    "title": "get_neighborhood",
    "section": "",
    "text": "Function Documentation\nget_neighborhood(x: Union[List[int], np.ndarray], v_star: np.ndarray, ids: List[List[int]], verbose: bool = False) -&gt; np.ndarray",
    "crumbs": [
      "Function documentation",
      "`get_neighborhood`"
    ]
  },
  {
    "objectID": "get-neighborhood.html#function-documentation",
    "href": "get-neighborhood.html#function-documentation",
    "title": "get_neighborhood",
    "section": "",
    "text": "Description\nThe get_neighborhood function computes a set of neighbor solutions by adding together selected rows from the array v_star to an initial solution vector x. The selection of rows is determined by the list of index lists ids, where each inner list represents a combination of indices. After generating the candidate neighbors, the function filters out any that contain negative values. An optional verbose flag provides debugging output during execution.\n\n\nParameters\n\nx (Union[List[int], np.ndarray]):\nThe current solution vector. Can be provided as a list of integers or as a NumPy array.\nv_star (np.ndarray):\nA 2D NumPy array where each row is an adjustment vector. These vectors are used to modify the current solution to explore its neighborhood.\nids (List[List[int]]):\nA list of index lists, where each inner list specifies which rows from v_star to sum together. Each combination represents a potential adjustment to the current solution.\nverbose (bool, optional):\nA flag indicating whether to print debugging information (e.g., intermediate computations, progress messages). Defaults to False.\n\n\n\nReturns\n\nnp.ndarray:\nA 2D NumPy array where each row is a neighbor solution (i.e., the result of adding a valid combination of adjustment vectors from v_star to x). Only neighbors with all non-negative entries are included in the output.\n\n\n\nExample\n\nimport numpy as np\nfrom functions import get_neighborhood, get_v_star, powerset\n\n# Define an initial solution vector\nx = [3, 2, 1]\n\n# Generate adjustment vectors using get_v_star\n# For instance, create a set of cyclic adjustment vectors of length 3\nv_star = get_v_star(3)\n\n# Generate combinations of indices (e.g., using a powerset for switching 1 patient)\nids = powerset(range(3), size=1)\n\n# Generate the neighborhood (neighbors with non-negative entries only)\nneighbors = get_neighborhood(x, v_star, ids, echo=True)\nprint(\"Neighbor solutions:\")\nprint(neighbors)\n\nPrinting every 50th result\nv_star[0]: [-1  0  1]\nx, x', delta:\n[3 2 1],\n[2 2 2],\n[-1  0  1]\n-----------------\nv_star[1]: [ 1 -1  0]\nv_star[2]: [ 0  1 -1]\nSize of raw neighborhood: 3\nFiltered out: 0 schedules with negative values.\nSize of filtered neighborhood: 3\nNeighbor solutions:\n[[2 2 2]\n [4 1 1]\n [3 3 0]]\n\n\n\nimport unittest\nimport numpy as np\nfrom functions import get_neighborhood, get_v_star, powerset\n\nclass TestGetNeighborhood(unittest.TestCase):\n    def test_non_negative_neighbors(self):\n        # Test with a simple solution vector and adjustment vectors\n        x = [3, 2, 1]\n        v_star = get_v_star(3)\n        ids = powerset(range(3), size=1)\n        \n        neighbors = get_neighborhood(x, v_star, ids, echo=False)\n        \n        # Ensure that no neighbor has negative entries\n        self.assertTrue(np.all(neighbors &gt;= 0), \"Some neighbor solutions contain negative values\")\n    \n    def test_neighborhood_shape(self):\n        # Test that the neighborhood returns a NumPy array with the proper dimensions\n        x = [3, 2, 1]\n        v_star = get_v_star(3)\n        ids = powerset(range(3), size=1)\n        neighbors = get_neighborhood(x, v_star, ids, echo=False)\n        self.assertIsInstance(neighbors, np.ndarray, \"Neighborhood is not a NumPy array\")\n        # The number of rows should equal the number of valid combinations in ids (after filtering negatives)\n        self.assertLessEqual(neighbors.shape[0], len(ids), \"Neighborhood size is larger than expected\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.002s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`get_neighborhood`"
    ]
  },
  {
    "objectID": "local-search.html",
    "href": "local-search.html",
    "title": "local_search",
    "section": "",
    "text": "Function Documentation\nlocal_search(x: Union[List[int], np.ndarray], d: int, convolutions: Dict[int, np.ndarray], w: float, v_star: np.ndarray, size: int = 2, echo: bool = False) -&gt; Tuple[np.ndarray, float]",
    "crumbs": [
      "Function documentation",
      "`local_search`"
    ]
  },
  {
    "objectID": "local-search.html#function-documentation",
    "href": "local-search.html#function-documentation",
    "title": "local_search",
    "section": "",
    "text": "Description\nThe local_search function optimizes a schedule by iteratively exploring its neighborhood. Starting with an initial solution x, the function computes its objective value using the precomputed convolutions of the service time probability mass function. The neighborhood is generated by combining adjustment vectors from v_star (using a powerset-based approach) and filtering out candidates that contain negative values. The search continues until no further improvement is found for neighborhoods up to the specified size. The objective function combines expected average waiting time per patient and spillover time weighted by w.\n\n\nParameters\n\nx (Union[List[int], np.ndarray]):\nThe initial solution vector representing the schedule. It can be provided as a list of integers or as a NumPy array.\nd (int):\nThe duration threshold for a time slot. It is used to adjust the service process and waiting time distribution.\nconvolutions (Dict[int, np.ndarray]):\nA dictionary containing precomputed convolutions of the service time PMF. The key 1 represents the adjusted service time distribution, and other keys represent the convolution for the corresponding number of scheduled patients.\nw (float):\nThe weighting factor for combining the two performance objectives: expected waiting time and expected spillover time.\nv_star (np.ndarray):\nA 2D NumPy array of adjustment vectors. Each row in v_star is used to modify the current solution vector in order to generate its neighborhood.\nsize (int, optional):\nThe maximum number of patients to switch (i.e., the size of the neighborhood to explore) during the local search. Defaults to 2.\necho (bool, optional):\nA flag that, when set to True, prints progress and debugging messages during the search process. Defaults to False.\n\n\n\nReturns\n\nTuple[np.ndarray, float]:\nA tuple containing:\n\nThe best solution found as a 1D NumPy array.\nThe corresponding cost (objective value) as a float.\n\n\n\n\nExample\n\nimport numpy as np\nfrom functions import local_search, calculate_objective_serv_time_lookup, compute_convolutions, get_v_star, powerset\n\nfrom typing import List, Dict, Tuple, Union\n\ndef ways_to_distribute(N: int, T: int) -&gt; List[List[int]]:\n    \"\"\"\n    Compute all possible ways to distribute N identical items into T bins.\n    \n    Each distribution is represented as a list of T nonnegative integers whose sum is N.\n    \n    Parameters:\n        N (int): Total number of identical items.\n        T (int): Number of bins.\n        \n    Returns:\n        List[List[int]]: A list of distributions. Each distribution is a list of T integers that sum to N.\n        \n    Example:\n        &gt;&gt;&gt; ways_to_distribute(3, 2)\n        [[0, 3], [1, 2], [2, 1], [3, 0]]\n    \"\"\"\n    # Base case: only one bin left, all items must go into it.\n    if T == 1:\n        return [[N]]\n    \n    distributions = []\n    # Iterate over possible numbers of items in the first bin\n    for i in range(N + 1):\n        # Recursively distribute the remaining items among the remaining bins.\n        for distribution in ways_to_distribute(N - i, T - 1):\n            distributions.append([i] + distribution)\n            \n    return distributions\n  \ndef choose_best_solution(solutions: List[np.ndarray], d: int, convs: Dict[int, np.ndarray], w: float, v_star: np.ndarray) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"\n    Choose the best solution from a list of solutions based on the objective function.\n    \n    Parameters:\n        solutions (List[np.ndarray]): A list of solution vectors.\n        d (int): Duration threshold for a time slot.\n        convs (Dict[int, np.ndarray]): Precomputed convolutions of the service time PMF.\n        w (float): Weighting factor for the objective function.\n        \n    Returns:\n        Tuple[np.ndarray, float]: The best solution and its corresponding cost.\n    \"\"\"\n    best_solution = None\n    best_cost = float('inf')\n    \n    for solution in solutions:\n        waiting_time, spillover = calculate_objective_serv_time_lookup(solution, d, convs)\n        cost = w * waiting_time /N + (1 - w) * spillover\n        if cost &lt; best_cost:\n            best_solution = solution\n            best_cost = cost\n            \n    return np.array(best_solution), best_cost\n\n# Example schedule: initial solution vector\nx_initial = [3, 2, 1, 0]\nT = len(x_initial)\nN = sum(x_initial)\n\n# Duration threshold for a time slot\nd = 5\n\n# Example probability mass function and no-show probability\nservice_time = np.zeros(11)\nservice_time[3] = 0.2\nservice_time[5] = 0.3\nservice_time[8] = 0.5\nq = 0.1\n\n# Compute convolutions (precomputed service time distributions)\nconvs = compute_convolutions(service_time, N=N, q=q)\n\n# Weighting factor for the objective function\nw = 0.5\n\n# Generate adjustment vectors for the schedule (v_star)\nv_star = get_v_star(len(x_initial))\n\n# Perform local search to optimize the schedule\nbest_solution, best_cost = local_search(x_initial, d, convs, w, v_star, size=T, echo=True)\n\nprint(\"Best Solution:\", best_solution)\nprint(\"Best Cost:\", best_cost)\n\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 3\nFound better solution: [2 2 1 1], cost: 10.564046280924003\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nFound better solution: [1 2 1 2], cost: 10.083192713700003\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nFound better solution: [2 1 1 2], cost: 9.894705450000002\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 6\nRunning local search with switching 3 patient(s)\nSize of neighborhood: 4\nBest Solution: [2 1 1 2]\nBest Cost: 9.894705450000002\n\n\n\nimport unittest\nimport numpy as np\nfrom functions import local_search, compute_convolutions, get_v_star\n\nclass TestLocalSearch(unittest.TestCase):\n    def test_local_search_improvement(self):\n        # Set up a simple test with a known schedule and parameters\n        x_initial = [3, 2, 1, 0]\n        T = len(x_initial)\n        N = sum(x_initial)\n        d = 5\n        service_time = np.zeros(11)\n        service_time[3] = 0.2\n        service_time[5] = 0.3\n        service_time[8] = 0.5\n        q = 0.1\n        convs = compute_convolutions(service_time, N=N, q=q)\n        w = 0.5\n        v_star = get_v_star(len(x_initial))\n        \n        # Perform local search\n        best_solution, best_cost = local_search(x_initial, d, convs, w, v_star, size=T, echo=False)\n        print(\"Best Solution:\", best_solution, \"Best Cost:\", best_cost)\n        \n        # Iterate over all solutions and choose best solution\n        solutions = ways_to_distribute(N, T)\n        best_solution_brute, best_cost_brute = choose_best_solution(solutions, d, convs, w, v_star)\n        print(\"Best Brute-force Solution:\", best_solution_brute, \"Best Brute-force Cost:\", best_cost_brute)\n        \n        # Verify that the local search solution is equal to the brute-force solution\n        self.assertTrue(np.array_equal(best_solution, best_solution_brute), \"The local search solution should match the brute-force solution.\")\n        \n        # Verify that the returned solution has the same length as the initial schedule\n        self.assertEqual(len(best_solution), len(x_initial), \"The optimized solution should have the same length as the initial solution.\")\n        \n        # Check that the cost is a float and that a solution is returned\n        self.assertIsInstance(best_cost, float, \"Cost should be a float value.\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n.\n----------------------------------------------------------------------\nRan 1 test in 0.011s\n\nOK\n\n\nBest Solution: [2 1 1 2] Best Cost: 9.894705450000002\nBest Brute-force Solution: [2 1 1 2] Best Brute-force Cost: 9.894705450000002",
    "crumbs": [
      "Function documentation",
      "`local_search`"
    ]
  }
]