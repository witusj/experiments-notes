[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Appointment Scheduling Experiments",
    "section": "",
    "text": "To Do",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#to-do",
    "href": "index.html#to-do",
    "title": "Appointment Scheduling Experiments",
    "section": "",
    "text": "Add a brief introduction to the project\nEvaluator Functions\n\nDocument and test the evaluator functions\nRun experiments using the evaluator functions\n\nSearcher Functions\n\nDocument and test the search functions\nRun experiments using the search functions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "function-testing.html",
    "href": "function-testing.html",
    "title": "2  Evaluator functions testing",
    "section": "",
    "text": "2.1 Objective\nIn this experiment we will test whether the functions for calculating the objective values work properly and efficiently.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#background",
    "href": "function-testing.html#background",
    "title": "2  Evaluator functions testing",
    "section": "2.2 Background",
    "text": "2.2 Background\nFor developing new methods for optimizing appointment schedules it is necessary that the function for calculating objective values works properly. It is also important that the function is efficient, as it will be used in optimization algorithms that will be run many times.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#hypothesis",
    "href": "function-testing.html#hypothesis",
    "title": "2  Evaluator functions testing",
    "section": "2.3 Hypothesis",
    "text": "2.3 Hypothesis\nThe functions for calculating that have been developed are working fast and generate correct results.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#methodology",
    "href": "function-testing.html#methodology",
    "title": "2  Evaluator functions testing",
    "section": "2.4 Methodology",
    "text": "2.4 Methodology\n\n2.4.1 Tools and Materials\nFor testing the correct working of the functions used to calculate objective values we will compare the exact calculation to results from Monte Carlo (MC) simulations. The MC simulations allow modeling the system and replicating closely the actual process of patients arriving and being served. The exact calculation is based on the convolution of the service time distribution and the number of patients arriving at each time slot.\n\n\n2.4.2 Experimental Design\nWe will define some typical instances of schedules and calculate the objective values for them both using the exact method as well as through MC simulations. We will then compare the results.\n\n\n2.4.3 Variables\n\nIndependent Variables:\n\nDifferent instances of appointment schedules.\n\nDependent Variables:\n\nObjective value results from exact calculations and simulations.\nSpeed indicators\n\n\n\n\n2.4.4 Setup\nWe have defined the following test cases:\n\nimport numpy as np\nimport pandas as pd\nimport time\nimport plotly.graph_objects as go\nfrom functions import service_time_with_no_shows, compute_convolutions, compute_convolutions_fft, calculate_objective_serv_time_lookup\n\n# Parameters\nd = 5\nq = 0.1\n    \n# Create service time distribution\nservice_time = np.zeros(11)\nservice_time[3] = 0.2\nservice_time[5] = 0.3\nservice_time[8] = 0.5\n\naverage_service_time = np.dot(range(len(service_time)), service_time)\nprint(f\"Average service time: {average_service_time}\")\n    \n# Different schedule patterns with the same total number of patients (except for test schedule)\nschedules = [\n    (\"Calibration\", [2, 0, 0, 0, 0, 1]),\n    (\"Uniform\", [2, 2, 2, 2]),\n    (\"Decreasing\", [5, 2, 1, 0]),\n    (\"Increasing\", [0, 1, 2, 5]),\n    (\"Front-heavy\", [4, 4, 0, 0]),\n    (\"Back-heavy\", [0, 0, 4, 4]),\n    (\"Alternating\", [4, 0, 4, 0]),\n    (\"Bailey-rule\", [2, 1, 1, 1, 1, 1, 1])  # Schedule 2 initially, then 1 each slot\n]\n\n# Set number of simulations for Monte Carlo simulation\nnr_simulations = 1000\n\n# Create dictionary for storing results\nresults_dict = {'schedule_name': [], 'average_waiting_time': [], 'average_overtime': [], 'expected_waiting_time': [], 'expected_overtime': [], 'average_computation_time': []}\nresults_dict['schedule_name'] = [s[0] for s in schedules]\n\nAverage service time: 6.1\n\n\nThe “Calibration” test set is used to calibrate the simulation results with the exact results. For this schedule, the exact results can be easily calculated by hand. The average service time after correcting for no-shows for one patient is 5.49 (see below) and only the second patient in this example will experience waiting times. So the average expected waiting time is 5.49 / 3 = 1.83.\nThe expected overtime is is the expected spillover time caused by the last patient in the schedule. As there are no patients before the last patient in the last interval, the spillover time distribution is simply distribution of the event that the (adjusted) service time will exceed the interval time. For the case that overtime is 3 (8 - 5), the probability is 0.45 and for other values it is 0.55. So the expected overtime is 0.45 * 3 + 0.55 * 0 = 1.35.\nThe other test sets are used to examine the performance of the functions for different schedule patterns.\n\n\n2.4.5 Sample Size and Selection\nSample Size: - For each schedule instance we will run 1000 simulations.\nSample Selection: - During each simulation for each patient a random service time will be sampled from the distribution (adjusted for no-shows).\n\n\n2.4.6 Experimental Procedure\n\n2.4.6.1 Step 1: Adjust the service time distribution for no-shows.\n\n# Adjust service time distribution for no-shows and compare to original\nservice_time_no_shows = service_time_with_no_shows(service_time, q)\nprint(f\"Service time distribution with no-shows: {service_time_no_shows}\")\n\naverage_service_time_no_shows = np.dot(range(len(service_time_no_shows)), service_time_no_shows)\nprint(f\"Average service time with no-shows: {average_service_time_no_shows}\")\n\nService time distribution with no-shows: [0.1, 0.0, 0.0, 0.18000000000000002, 0.0, 0.27, 0.0, 0.0, 0.45, 0.0, 0.0]\nAverage service time with no-shows: 5.49\n\n\n\n\n2.4.6.2 Step 2: Monte carlo simulation\nFor each schedule instance:\n\nCalculate \\(N\\) and \\(T\\), the total number of patients and the total time of the schedule.\nFor each simulation:\n\nSample random service times for each of the \\(N\\) patient from service times distribution with no-shows.\nCalculate the the average waiting time and the overtime for the schedule using a Lindley recursion, starting at \\(t = 0\\) and ending at \\(t = T - 1\\).\n\n\n\nimport numpy as np\nfrom typing import List, Tuple, Union\n\ndef simulate_schedule(\n    schedule: List[int],\n    service_time_no_shows: Union[List[float], np.ndarray],\n    d: int,\n    nr_simulations: int\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Runs a Monte Carlo simulation for a single schedule.\n\n    This function simulates patient scheduling over multiple time slots and computes the average waiting \n    time per patient and the average overtime across all simulation iterations. Each time slot has a duration \n    threshold `d`. Service times for patients are sampled based on the provided probability mass function.\n\n    Parameters:\n        schedule (List[int]): A list where each element represents the number of patients scheduled in each time slot.\n        service_time_no_shows (Union[List[float], np.ndarray]): A probability mass function (PMF) for service times.\n        d (int): The duration threshold for a time slot.\n        nr_simulations (int): The number of simulation iterations to run.\n\n    Returns:\n        Tuple[float, float]: A tuple containing:\n            - The average waiting time per patient across simulations.\n            - The average overtime across simulations.\n    \"\"\"\n    N: int = sum(schedule)  # Total number of patients\n    T: int = len(schedule)  # Total number of time slots\n\n    total_waiting_time: float = 0.0\n    total_overtime: float = 0.0\n\n    for _ in range(nr_simulations):\n        cum_waiting_time: float = 0.0\n\n        # --- Process the first time slot ---\n        num_patients: int = schedule[0]\n        # Generate random service times for the first slot\n        sampled: np.ndarray = np.random.choice(\n            range(len(service_time_no_shows)),\n            size=num_patients,\n            p=service_time_no_shows\n        )\n\n        if num_patients == 0:\n            waiting_time: float = 0.0\n            spillover_time: float = 0.0\n        elif num_patients == 1:\n            waiting_time = 0.0\n            spillover_time = max(0, sampled[0])\n        else:\n            # For more than one patient, the waiting time is the cumulative sum\n            # of the service times for all but the last patient.\n            waiting_time = float(sum(np.cumsum(sampled[:-1])))\n            spillover_time = max(0, sum(sampled) - d)\n        cum_waiting_time += waiting_time\n\n        # --- Process the remaining time slots ---\n        for t in range(1, T):\n            num_patients = schedule[t]\n            # Generate random service times for time slot t\n            sampled = np.random.choice(\n                range(len(service_time_no_shows)),\n                size=num_patients,\n                p=service_time_no_shows\n            )\n            if num_patients == 0:\n                waiting_time = 0.0\n                spillover_time = max(0, spillover_time - d)\n            elif num_patients == 1:\n                waiting_time = spillover_time\n                spillover_time = max(0, spillover_time + sampled[0] - d)\n            else:\n                # Each patient waits the current spillover,\n                # plus additional waiting due to the service times of those ahead.\n                waiting_time = spillover_time * num_patients + sum(np.cumsum(sampled[:-1]))\n                spillover_time = max(0, spillover_time + sum(sampled) - d)\n            cum_waiting_time += waiting_time\n\n        # Accumulate normalized waiting time (per patient) and overtime\n        total_waiting_time += cum_waiting_time / N\n        total_overtime += spillover_time\n\n    avg_waiting_time: float = total_waiting_time / nr_simulations\n    avg_overtime: float = total_overtime / nr_simulations\n\n    return avg_waiting_time, avg_overtime\n\n\n# Loop through the schedules\nfor schedule_name, schedule in schedules:\n    N = sum(schedule)\n    T = len(schedule)\n    print(f\"Schedule: {schedule_name} {schedule}, N: {N}, T: {T}\")\n    \n    avg_waiting_time, avg_overtime = simulate_schedule(schedule, service_time_no_shows, d, nr_simulations)\n    \n    print(f\"Average waiting time: {avg_waiting_time}, average overtime: {avg_overtime}\")\n    results_dict['average_waiting_time'].append(avg_waiting_time)\n    results_dict['average_overtime'].append(avg_overtime)\n\nSchedule: Calibration [2, 0, 0, 0, 0, 1], N: 3, T: 6\nAverage waiting time: 1.8563333333333518, average overtime: 1.365\nSchedule: Uniform [2, 2, 2, 2], N: 8, T: 4\nAverage waiting time: 11.777375, average overtime: 24.064\nSchedule: Decreasing [5, 2, 1, 0], N: 8, T: 4\nAverage waiting time: 16.7825, average overtime: 23.804\nSchedule: Increasing [0, 1, 2, 5], N: 8, T: 4\nAverage waiting time: 12.47625, average overtime: 29.712\nSchedule: Front-heavy [4, 4, 0, 0], N: 8, T: 4\nAverage waiting time: 16.810125, average overtime: 24.081\nSchedule: Back-heavy [0, 0, 4, 4], N: 8, T: 4\nAverage waiting time: 16.473875, average overtime: 33.617\nSchedule: Alternating [4, 0, 4, 0], N: 8, T: 4\nAverage waiting time: 14.096875, average overtime: 23.703\nSchedule: Bailey-rule [2, 1, 1, 1, 1, 1, 1], N: 8, T: 7\nAverage waiting time: 6.5575, average overtime: 10.043\n\n\n\n\n2.4.6.3 Step 3: Exact calculation\nFor each schedule instance run 10 evaluations of the objective value using the exact method and calculate the average waiting time and overtime.\n\n# Loop through the schedules, run 10 evaluations, calculate average waiting time and overtime for each schedule, calculate average computation times and store the results in the results dictionary\n\nfor schedule_name, schedule in schedules:\n    N = sum(schedule)\n    T = len(schedule)\n    print(f\"Schedule: {schedule_name} {schedule}, N: {N}, T: {T}\")\n    convolutions = compute_convolutions(service_time, N, q)\n    \n    total_time = 0\n    # Exact calculation over 10 evaluations\n    for i in range(10):\n        start_time = time.time()\n        # Calculate the objective value using the exact method\n        waiting_time, overtime = calculate_objective_serv_time_lookup(schedule, d, convolutions)\n        elapsed_time = time.time() - start_time\n        total_time += elapsed_time\n        \n    avg_time = total_time / 10\n    print(f\"Expected waiting time: {waiting_time / N}, Expected overtime: {overtime}\")\n    results_dict['expected_waiting_time'].append(waiting_time / N)\n    results_dict['expected_overtime'].append(overtime)\n    results_dict['average_computation_time'].append(avg_time)\n\nSchedule: Calibration [2, 0, 0, 0, 0, 1], N: 3, T: 6\nExpected waiting time: 1.83, Expected overtime: 1.35\nSchedule: Uniform [2, 2, 2, 2], N: 8, T: 4\nExpected waiting time: 11.816608810500004, Expected overtime: 24.064827562971374\nSchedule: Decreasing [5, 2, 1, 0], N: 8, T: 4\nExpected waiting time: 16.715096633250006, Expected overtime: 23.92331748953545\nSchedule: Increasing [0, 1, 2, 5], N: 8, T: 4\nExpected waiting time: 12.5150625, Expected overtime: 29.856120798600017\nSchedule: Front-heavy [4, 4, 0, 0], N: 8, T: 4\nExpected waiting time: 16.715970000000002, Expected overtime: 23.92482686022145\nSchedule: Back-heavy [0, 0, 4, 4], N: 8, T: 4\nExpected waiting time: 16.715970000000002, Expected overtime: 33.92194762296002\nSchedule: Alternating [4, 0, 4, 0], N: 8, T: 4\nExpected waiting time: 14.233406400000002, Expected overtime: 23.95841024194273\nSchedule: Bailey-rule [2, 1, 1, 1, 1, 1, 1], N: 8, T: 7\nExpected waiting time: 6.439653759761102, Expected overtime: 9.820826086143853",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#results",
    "href": "function-testing.html#results",
    "title": "2  Evaluator functions testing",
    "section": "2.5 Results",
    "text": "2.5 Results\nComparison of the results of the exact calculations with the results of the Monte Carlo simulations.\n\ndf_results = pd.DataFrame.from_dict(results_dict)\ndf_results\n\n\n\n\n\n\n\n\n\nschedule_name\naverage_waiting_time\naverage_overtime\nexpected_waiting_time\nexpected_overtime\naverage_computation_time\n\n\n\n\n0\nCalibration\n1.856333\n1.365\n1.830000\n1.350000\n0.000093\n\n\n1\nUniform\n11.777375\n24.064\n11.816609\n24.064828\n0.000175\n\n\n2\nDecreasing\n16.782500\n23.804\n16.715097\n23.923317\n0.000077\n\n\n3\nIncreasing\n12.476250\n29.712\n12.515063\n29.856121\n0.000069\n\n\n4\nFront-heavy\n16.810125\n24.081\n16.715970\n23.924827\n0.000065\n\n\n5\nBack-heavy\n16.473875\n33.617\n16.715970\n33.921948\n0.000062\n\n\n6\nAlternating\n14.096875\n23.703\n14.233406\n23.958410\n0.000057\n\n\n7\nBailey-rule\n6.557500\n10.043\n6.439654\n9.820826\n0.000127\n\n\n\n\n\n\n\n\n\n# Extract schedule names from the dataframe\nschedule_names = df_results['schedule_name'].tolist()\n\n# Create new x-values for simulation and exact results\nx_sim = [f\"{s}&lt;br&gt;Simulation\" for s in schedule_names]\nx_exact = [f\"{s}&lt;br&gt;Exact\" for s in schedule_names]\n\n# Extract values from the dataframe\nsim_wait = df_results['average_waiting_time'].tolist()\nsim_over = df_results['average_overtime'].tolist()\nexact_wait = df_results['expected_waiting_time'].tolist()\nexact_over = df_results['expected_overtime'].tolist()\n\n# Create a combined category list with an empty category between the two groups\ncategories = x_sim + [\"\"] + x_exact\n\n# Create the figure\nfig = go.Figure()\n\n# Simulation bar traces (stacked)\nfig.add_trace(go.Bar(\n    x=x_sim,\n    y=sim_wait,\n    name='Waiting Time',\n    marker_color='blue'\n))\nfig.add_trace(go.Bar(\n    x=x_sim,\n    y=sim_over,\n    name='Overtime',\n    marker_color='red'\n))\n\n# Exact bar traces (stacked)\nfig.add_trace(go.Bar(\n    x=x_exact,\n    y=exact_wait,\n    name='Waiting Time',\n    marker_color='blue',\n    showlegend=False  # legend already shown for waiting time above\n))\nfig.add_trace(go.Bar(\n    x=x_exact,\n    y=exact_over,\n    name='Overtime',\n    marker_color='red',\n    showlegend=False  # legend already shown for overtime above\n))\n\n# Update x-axis to use the full category array (which includes the gap)\nfig.update_xaxes(\n    tickangle=45,\n    categoryorder='array',\n    categoryarray=categories\n)\n\n# Optionally, adjust the vertical dotted line.\n# For example, you can remove it if the gap is sufficient or reposition it.\nfig.update_layout(\n    title=\"Comparison of Simulation vs. Exact Results\",\n    xaxis_title=\"Schedule Type\",\n    yaxis_title=\"Time\",\n    barmode='stack',\n    shapes=[\n        dict(\n            type=\"line\",\n            xref=\"paper\", x0=0.5, x1=0.5,\n            yref=\"paper\", y0=0, y1=1,\n            line=dict(\n                color=\"black\",\n                width=2,\n                dash=\"dot\"\n            )\n        )\n    ]\n)\n\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#discussion",
    "href": "function-testing.html#discussion",
    "title": "2  Evaluator functions testing",
    "section": "2.6 Discussion",
    "text": "2.6 Discussion\nThe results show that the exact calculations and the Monte Carlo simulations are in good agreement. The average waiting times and overtimes are very close for both methods. The computation times for the exact calculations are also reasonable, indicating that the functions are efficient - at least for these limited instances.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "function-testing.html#timeline",
    "href": "function-testing.html#timeline",
    "title": "2  Evaluator functions testing",
    "section": "2.7 Timeline",
    "text": "2.7 Timeline\nThis experiment has been started on 07-03-2025 and is expected to be finished on 14-03-2025.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evaluator functions testing</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html",
    "href": "xgboost-pairwise-ranking-large.html",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "",
    "text": "3.1 Objective\nObjective: Testing the performance of an XGBoost model trained for ranking pairwise schedules.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#background",
    "href": "xgboost-pairwise-ranking-large.html#background",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.2 Background",
    "text": "3.2 Background\nIn this experiment we develop a Machine Learning model using XGBoost that can evaluate two neighboring schedules and rank them according to preference. This ranking model can be applied to quickly guide the search process towards a ‘good enough’ solution.\nThe choice of using an ordinal model instead of a cardinal model is based on the consideration that it is significantly easier to determine whether alternative A is superior to B than to quantify the exact difference between A and B. This makes intuitive sense when considering the scenario of holding two identical-looking packages and deciding which one is heavier, as opposed to estimating the precise weight difference between them. (ho_ordinal_2000?).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#hypothesis",
    "href": "xgboost-pairwise-ranking-large.html#hypothesis",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.3 Hypothesis",
    "text": "3.3 Hypothesis\nAn XGBoost ranking model achieves superior computational efficiency compared to evaluating each element of a pair individually, leading to faster overall performance in ranking tasks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#methodology",
    "href": "xgboost-pairwise-ranking-large.html#methodology",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.4 Methodology",
    "text": "3.4 Methodology\n\n3.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBClassifier interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\nimport random\nfrom scipy.optimize import minimize\nfrom itertools import combinations\n\n\n\n3.4.2 Experimental Design\nTo compare an XGBoost Machine Learning model with a simple evaluation of each individual element of the pair, we will use a pairwise ranking approach. The objective is to rank two neighboring schedules according to preference.\n\nfrom functions import compute_convolutions\n\nN = 22 # Number of patients\nT = 20 # Number of intervals\nd = 5 # Length of each interval\nmax_s = 20 # Maximum service time\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.1 # Weight for the waiting time in objective function\nl = 10\nnum_schedules = 100000 # Number of schedules to sample\n\n# Create service time distribution\ndef generate_weighted_list(max_s, l, i):\n    # Initialize an array of T+1 values, starting with zero\n    values = np.zeros(T + 1)\n    \n    # Objective function: Sum of squared differences between current weighted average and the desired l\n    def objective(x):\n        weighted_avg = np.dot(np.arange(1, T + 1), x) / np.sum(x)\n        return (weighted_avg - l) ** 2\n\n    # Constraint: The sum of the values from index 1 to T must be 1\n    constraints = ({\n        'type': 'eq',\n        'fun': lambda x: np.sum(x) - 1\n    })\n    \n    # Bounds: Each value should be between 0 and 1\n    bounds = [(0, 1)] * T\n\n    # Initial guess: Random distribution that sums to 1\n    initial_guess = np.random.dirichlet(np.ones(T))\n\n    # Optimization: Minimize the objective function subject to the sum and bounds constraints\n    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n\n    # Set the values in the array (index 0 remains 0)\n    values[1:] = result.x\n\n    # Now we need to reorder the values as per the new requirement\n    first_part = np.sort(values[1:i+1])  # Sort the first 'i' values in ascending order\n    second_part = np.sort(values[i+1:])[::-1]  # Sort the remaining 'T-i' values in descending order\n    \n    # Combine the sorted parts back together\n    values[1:i+1] = first_part\n    values[i+1:] = second_part\n    \n    return values\n\ni = 5  # First 5 highest values in ascending order, rest in descending order\ns = generate_weighted_list(max_s, l, i)\nprint(s)\nprint(\"Sum:\", np.sum(s[1:]))  # This should be 1\nprint(\"Weighted service time:\", np.dot(np.arange(1, T + 1), s[1:]))  # This should be close to l\n\nconvolutions = compute_convolutions(s, N, q)\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\nwith open(file_path_parameters, 'wb') as f:\n    pickle.dump({\n      'N': N,\n      'T': T,\n      'd': d,\n      'max_s': max_s,\n      'q': q,\n      'w': w,\n      'l': l,\n      'num_schedules': num_schedules,\n      'convolutions': convolutions\n      }, f)\n    print(f\"Data saved successfully to '{file_path_parameters}'\")\n\n[0.         0.00404263 0.03357069 0.03766083 0.05965914 0.21545433\n 0.13252345 0.1135196  0.07931712 0.07901999 0.05399852 0.04090512\n 0.03947682 0.03845887 0.02797408 0.02142202 0.01606378 0.0023518\n 0.00205776 0.00182846 0.00069498]\nSum: 1.0000000001765827\nWeighted service time: 7.494846695040667\nData saved successfully to 'datasets/parameters_22_20_10.pkl'\n\n\nWe will create a random set of pairs of neighboring schedules with \\(N = 22\\) patients and \\(T = 20\\) intervals of length \\(d = 5\\).\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict which of the two neighboring schedules has the lowest objective value. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value and then ranked.\n\n\n3.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables: A list with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n3.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n3.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 244663.0 mln. For this experiment we will be using a relatively small sample of 100000 pairs of schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n3.4.6 Experimental Procedure\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Objective values\"]\n    D --&gt; |Rank objectives| E[\"Labels: Rankings\"]\n    E --&gt; |\"Split dataset\"| F[\"Training set\"]\n    E --&gt; |\"Split dataset\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\nStep 1: Randomly select a subset of schedules.\n\nfrom functions import create_random_schedules\n\nstart = time.time()\n# schedules = random_combination_with_replacement(T, N, num_schedules)\nschedules = create_random_schedules(T, N, num_schedules)\nprint(f\"Sampled: {len(schedules):,} schedules\\n\")\nh = random.choices(range(len(schedules)), k=7)\nprint(f\"Sampled schedules: {h}\")\nfor i in h:\n    print(f\"Schedule: {schedules[i]}\")\nend = time.time()\ndata_prep_time = end - start\n\nprint(f\"\\nProcessing time: {data_prep_time} seconds\\n\")\n\nSampled: 100,000 schedules\n\nSampled schedules: [78971, 87707, 21018, 26420, 22393, 82424, 93404]\nSchedule: [2, 0, 3, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1]\nSchedule: [2, 1, 2, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 0, 5, 2, 0, 0, 1]\nSchedule: [1, 0, 1, 0, 2, 1, 2, 4, 2, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 0]\nSchedule: [1, 1, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 0, 1, 3, 1, 1, 0, 0, 2]\nSchedule: [2, 2, 0, 1, 1, 5, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 3, 2, 0]\nSchedule: [0, 1, 3, 1, 2, 1, 0, 0, 1, 2, 3, 2, 0, 0, 0, 2, 0, 1, 1, 2]\nSchedule: [2, 0, 0, 2, 2, 4, 0, 2, 0, 0, 1, 0, 2, 1, 3, 2, 0, 0, 1, 0]\n\nProcessing time: 0.6842160224914551 seconds\n\n\n\nStep 2: Create pairs of neighboring schedules.\n\nfrom functions import get_v_star\n\ndef create_neighbors_list(s: list[int], v_star: np.ndarray) -&gt; (list[int], list[int]):\n    \"\"\"\n    Create a set of pairs of schedules that are from the same neighborhood.\n    \n    Parameters:\n      s (list[int]): A list of integers with |s| = T and sum N.\n      v_star (np.ndarray): Precomputed vectors V* of length T.\n      \n    Returns:\n      tuple(list[int], list[int]): A pair of schedules.\n    \"\"\"\n    T = len(s)\n\n    # Precompute binomial coefficients (weights for random.choices)\n    binom_coeff = [math.comb(T, i) for i in range(1, T)]\n\n    # Choose a random value of i with the corresponding probability\n    i = random.choices(range(1, T), weights=binom_coeff)[0]\n\n    # Instead of generating the full list of combinations, sample one directly\n    j = random.sample(range(T), i)\n    \n    s_p = s.copy()\n    for k in j:\n        s_temp = np.array(s_p) + v_star[k]\n        s_temp = s_temp.astype(int)\n        if np.all(s_temp &gt;= 0):\n            s_p = s_temp.astype(int).tolist()\n        \n    return s, s_p\n\nstart = time.time()\nv_star = get_v_star(T)\nneighbors_list = [create_neighbors_list(schedule, v_star) for schedule in schedules] # This can be done in parellel to improve speed\nend = time.time()\nfor i in h:\n    original_schedule = neighbors_list[i][0]\n    neighbor_schedule = neighbors_list[i][1]\n    difference = [int(x - y) for x, y in zip(neighbors_list[i][0], neighbors_list[i][1])]\n    print(f\"Neighbors\\n{original_schedule}\\n{neighbor_schedule}\\n{difference}\")\ntraining_set_feat_time = end - start\nprint(f\"\\nProcessing time: {training_set_feat_time} seconds\\n\")\n\nNeighbors\n[2, 0, 3, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1]\n[2, 0, 4, 0, 1, 2, 2, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1]\n[0, 0, -1, 1, 0, 0, 0, 0, -1, 1, 0, -1, 1, -1, 1, -1, 1, -1, 1, 0]\nNeighbors\n[2, 1, 2, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 0, 5, 2, 0, 0, 1]\n[3, 1, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 0, 5, 2, 0, 0, 1]\n[-1, 0, 1, -1, 1, 0, 0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\nNeighbors\n[1, 0, 1, 0, 2, 1, 2, 4, 2, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 0]\n[1, 0, 1, 1, 1, 2, 2, 3, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0]\n[0, 0, 0, -1, 1, -1, 0, 1, 0, 0, 0, -1, 0, 1, 0, -1, 1, 0, 0, 0]\nNeighbors\n[1, 1, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 0, 1, 3, 1, 1, 0, 0, 2]\n[1, 0, 1, 1, 3, 1, 1, 0, 0, 1, 3, 1, 1, 0, 4, 0, 1, 0, 1, 2]\n[0, 1, -1, 1, -1, 0, 1, 0, 0, 0, -1, 1, -1, 1, -1, 1, 0, 0, -1, 0]\nNeighbors\n[2, 2, 0, 1, 1, 5, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 3, 2, 0]\n[1, 2, 1, 1, 0, 5, 0, 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 3, 1, 1]\n[1, 0, -1, 0, 1, 0, 0, -1, 1, 0, 0, 0, 0, 0, -1, 1, -1, 0, 1, -1]\nNeighbors\n[0, 1, 3, 1, 2, 1, 0, 0, 1, 2, 3, 2, 0, 0, 0, 2, 0, 1, 1, 2]\n[0, 2, 3, 1, 1, 1, 0, 1, 1, 2, 3, 1, 0, 0, 0, 2, 1, 1, 1, 1]\n[0, -1, 0, 0, 1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, 1]\nNeighbors\n[2, 0, 0, 2, 2, 4, 0, 2, 0, 0, 1, 0, 2, 1, 3, 2, 0, 0, 1, 0]\n[2, 0, 1, 1, 2, 4, 1, 1, 0, 1, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0]\n[0, 0, -1, 1, 0, 0, -1, 1, 0, -1, 1, -1, 1, -1, 1, 0, 0, -1, 1, 0]\n\nProcessing time: 9.59852910041809 seconds\n\n\n\nStep 3: For each schedule in each pair calculate the objective. For each pair save the index of the schedule that has the lowest objective value.\n\nfrom functions import calculate_objective_serv_time_lookup\n\nobjectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[0], d, convolutions)]\n]\nstart = time.time()\nobjectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[1], d, convolutions)]\n]\nend = time.time()\ntraining_set_lab_time = end - start\nobjectives = [[obj, objectives_schedule_2[i]] for i, obj in enumerate(objectives_schedule_1)]\nrankings = np.argmin(objectives, axis=1).tolist()\nfor i in range(5):\n    print(f\"Objectives: {objectives[i]}, Ranking: {rankings[i]}\")\n\nprint(f\"\\nProcessing time: {training_set_lab_time} seconds\\n\")\n\n# Saving neighbors_list and objectives to a pickle file\n\nfile_path_neighbors = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\nwith open(file_path_neighbors, 'wb') as f:\n    pickle.dump({'neighbors_list': neighbors_list, 'objectives': objectives, 'rankings': rankings}, f)\n    print(f\"Data saved successfully to '{file_path_neighbors}'\")\n\nObjectives: [83.04192963686182, 83.54356435776737], Ranking: 0\nObjectives: [77.79868987625441, 78.60755862567558], Ranking: 0\nObjectives: [74.1891415694572, 74.8778761666206], Ranking: 0\nObjectives: [115.13908790487503, 118.11655584272562], Ranking: 0\nObjectives: [81.39598881694657, 83.70582096705965], Ranking: 0\n\nProcessing time: 52.7902557849884 seconds\n\nData saved successfully to 'datasets/neighbors_and_objectives_22_20_10.pkl'\n\n\nStep 4: Create training and test sets.\n\n# Prepare the dataset\nX = []\nfor neighbors in neighbors_list:\n    X.append(neighbors[0] + neighbors[1])\n\nX = np.array(X)\ny = np.array(rankings)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nStep 5: Train the XGBoost model.\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B[Initialize StratifiedKFold]\n    B --&gt; C[Initialize XGBClassifier]\n    C --&gt; D[Set results as empty list]\n    D --&gt; E[Loop through each split of cv split]\n    E --&gt; F[Get train and test indices]\n    F --&gt; G[Split X and y into X_train, X_test, y_train, y_test]\n    G --&gt; H[Clone the classifier]\n    H --&gt; I[Call fit_and_score function]\n    I --&gt; J[Fit the estimator]\n    J --&gt; K[Score on training set]\n    J --&gt; L[Score on test set]\n    K --&gt; M[Return estimator, train_score, test_score]\n    L --&gt; M\n    M --&gt; N[Append the results]\n    N --&gt; E\n    E --&gt; O[Loop ends]\n    O --&gt; P[Print results]\n    P --&gt; Q[End]\n\n\n\n\n\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['logloss'][epoch]}\")\n        return False\n    \ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0\n    )\n\n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)\n\n# Initialize the XGBClassifier without early stopping here\n# Load the best trial parameters from a JSON file.\nwith open(\"model_params.json\", \"r\") as f:\n    model_params = json.load(f)\n    \n# Initialize the EarlyStopping callback with validation dataset\nearly_stop = xgb.callback.EarlyStopping(\n    rounds=10, metric_name='logloss', data_name='validation_0', save_best=True\n)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    early_stopping_rounds=9,\n    #callbacks=[CustomCallback(period=50), early_stop],\n    callbacks=[CustomCallback(period=50)],\n)\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    est, train_score, test_score = fit_and_score(\n        clone(clf), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nParams: \n max_depth: 6\n min_child_weight: 1\n gamma: 0.1\n subsample: 0.8\n colsample_bytree: 0.8\n learning_rate: 0.1\n n_estimators: 100\nEpoch 49, Evaluation log: 0.3859358516913373\nEpoch 99, Evaluation log: 0.33441790031939744\nEpoch 49, Evaluation log: 0.3907189334275201\nEpoch 99, Evaluation log: 0.3380307249811827\nEpoch 49, Evaluation log: 0.382494989436632\nEpoch 99, Evaluation log: 0.3313815239557647\nEpoch 49, Evaluation log: 0.3816863031534478\nEpoch 99, Evaluation log: 0.33048702430794946\nEpoch 49, Evaluation log: 0.38382685379032044\nEpoch 99, Evaluation log: 0.33395808137736166\n\nTraining time: 4.385956048965454 seconds\n\n\n\nStep 6: To evaluate the performance of the XGBoost ranking model, we will use Stratified K-Fold Cross-Validation with 5 splits, ensuring each fold maintains the same class distribution as the original dataset. Using StratifiedKFold(n_splits=5, shuffle=True, random_state=94), the dataset will be divided into five folds. In each iteration, the model will be trained on four folds and evaluated on the remaining fold. A custom callback, CustomCallback(period=10), will print the evaluation log every 10 epochs.\nThe fit_and_score function will fit the model and score it on both the training and test sets, storing the results for each fold. This provides insight into the model’s performance across different subsets of the data, helps in understanding how well the model generalizes to unseen data and identifies potential overfitting or underfitting issues. The overall processing time for the cross-validation will also be recorded.\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score (Accuracy): {train_score:.4f}, Test Score (Accuracy): {test_score:.4f}\")\n\nFold 1 - Train Score (Accuracy): 0.8760, Test Score (Accuracy): 0.8673\nFold 2 - Train Score (Accuracy): 0.8786, Test Score (Accuracy): 0.8649\nFold 3 - Train Score (Accuracy): 0.8769, Test Score (Accuracy): 0.8669\nFold 4 - Train Score (Accuracy): 0.8782, Test Score (Accuracy): 0.8675\nFold 5 - Train Score (Accuracy): 0.8778, Test Score (Accuracy): 0.8669\n\n\nTraining the model on the entire dataset provides a final model that has learned from all available data. Recording the training time helps in understanding the computational efficiency and scalability of the model with the given hyperparameters.\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nclf.save_model('models/classifier_large_instance.json')\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\\n\")\n\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\nTraining accuracy: 87.66%\n\n\nTraining time: 0.7132198810577393 seconds\n\n\n\n\n\n3.4.7 Validation\nGenerating test schedules and calculating their objectives and rankings allows us to create a new dataset for evaluating the model’s performance on unseen data.\n\nnum_test_schedules = 1000\n\n#test_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_schedules = create_random_schedules(T, N, num_test_schedules)\n\ntest_neighbors = [create_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[0], d, convolutions)]\n]\n# Start time measurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[1], d, convolutions)]\n]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nSampled: 1000 schedules\n\n\nEvaluation time: 0.6055338382720947 seconds\n\nNeighbors: ([0, 1, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 0, 2, 3, 1, 2, 1, 1], [1, 0, 2, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 0, 3, 3, 0, 3, 0, 1]),\nObjectives: [80.34375674586019, 79.0522040925382], Ranking: 1\n\nNeighbors: ([3, 1, 0, 0, 1, 3, 3, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1], [4, 0, 1, 0, 1, 3, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 2, 0]),\nObjectives: [83.91062848425169, 85.28542843713318], Ranking: 0\n\nNeighbors: ([1, 3, 0, 2, 2, 0, 0, 0, 3, 1, 1, 3, 1, 0, 1, 1, 1, 0, 1, 1], [2, 2, 1, 2, 1, 0, 0, 1, 2, 2, 0, 4, 0, 0, 2, 1, 0, 0, 2, 0]),\nObjectives: [81.27180493558375, 81.81911145623857], Ranking: 0\n\nNeighbors: ([0, 4, 1, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 2], [1, 3, 1, 3, 1, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1, 2, 2, 0, 1, 1]),\nObjectives: [90.93131720913884, 84.04987894608132], Ranking: 1\n\nNeighbors: ([0, 0, 1, 2, 1, 3, 1, 0, 2, 1, 2, 1, 1, 2, 0, 1, 1, 3, 0, 0], [0, 1, 0, 3, 0, 3, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 3, 0, 0]),\nObjectives: [98.81490682689946, 96.65022564996356], Ranking: 1\n\nNeighbors: ([2, 1, 0, 1, 1, 1, 3, 1, 2, 0, 0, 2, 1, 0, 1, 2, 0, 1, 0, 3], [2, 0, 0, 2, 0, 1, 3, 2, 1, 0, 1, 1, 1, 0, 2, 2, 0, 0, 0, 4]),\nObjectives: [73.93710300450431, 77.12052958708485], Ranking: 0\n\n\n\nMaking predictions on new data and comparing them to the actual rankings provides an evaluation of the model’s performance in practical applications. Recording the prediction time helps in understanding the model’s efficiency during inference.\n\ninput_X = test_neighbors\nX_new = []\nfor test_neighbor in input_X:\n    X_new.append(test_neighbor[0] + test_neighbor[1])\n    \n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.006290912628173828 seconds\n\ntest_rankings = [1 0 0 1 1 0], \ny_pred = [1 0 0 1 1 0], \ny_pred_proba = \n[[0.08373594 0.91626406]\n [0.92097473 0.07902525]\n [0.5798993  0.42010072]\n [0.00610781 0.9938922 ]\n [0.12959522 0.8704048 ]\n [0.82179135 0.17820863]]\n\n\nCalculating the ambiguousness of the predicted probabilities helps in understanding the model’s confidence in its predictions. High ambiguousness indicates uncertain predictions, while low ambiguousness indicates confident predictions.\nAmbiguousness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the ambiguousness of the random variable \\(X\\) - the set of probability scores for the predicted rankings,\n\\(p(x_i)\\) is probability score \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\nCalculating cumulative error rate and cumulative accuracy helps in understanding how the model’s performance evolves over the dataset.\nVisualizing the relationship between ambiguousness and error provides insights into how uncertainty in the model’s predictions correlates with its accuracy. This can help in identifying patterns and understanding the conditions under which the model performs well or poorly.\n\nfrom functions import calculate_ambiguousness\n\nerrors = np.abs(y_pred - np.array(test_rankings))\n\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\n\n                                                \n\n\n\n\n3.4.8 Hyperparameter Optimization\nIn the initial model the choice of hyperparameters was based on default values, examples from demo’s or trial and error. To improve the model’s performance, we applied a hyperparameter optimization technique to find the best set of hyperparameters. We used a grid search with cross-validation to find the optimal hyperparameters for the XGBoost model. The grid search was performed over a predefined set of hyperparameters, and the best hyperparameters were selected based on the model’s performance on the validation set. The best hyperparameters were then used to train the final model.\n\nfrom functions import compare_json\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n    \ndifferences = compare_json(model_params, best_trial_params)\n\nparams_tbl = pd.DataFrame(differences)\nparams_tbl.rename(index={'json1_value': 'base parameters', 'json2_value': 'optimized parameters'}, inplace=True)\nprint(params_tbl)\n\n                      max_depth     gamma  subsample  colsample_bytree  \\\nbase parameters               6  0.100000   0.800000          0.800000   \noptimized parameters          5  0.304548   0.781029          0.922528   \n\n                      learning_rate  n_estimators  \nbase parameters            0.100000           100  \noptimized parameters       0.239488           490  \n\n\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\n# Load the best trial parameters from a JSON file.\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\")\n\n\nTraining time: 2.8103280067443848 seconds\n\nTraining accuracy: 94.73%\n\n\n\n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.006420135498046875 seconds\n\ntest_rankings = [1 0 0 1 1 0], \ny_pred = [1 0 1 1 1 0], \ny_pred_proba = \n[[2.2580880e-01 7.7419120e-01]\n [8.3462286e-01 1.6537715e-01]\n [4.3862438e-01 5.6137562e-01]\n [5.7220459e-05 9.9994278e-01]\n [5.9172392e-02 9.4082761e-01]\n [9.0017807e-01 9.9821933e-02]]\n\n\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors, \"Schedules\": test_neighbors, \"Objectives\": test_objectives}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n\n\n\n\n\n\n\nAmbiguousness\nError\nSchedules\nObjectives\nCumulative error rate\nCumulative accuracy\n\n\n\n\n830\n0.000135\n0\n([0, 3, 0, 2, 2, 0, 0, 4, 0, 0, 1, 2, 0, 1, 0,...\n[81.86230352024046, 73.6280899313611]\n0.0\n1.0\n\n\n264\n0.000138\n0\n([1, 2, 3, 2, 1, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2,...\n[86.28344323753004, 93.58667401853906]\n0.0\n1.0\n\n\n806\n0.000190\n0\n([1, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 0, 1, 1, 2,...\n[74.82846584607623, 81.24221619390504]\n0.0\n1.0\n\n\n908\n0.000422\n0\n([1, 0, 3, 2, 0, 0, 4, 1, 1, 2, 1, 1, 0, 1, 1,...\n[92.0076682291616, 105.14413473653872]\n0.0\n1.0\n\n\n223\n0.000497\n0\n([1, 0, 1, 1, 1, 0, 0, 2, 3, 1, 2, 0, 0, 0, 2,...\n[84.59579641316651, 97.02203999243454]\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    customdata=df[[\"Schedules\", \"Objectives\"]],\n                    hovertemplate=\n                        \"Ambiguousness: %{x} &lt;br&gt;\" +\n                        \"Error: %{y} &lt;br&gt;\" +\n                        \"Schedules: %{customdata[0][0]} / %{customdata[0][1]} &lt;br&gt;\" +\n                        \"Objectives: %{customdata[1]} &lt;br&gt;\"\n                    ))\n                  \nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#results",
    "href": "xgboost-pairwise-ranking-large.html#results",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.5 Results",
    "text": "3.5 Results\nWe wanted to test whether an XGBoost classification model could be used to assess and rank the quality of pairs of schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost ranking model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 244663.0 million. For training and evaluation, we sampled 200000 schedules and corresponding neighbors. Generating the feature and label set took a total of 63.073 seconds, with the calculation of objective values accounting for 52.7903 seconds.\nThe model demonstrates strong and consistent performance with high accuracies both for training, testing and validation (89.4%) with good generalization and stability. Total training time for the final model was 2.8103 seconds. The evaluation of 1000 test schedules took 0.0064 seconds for the the XGBoost model and 0.6055 for the conventional method, which is an improvement of 94X.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#discussion",
    "href": "xgboost-pairwise-ranking-large.html#discussion",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.6 Discussion",
    "text": "3.6 Discussion\n\ntraining_time = round(modeling_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Ranking model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost ranking model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#timeline",
    "href": "xgboost-pairwise-ranking-large.html#timeline",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.7 Timeline",
    "text": "3.7 Timeline\nThis experiment was started on 26-04-2025. The expected completion date is 26-04-2025.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#references",
    "href": "xgboost-pairwise-ranking-large.html#references",
    "title": "3  Large instance XGBoost classification model for pairwise ranking",
    "section": "3.8 References",
    "text": "3.8 References",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "",
    "text": "4.1 Objective\nObjective: Testing the performance of an XGBoost model trained for ranking pairwise schedules taken from a neighborhood around quasi optimal initial schedule (Bailey-Welch).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#background",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#background",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.2 Background",
    "text": "4.2 Background\nIn a previous experiment we developed a Machine Learning model using XGBoost that can evaluate two neighboring schedules and rank them according to preference. For evaluation random schedules were sampled from the full solution set.\nThe full solution set however contains many schedules that are obviously not optimal. Adding them to the training set would provide the model with rather useless knowledge. Therefore in this experiment we only sample pairs of schedules taken from within the vicinity of a ‘good’ starting point.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#hypothesis",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#hypothesis",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.3 Hypothesis",
    "text": "4.3 Hypothesis\nAn XGBoost ranking model achieves superior computational efficiency compared to evaluating each element of a pair individually, leading to faster overall performance in ranking tasks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#methodology",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#methodology",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.4 Methodology",
    "text": "4.4 Methodology\n\n4.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBClassifier interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\nimport random\nfrom scipy.optimize import minimize\nfrom itertools import combinations\n\n\n\n4.4.2 Experimental Design\nTo compare an XGBoost Machine Learning model with a simple evaluation of each individual element of the pair, we will use a pairwise ranking approach. The objective is to rank two neighboring schedules according to preference.\n\nfrom functions import compute_convolutions, bailey_welch_schedule\n\nN = 22 # Number of patients\nT = 20 # Number of intervals\nd = 5 # Length of each interval\nmax_s = 20 # Maximum service time\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.1 # Weight for the waiting time in objective function\nl = 10\nnum_schedules = 300000 # Number of schedules to sample\n\n# Create service time distribution\ndef generate_weighted_list(max_s, l, i):\n    \"\"\"\n    Generates a service time probability distribution using optimization.\n\n    This function creates a discrete probability distribution over T possible\n    service times (from 1 to T). It uses optimization (SLSQP) to find a\n    distribution whose weighted average service time is as close as possible\n    to a target value 'l', subject to the constraint that the probabilities\n    sum to 1 and each probability is between 0 and 1.\n\n    After finding the distribution, it sorts the probabilities: the first 'i'\n    probabilities (corresponding to service times 1 to i) are sorted in\n    ascending order, and the remaining probabilities (service times i+1 to T)\n    are sorted in descending order.\n\n    Note:\n        - This function relies on a globally defined integer 'T', representing\n          the maximum service time considered (or number of probability bins).\n        - The parameter 'max_s' is accepted but not used directly within this\n          function's optimization or sorting logic as shown. It might be\n          related to how 'T' is determined externally.\n        - Requires NumPy and SciPy libraries (specifically scipy.optimize.minimize).\n\n    Args:\n        max_s (any): Maximum service time parameter (currently unused in the\n                     provided function body's core logic).\n        l (float): The target weighted average service time for the distribution.\n        i (int): The index determining the sorting split point. Probabilities\n                 for service times 1 to 'i' are sorted ascendingly, and\n                 probabilities for service times 'i+1' to 'T' are sorted\n                 descendingly. Must be between 1 and T-1 for meaningful sorting.\n\n    Returns:\n        numpy.ndarray: An array of size T+1. The first element (index 0) is 0.\n                       Elements from index 1 to T represent the calculated\n                       and sorted probability distribution, summing to 1.\n                       Returns None if optimization fails.\n    \"\"\"\n    # Initialize an array of T+1 values, starting with zero\n    # Index 0 is unused for probability, indices 1 to T hold the distribution\n    values = np.zeros(l + 1)\n\n    # --- Inner helper function for optimization ---\n    def objective(x):\n        \"\"\"Objective function: Squared difference between weighted average and target l.\"\"\"\n        # Calculate weighted average: sum(index * probability) / sum(probability)\n        # Since sum(probability) is constrained to 1, it simplifies.\n        weighted_avg = np.dot(np.arange(1, l + 1), x) # Corresponds to sum(k * P(ServiceTime=k))\n        return (weighted_avg - l) ** 2\n\n    # --- Constraints for optimization ---\n    # Constraint 1: The sum of the probabilities (x[0] to x[T-1]) must be 1\n    constraints = ({\n        'type': 'eq',\n        'fun': lambda x: np.sum(x) - 1\n    })\n\n    # Bounds: Each probability value x[k] must be between 0 and 1\n    # Creates a list of T tuples, e.g., [(0, 1), (0, 1), ..., (0, 1)]\n    bounds = [(0, 1)] * l\n\n    # Initial guess: Use Dirichlet distribution to get a random distribution that sums to 1\n    # Provides a starting point for the optimizer. np.ones(T) gives equal weights initially.\n    initial_guess = np.random.dirichlet(np.ones(l))\n\n    # --- Perform Optimization ---\n    # Minimize the objective function subject to the sum and bounds constraints\n    # using the Sequential Least Squares Programming (SLSQP) method.\n    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n\n    # Check if optimization was successful\n    if not result.success:\n        print(f\"Warning: Optimization failed! Message: {result.message}\")\n        # Handle failure case, e.g., return None or raise an error\n        return None # Or potentially return a default distribution\n\n    # Assign the optimized probabilities (result.x) to the correct slice of the values array\n    # result.x contains the T probabilities for service times 1 to T.\n    values[1:] = result.x\n\n    # --- Reorder the values based on the index 'i' ---\n    # Ensure 'i' is within a valid range for slicing and sorting\n    if not (0 &lt; i &lt; l):\n       print(f\"Warning: Index 'i' ({i}) is outside the valid range (1 to {T-1}). Sorting might be trivial.\")\n       # Adjust i or handle as an error depending on requirements\n       i = max(1, min(i, l - 1)) # Clamp i to a safe range for demonstration\n\n    # Sort the first 'i' probabilities (indices 1 to i) in ascending order\n    first_part = np.sort(values[1:i+1])\n    # Sort the remaining 'T-i' probabilities (indices i+1 to T) in descending order\n    second_part = np.sort(values[i+1:])[::-1] # [::-1] reverses the sorted array\n\n    # Combine the sorted parts back into the 'values' array\n    values[1:i+1] = first_part\n    values[i+1:] = second_part\n\n    # Return the final array with the sorted probability distribution\n    return values\n\ni = 5  # First 5 highest values in ascending order, rest in descending order\ns = generate_weighted_list(max_s, l, i)\nprint(s)\nprint(\"Sum:\", np.sum(s[1:]))  # This should be 1\nprint(\"Weighted service time:\", np.dot(np.arange(len(s)), s))  # This should be close to l\ninitial_x = bailey_welch_schedule(T, d, N, s)\nprint(f\"Initial schedule: {initial_x}\")\nconvolutions = compute_convolutions(s, N, q)\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\nwith open(file_path_parameters, 'wb') as f:\n    pickle.dump({\n      'N': N,\n      'T': T,\n      'd': d,\n      'max_s': max_s,\n      'q': q,\n      'w': w,\n      'l': l,\n      'num_schedules': num_schedules,\n      'convolutions': convolutions\n      }, f)\n    print(f\"Data saved successfully to '{file_path_parameters}'\")\n\n[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.68307590e-11\n 1.20362054e-11 7.26149696e-12 2.43707832e-12]\nSum: 1.0000000000385656\nWeighted service time: 6.000000000303828\nInitial schedule: [2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 5]\nData saved successfully to 'datasets/parameters_22_20_10.pkl'\n\n\nWe will create a random set of pairs of neighboring schedules from within the neighborhood around schedule [2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 5].\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict which of the two neighboring schedules has the lowest objective value. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value and then ranked.\n\n\n4.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables: A list with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n4.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n4.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 244663.0 mln. For this experiment we will be using a relatively small sample of 300000 pairs of schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n4.4.6 Experimental Procedure\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Objective values\"]\n    D --&gt; |Rank objectives| E[\"Labels: Rankings\"]\n    E --&gt; |\"Split dataset\"| F[\"Training set\"]\n    E --&gt; |\"Split dataset\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\nStep 1: Create pairs of neighboring schedules. A set of 300000 schedules will be sampled from the neighborhood of the initial schedule. For each schedule a pair of neighbors will be created. The order of the neighbors will be randomly switched to create a more diverse training set. The time taken to sample the schedules and create the neighbors will be recorded.\n\nfrom functions import get_v_star, get_neighborhood\n\ndef sample_neighbors_list(x: list[int], v_star: np.ndarray, all = True) -&gt; (list[int], list[int]):\n    \"\"\"\n    Create a set of pairs of schedules that are from the same neighborhood.\n    \n    Parameters:\n      x (list[int]): A list of integers with |s| = T and sum N.\n      v_star (np.ndarray): Precomputed vectors V* of length T.\n      \n    Returns:\n      tuple(list[int], list[int]): A pair of schedules.\n    \"\"\"\n    T = len(x)\n\n    # Precompute binomial coefficients (weights for random.choices)\n    binom_coeff = [math.comb(T, i) for i in range(1, T)]\n\n    # Choose a random value of i with the corresponding probability\n    i = random.choices(range(1, T), weights=binom_coeff)[0]\n\n    # Instead of generating the full list of combinations, sample one directly\n    j = random.sample(range(T), i)\n    \n    x_p = x.copy()\n    for k in j:\n        x_temp = np.array(x_p) + v_star[k]\n        x_temp = x_temp.astype(int)\n        if np.all(x_temp &gt;= 0):\n            x_p = x_temp.astype(int).tolist()\n    if all:\n        return x, x_p\n    else:    \n        return x_p\n\nstart = time.time()\nv_star = get_v_star(T)\n# Sample a set of schedules from the neighborhood of the initial schedule\nneighbors_selection = [sample_neighbors_list(initial_x, v_star, all = False) for i in range(num_schedules)] # This can be done in parallel to improve speed\nprint(len(neighbors_selection))\nend = time.time()\n# For the sampled schedules, create the neighbors\nneighbors_list = [sample_neighbors_list(schedule, v_star) for schedule in neighbors_selection]\n# Randomly switch the order of the neighbors\nneighbors_list = [neighbor if random.random() &lt; 0.5 else neighbor[::-1] for neighbor in neighbors_list]\nend = time.time()\nh = random.choices(range(num_schedules), k=7)\nprint(f\"Sampled schedules: {h}\")\nfor i in h:\n    original_schedule = neighbors_list[i][0]\n    neighbor_schedule = neighbors_list[i][1]\n    difference = [int(x - y) for x, y in zip(neighbors_list[i][0], neighbors_list[i][1])]\n    print(f\"Neighbors\\n{original_schedule}\\n{neighbor_schedule}\\n{difference}\")\ntraining_set_feat_time = end - start\nprint(f\"\\nProcessing time: {training_set_feat_time} seconds\\n\")\n\n300000\nSampled schedules: [69775, 15273, 299789, 83343, 173983, 181155, 68011]\nNeighbors\n[2, 3, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 4]\n[2, 2, 1, 0, 1, 1, 0, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 1, 0, 5]\n[0, 1, -1, 1, 0, -1, 1, -1, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 1, -1]\nNeighbors\n[2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1, 0, 0, 1, 6]\n[1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1, 0, 7]\n[1, -1, 0, 1, -1, 0, 0, 1, 0, 0, 0, 0, 0, 0, -1, 1, 0, -1, 1, -1]\nNeighbors\n[1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 6]\n[1, 0, 2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 0, 1, 1, 2, 1, 0, 0, 7]\n[0, 1, 0, 0, -1, 1, 0, 0, 0, 0, -1, 1, 0, 0, 0, -1, 0, 1, 0, -1]\nNeighbors\n[3, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 5]\n[2, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1, 1, 0, 1, 0, 6]\n[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 1, 0, 0, 0, -1]\nNeighbors\n[0, 1, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 0, 2, 6]\n[1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 0, 2, 5]\n[-1, 0, 0, 0, 0, 0, 1, -1, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\nNeighbors\n[3, 1, 0, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 5]\n[3, 0, 0, 2, 0, 1, 1, 0, 2, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 5]\n[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 1, 0, 0, -1, 0]\nNeighbors\n[2, 0, 1, 2, 0, 0, 1, 1, 2, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 5]\n[2, 0, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 5]\n[0, 0, 0, 0, 0, -1, 1, -1, 1, -1, 1, -1, 0, 1, 0, 0, 0, -1, 1, 0]\n\nProcessing time: 74.44435214996338 seconds\n\n\n\nStep 2: For each schedule in each pair calculate the objective. For each pair save the index of the schedule that has the lowest objective value.\n\nfrom functions import calculate_objective_serv_time_lookup\n\nobjectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[0], d, convolutions)]\n]\nstart = time.time()\nobjectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[1], d, convolutions)]\n]\nend = time.time()\ntraining_set_lab_time = end - start\nobjectives = [[obj, objectives_schedule_2[i]] for i, obj in enumerate(objectives_schedule_1)]\nrankings = np.argmin(objectives, axis=1).tolist()\nfor i in range(5):\n    print(f\"Objectives: {objectives[i]}, Ranking: {rankings[i]}\")\n\nprint(f\"\\nProcessing time: {training_set_lab_time} seconds\\n\")\n\n# Step 1: Flatten the objectives into a 1D array\nflattened_data = [value for sublist in objectives for value in sublist]\n\n# Step 2: Find the index of the minimum value\nmin_index = np.argmin(flattened_data)\n\n# Step 3: Convert that index back to the original 2D structure\nrow_index = min_index // 2  # Assuming each inner list has 2 values\ncol_index = min_index % 2\n\nprint(f\"The minimum objective value is at index [{row_index}][{col_index}].\\nThis is schedule: {neighbors_list[row_index][col_index]} with objective value {objectives[row_index][col_index]}.\")\n\nfile_path_best_schedule = f\"datasets/best_schedule_{N}_{T}_{l}.pkl\"\nwith open(file_path_best_schedule, 'wb') as f:\n    pickle.dump({'best_schedule':neighbors_list[row_index][col_index], 'objective': objectives[row_index][col_index]}, f)\n    print(f\"Data saved successfully to '{file_path_best_schedule}'\")\n\nprint(f\"\\nAverage ranking: {np.mean(rankings)}\\n\")\n\n# Saving neighbors_list and objectives to a pickle file\nfile_path_neighbors = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\nwith open(file_path_neighbors, 'wb') as f:\n    pickle.dump({'neighbors_list': neighbors_list, 'objectives': objectives, 'rankings': rankings}, f)\n    print(f\"Data saved successfully to '{file_path_neighbors}'\")\n\nObjectives: [35.553919980073246, 32.33726491738459], Ranking: 1\nObjectives: [30.01311862226904, 30.477549128030365], Ranking: 0\nObjectives: [32.42887527378183, 30.48485009020675], Ranking: 1\nObjectives: [40.1069462538209, 31.984975323612133], Ranking: 1\nObjectives: [30.124409036404096, 30.668188818704948], Ranking: 0\n\nProcessing time: 127.02678227424622 seconds\n\nThe minimum objective value is at index [263821][1].\nThis is schedule: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3] with objective value 24.028625804839624.\nData saved successfully to 'datasets/best_schedule_22_20_10.pkl'\n\nAverage ranking: 0.50062\n\nData saved successfully to 'datasets/neighbors_and_objectives_22_20_10.pkl'\n\n\nStep 3: Create training and test sets.\n\n# Prepare the dataset\nX = []\nfor neighbors in neighbors_list:\n    X.append(neighbors[0] + neighbors[1])\n\nX = np.array(X)\ny = np.array(rankings)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nStep 4: Train the XGBoost model.\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B[Initialize StratifiedKFold]\n    B --&gt; C[Initialize XGBClassifier]\n    C --&gt; D[Set results as empty list]\n    D --&gt; E[Loop through each split of cv split]\n    E --&gt; F[Get train and test indices]\n    F --&gt; G[Split X and y into X_train, X_test, y_train, y_test]\n    G --&gt; H[Clone the classifier]\n    H --&gt; I[Call fit_and_score function]\n    I --&gt; J[Fit the estimator]\n    J --&gt; K[Score on training set]\n    J --&gt; L[Score on test set]\n    K --&gt; M[Return estimator, train_score, test_score]\n    L --&gt; M\n    M --&gt; N[Append the results]\n    N --&gt; E\n    E --&gt; O[Loop ends]\n    O --&gt; P[Print results]\n    P --&gt; Q[End]\n\n\n\n\n\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['logloss'][epoch]}\")\n        return False\n    \ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0\n    )\n\n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)\n\n# Initialize the XGBClassifier without early stopping here\n# Load the best trial parameters from a JSON file.\nwith open(\"model_params.json\", \"r\") as f:\n    model_params = json.load(f)\n    \n# Initialize the EarlyStopping callback with validation dataset\nearly_stop = xgb.callback.EarlyStopping(\n    rounds=10, metric_name='logloss', data_name='validation_0', save_best=True\n)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    early_stopping_rounds=9,\n    #callbacks=[CustomCallback(period=50), early_stop],\n    callbacks=[CustomCallback(period=50)],\n)\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    est, train_score, test_score = fit_and_score(\n        clone(clf), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nParams: \n max_depth: 6\n min_child_weight: 1\n gamma: 0.1\n subsample: 0.8\n colsample_bytree: 0.8\n learning_rate: 0.1\n n_estimators: 100\nEpoch 49, Evaluation log: 0.3335401283745809\nEpoch 99, Evaluation log: 0.24401652437256852\nEpoch 49, Evaluation log: 0.33205071952318926\nEpoch 99, Evaluation log: 0.23965719920785827\nEpoch 49, Evaluation log: 0.3323474727777454\nEpoch 99, Evaluation log: 0.2458199597942381\nEpoch 49, Evaluation log: 0.3376562827277618\nEpoch 99, Evaluation log: 0.2460464604153424\nEpoch 49, Evaluation log: 0.33256069475908295\nEpoch 99, Evaluation log: 0.24362079493092606\n\nTraining time: 12.293036937713623 seconds\n\n\n\nStep 5: To evaluate the performance of the XGBoost ranking model, we will use Stratified K-Fold Cross-Validation with 5 splits, ensuring each fold maintains the same class distribution as the original dataset. Using StratifiedKFold(n_splits=5, shuffle=True, random_state=94), the dataset will be divided into five folds. In each iteration, the model will be trained on four folds and evaluated on the remaining fold. A custom callback, CustomCallback(period=10), will print the evaluation log every 10 epochs.\nThe fit_and_score function will fit the model and score it on both the training and test sets, storing the results for each fold. This provides insight into the model’s performance across different subsets of the data, helps in understanding how well the model generalizes to unseen data and identifies potential overfitting or underfitting issues. The overall processing time for the cross-validation will also be recorded.\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score (Accuracy): {train_score:.4f}, Test Score (Accuracy): {test_score:.4f}\")\n\nFold 1 - Train Score (Accuracy): 0.9296, Test Score (Accuracy): 0.9273\nFold 2 - Train Score (Accuracy): 0.9315, Test Score (Accuracy): 0.9309\nFold 3 - Train Score (Accuracy): 0.9269, Test Score (Accuracy): 0.9273\nFold 4 - Train Score (Accuracy): 0.9292, Test Score (Accuracy): 0.9287\nFold 5 - Train Score (Accuracy): 0.9277, Test Score (Accuracy): 0.9267\n\n\nTraining the model on the entire dataset provides a final model that has learned from all available data. Recording the training time helps in understanding the computational efficiency and scalability of the model with the given hyperparameters.\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nclf.save_model('models/classifier_large_instance.json')\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\\n\")\n\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\nTraining accuracy: 92.98%\n\n\nTraining time: 2.0916380882263184 seconds\n\n\n\n\n\n4.4.7 Validation\nGenerating test schedules and calculating their objectives and rankings allows us to create a new dataset for evaluating the model’s performance on unseen data.\n\nnum_test_schedules = 1000\n\n#test_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_schedules = [sample_neighbors_list(initial_x, v_star, all = False) for i in range(num_test_schedules)]\n\ntest_neighbors = [sample_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[0], d, convolutions)]\n]\n# Start time measurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[1], d, convolutions)]\n]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nSampled: 1000 schedules\n\n\nEvaluation time: 0.4115619659423828 seconds\n\nNeighbors: ([1, 2, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 0, 2, 5], [1, 3, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 5]),\nObjectives: [33.18772614060374, 32.014184657492976], Ranking: 1\n\nNeighbors: ([2, 0, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0, 6], [2, 1, 1, 1, 1, 1, 0, 0, 3, 1, 0, 0, 1, 0, 2, 0, 2, 0, 0, 6]),\nObjectives: [32.927719304007255, 35.647250503738896], Ranking: 0\n\nNeighbors: ([3, 0, 1, 1, 2, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 5], [2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 0, 0, 6]),\nObjectives: [29.945637131579648, 35.49276948970122], Ranking: 0\n\nNeighbors: ([3, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 1, 4], [3, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 2, 0, 4]),\nObjectives: [27.95496167081272, 28.433288634960313], Ranking: 0\n\nNeighbors: ([2, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 6], [1, 1, 1, 1, 0, 0, 2, 0, 3, 0, 0, 1, 1, 1, 2, 0, 1, 0, 1, 6]),\nObjectives: [33.43479200225032, 35.90095274787456], Ranking: 0\n\nNeighbors: ([1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 2, 0, 0, 2, 5], [0, 2, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 2, 5]),\nObjectives: [32.698734609826815, 36.30741609531623], Ranking: 0\n\n\n\nMaking predictions on new data and comparing them to the actual rankings provides an evaluation of the model’s performance in practical applications. Recording the prediction time helps in understanding the model’s efficiency during inference.\n\ninput_X = test_neighbors\nX_new = []\nfor test_neighbor in input_X:\n    X_new.append(test_neighbor[0] + test_neighbor[1])\n    \n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.006228923797607422 seconds\n\ntest_rankings = [1 0 0 0 0 0], \ny_pred = [1 0 0 0 0 0], \ny_pred_proba = \n[[0.19833893 0.8016611 ]\n [0.8240117  0.17598829]\n [0.9714385  0.02856148]\n [0.8815096  0.11849042]\n [0.8032509  0.19674908]\n [0.96251136 0.03748867]]\n\n\nCalculating the ambiguousness of the predicted probabilities helps in understanding the model’s confidence in its predictions. High ambiguousness indicates uncertain predictions, while low ambiguousness indicates confident predictions.\nAmbiguousness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the ambiguousness of the random variable \\(X\\) - the set of probability scores for the predicted rankings,\n\\(p(x_i)\\) is probability score \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\nCalculating cumulative error rate and cumulative accuracy helps in understanding how the model’s performance evolves over the dataset.\nVisualizing the relationship between ambiguousness and error provides insights into how uncertainty in the model’s predictions correlates with its accuracy. This can help in identifying patterns and understanding the conditions under which the model performs well or poorly.\n\nfrom functions import calculate_ambiguousness\n\nerrors = np.abs(y_pred - np.array(test_rankings))\n\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\n\n                                                \n\n\n\n\n4.4.8 Hyperparameter Optimization\nIn the initial model the choice of hyperparameters was based on default values, examples from demo’s or trial and error. To improve the model’s performance, we applied a hyperparameter optimization technique to find the best set of hyperparameters. We used a grid search with cross-validation to find the optimal hyperparameters for the XGBoost model. The grid search was performed over a predefined set of hyperparameters, and the best hyperparameters were selected based on the model’s performance on the validation set. The best hyperparameters were then used to train the final model.\n\nfrom functions import compare_json\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n    \ndifferences = compare_json(model_params, best_trial_params)\n\nparams_tbl = pd.DataFrame(differences)\nparams_tbl.rename(index={'json1_value': 'base parameters', 'json2_value': 'optimized parameters'}, inplace=True)\nprint(params_tbl)\n\n                      max_depth     gamma  subsample  colsample_bytree  \\\nbase parameters               6  0.100000   0.800000          0.800000   \noptimized parameters          5  0.304548   0.781029          0.922528   \n\n                      learning_rate  n_estimators  \nbase parameters            0.100000           100  \noptimized parameters       0.239488           490  \n\n\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\n# Load the best trial parameters from a JSON file.\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\")\n\n\nTraining time: 8.635821104049683 seconds\n\nTraining accuracy: 97.32%\n\n\n\n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.005888938903808594 seconds\n\ntest_rankings = [1 0 0 0 0 0], \ny_pred = [1 0 0 0 0 0], \ny_pred_proba = \n[[8.6118579e-03 9.9138814e-01]\n [9.9961799e-01 3.8200631e-04]\n [9.9999726e-01 2.7135134e-06]\n [8.9641535e-01 1.0358467e-01]\n [9.8878163e-01 1.1218370e-02]\n [9.9978304e-01 2.1696255e-04]]\n\n\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors, \"Schedules\": test_neighbors, \"Objectives\": test_objectives}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n\n\n\n\n\n\n\nAmbiguousness\nError\nSchedules\nObjectives\nCumulative error rate\nCumulative accuracy\n\n\n\n\n282\n1.952094e-08\n0\n([1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 2, 0, 1,...\n[33.27605065469817, 43.90588213428762]\n0.0\n1.0\n\n\n881\n7.576995e-08\n0\n([1, 2, 0, 2, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 0,...\n[31.50709134156461, 39.045204664821995]\n0.0\n1.0\n\n\n959\n7.632419e-08\n0\n([2, 0, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 2, 0, 1,...\n[34.461392149557454, 42.47948500004395]\n0.0\n1.0\n\n\n435\n1.470183e-07\n0\n([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 1,...\n[33.00896278203578, 42.07269588005636]\n0.0\n1.0\n\n\n821\n1.835731e-07\n0\n([1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1,...\n[29.9172095021296, 36.93160018047193]\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    customdata=df[[\"Schedules\", \"Objectives\"]],\n                    hovertemplate=\n                        \"Ambiguousness: %{x} &lt;br&gt;\" +\n                        \"Error: %{y} &lt;br&gt;\" +\n                        \"Schedules: %{customdata[0][0]} / %{customdata[0][1]} &lt;br&gt;\" +\n                        \"Objectives: %{customdata[1]} &lt;br&gt;\"\n                    ))\n                  \nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#results",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#results",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.5 Results",
    "text": "4.5 Results\nWe wanted to test whether an XGBoost classification model could be used to assess and rank the quality of pairs of schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost ranking model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 244663.0 million. For training and evaluation, we sampled 600000 schedules and corresponding neighbors. Generating the feature and label set took a total of 201.4711 seconds, with the calculation of objective values accounting for 127.0268 seconds.\nThe model demonstrates strong and consistent performance with high accuracies both for training, testing and validation (96.6%) with good generalization and stability. Total training time for the final model was 8.6358 seconds. The evaluation of 1000 test schedules took 0.0059 seconds for the the XGBoost model and 0.4116 for the conventional method, which is an improvement of 69X.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#discussion",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#discussion",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.6 Discussion",
    "text": "4.6 Discussion\n\ntraining_time = round(modeling_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Ranking model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost ranking model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#timeline",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#timeline",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.7 Timeline",
    "text": "4.7 Timeline\nThis experiment was started on 26-04-2025. The expected completion date is 26-04-2025.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large-w-bailey-welch.html#references",
    "href": "xgboost-pairwise-ranking-large-w-bailey-welch.html#references",
    "title": "4  Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule",
    "section": "4.8 References",
    "text": "4.8 References",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking with Bailey-Welch rule</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html",
    "href": "local-search-ranking-large.html",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "",
    "text": "5.1 Objective\nTest the working and performance of a previously trained XGBoost Ranking model in a local search application.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#background",
    "href": "local-search-ranking-large.html#background",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.2 Background",
    "text": "5.2 Background\nIn previous experiments, we trained an XGBoost Classifier model to predict the objective values of neighboring schedules. In this experiment, we will use the trained models to perform a local search to find the best schedule.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#hypothesis",
    "href": "local-search-ranking-large.html#hypothesis",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.3 Hypothesis",
    "text": "5.3 Hypothesis\nThe XGBoost Classifier model will be able to efficiently guide the local search algorithm to find a schedule with a lower objective value than the initial schedule.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#methodology",
    "href": "local-search-ranking-large.html#methodology",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.4 Methodology",
    "text": "5.4 Methodology\n\n5.4.1 Tools and Materials\n\nimport numpy as np\nimport json\nimport time\nfrom itertools import chain, combinations\nimport sys\nfrom math import comb  # Python 3.8 and later\nimport xgboost as xgb\nimport pickle\nfrom typing import List, Tuple, Dict, Iterable, TypeVar, Union, Any, Optional, Literal\n\nimport logging\nimport sys # Needed for StreamHandler in order to enable explicit console output\n\n# Logging configuration\nlog_level = logging.DEBUG # DEBUG or INFO\nlog_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n\n# Log to a file instead of to the console:\nlogging.basicConfig(level=log_level, format=log_format, filename='search.log', filemode='w')\n\n# Get a logger instance\nlogger = logging.getLogger(__name__)\n\n\n\n5.4.2 Load Parameters\n\nN = 22 # Number of patients\nT = 20 # Number of intervals\nl = 10 # Target service time length\n\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\" # For retrieving saved scheduling parameters\n# Load the data from the pickle file\nwith open(file_path_parameters, 'rb') as f:\n    data_params = pickle.load(f)\n\nN = data_params['N'] # Number of patients\nT = data_params['T'] # Number of intervals\nd = data_params['d'] # Length of each interval\nmax_s = data_params['max_s'] # Maximum service time\nq = data_params['q'] # Probability of a scheduled patient not showing up\nw = data_params['w'] # Weight for the waiting time in objective function\nl = data_params['l']\n  \nnum_schedules = data_params['num_schedules'] # Size of training set\nconvolutions = data_params['convolutions'] # Service time distributions used in training phase adjusted for no-shows\nprint(f\"Parameters loaded: N={N}, T={T}, l={l}, d={d}, max_s={max_s}, q={q}, w={w}, num_schedules={num_schedules}\")\n\nParameters loaded: N=22, T=20, l=10, d=5, max_s=20, q=0.2, w=0.1, num_schedules=300000\n\n\n\n\n5.4.3 Experimental Design\nWe will use the trained XGBoost Classifier model to guide a local search algorithm to find the best schedule. The local search algorithm will start with an initial schedule and iteratively explore the neighborhood of the current schedule to find a better one. As an initial schedule, we will use the schedule with the lowest objective value from the training dataset that was used to train the XGBoost Classifier model.\n\n\n5.4.4 Variables\n\nIndependent Variables:\n\nInitial schedule, trained XGBoost Classifier\n\nDependent Variables:\n\nSpeed, accuracy, and convergence of the local search algorithm.\n\n\n\n\n5.4.5 Data Collection\nWe will use the training dataset to initialize the local search algorithm.\n\n\n5.4.6 Sample Size and Selection\n\n\n5.4.7 Experimental Procedure\n\n\n\n\n\ngraph TD\n                A[Start] --&gt; B(\"Initialize schedule x\");\n                B --&gt; C{\"Iterate through all subsets U of V*\"};\n                C -- \"For each U\" --&gt; D{\"Compute y = x + sum(v in U)\"};\n                D -- \"Check y &gt;= 0\" --&gt; E{\"Compute cost C(y)\"};\n                E --&gt; F{\"Is C(y) &lt; C(x)?\"};\n                F -- \"Yes\" --&gt; G[\"Update x := y\"];\n                G --&gt; C;\n                F -- \"No\" --&gt; H{\"Finished iterating all U?\"};\n                H -- \"Yes\" --&gt; I[\"End: x is optimal schedule\"];\n                H -- \"No\" --&gt; C;\n                D -- \"If y &lt; 0\" --&gt; C;",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#results",
    "href": "local-search-ranking-large.html#results",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.5 Results",
    "text": "5.5 Results\n\n5.5.1 Load the initial best schedule.\nStart with the best solution found so far \\(\\{x^*, C(x^*)\\}\\) from the training set.\n\n# Load the best solution from the training dataset\nfile_path_schedules = f\"datasets/best_schedule_{N}_{T}_{l}.pkl\"\n# Load the data from the pickle file\nwith open(file_path_schedules, 'rb') as f:\n    best_schedule_data = pickle.load(f)\n    \nprint(f\"The data has following keys: {[key for key in best_schedule_data.keys()]}\")\n\nprint(f\"The current best schedule is: {best_schedule_data['best_schedule']} with objective value {best_schedule_data['objective']}.\")\n\n# Set the initial schedule to the best solution from the training dataset\ninitial_schedule = best_schedule_data['best_schedule']\n\nThe data has following keys: ['best_schedule', 'objective']\nThe current best schedule is: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3] with objective value 24.028625804839624.\n\n\n\n\n5.5.2 Generate the neighborhood of \\(x^*\\).\n\n5.5.2.1 Define \\(V^*\\) and \\(U_t\\).\nDefine the vectors \\(V^*\\) as follows:\n\\[\n\\left\\{\n\\begin{array}{c}\n\\vec{v_1}, \\\\\n\\vec{v_2}, \\\\\n\\vec{v_3}, \\\\\n\\vdots \\\\\n\\vec{v_{T-1}}, \\\\\n\\vec{v_T} \\\\\n\\end{array}\n\\right\\} =\n\\left\\{\n\\begin{array}{c}\n(-1, 0,...., 0, 1), \\\\\n(1, -1, 0,...., 0), \\\\\n(0, 1, -1,...., 0), \\\\\n\\vdots \\\\\n(0,...., 1, -1, 0), \\\\\n(0,...., 0, 1, -1) \\\\\n\\end{array}\n\\right\\}\n\\]\nDefine \\(U_t\\) as the set of all possible subsets of \\(V^*\\) such that each subset contains exactly \\(t\\) elements, i.e.,\n\\[\nU_t = \\{ S \\subsetneq V^* \\mid |S| = t \\}, \\quad t \\in \\{1, 2, \\dots, T\\}.\n\\]\n\nfrom functions import get_v_star\n\ndef powerset(iterable, size=1):\n    \"powerset([1,2,3], 2) --&gt; (1,2) (1,3) (2,3)\"\n    return [[i for i in item] for item in combinations(iterable, size)]\n  \nx = initial_schedule\n\n# Generate a matrix 'v_star' using the 'get_v_star' function\nv_star = get_v_star(T)\n\n# Generate all possible non-empty subsets (powerset) of the set {0, 1, 2, ..., t-1}\n# 'ids' will be a list of tuples, where each tuple is a subset of indices\nsize = 2\nids = powerset(range(T), size)\nlen(ids)\nids[:T]\n\n[[0, 1],\n [0, 2],\n [0, 3],\n [0, 4],\n [0, 5],\n [0, 6],\n [0, 7],\n [0, 8],\n [0, 9],\n [0, 10],\n [0, 11],\n [0, 12],\n [0, 13],\n [0, 14],\n [0, 15],\n [0, 16],\n [0, 17],\n [0, 18],\n [0, 19],\n [1, 2]]\n\n\n\n\n5.5.2.2 Define the neighborhood of \\(x\\)\nDefine the neighborhood of \\(x\\) as all vectors of the form \\(x + u_{tk}, \\forall \\, u_{tk} \\in U_t\\).\n\nfrom functions import get_neighborhood\ntest_nh = get_neighborhood(x, v_star, ids)\nprint(f\"All neighborhoods with {size} patients switched:\\n x = {np.array(x)}: \\n {test_nh}\")\n\nAll neighborhoods with 2 patients switched:\n x = [2 2 0 2 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 3]: \n [[2 1 0 ... 1 1 4]\n [1 2 1 ... 1 1 4]\n [1 2 0 ... 1 1 4]\n ...\n [2 2 0 ... 1 0 3]\n [2 2 0 ... 0 2 2]\n [2 2 0 ... 2 1 2]]\n\n\n\n\n\n5.5.3 Local search algorithm with prediction\nLoad the pre-trained model and use it for evaluating schedules within a local search algorithm. The search algorithm checks for false positives (prediction improvement = “True”, actual is improvement = “False”) and false negatives (prediction improvement = “False”, actual is improvement = “True”). In both cases the model is updated using the schedules and associated objective values (rankings).\n\n\n\n\n\ngraph TD\n    %% --- Part 1: Initialization & Outer Loop ---\n\n    A[Start: local_search_predict_update] --&gt; B{Inputs: x, w, v_star, clf, params, size, restarts, threshold};\n    B --&gt; C{\"Validate Inputs (clf, x length)\"};\n    C -- Valid --&gt; D[\"Initialize: x_star, T, restart_count=0, t=1\"];\n    C -- Invalid --&gt; Z_Err1[\"Raise ValueError\"];\n    D --&gt; E{\"Calculate Initial cost_star\"};\n    E -- Success --&gt; F{\"Outer Loop: t &lt;= size AND restart_count &lt; restarts?\"};\n    E -- Error --&gt; Z_Err2[\"Return x_star, clf\"];\n\n    %% Connections FROM other parts back to the Outer Loop check (F)\n    Connector_O([From Part 2: Break Inner Loop]) --&gt; F;\n    Connector_CC_Yes([From Part 3: Found Better at Level t]) --&gt; F;\n    Connector_DD([From Part 3: Incremented t]) --&gt; F;\n\n    %% Connections TO other parts\n    F -- No --&gt; Y[\"End: Return x_star, clf\"];\n    F -- Yes --&gt; G[\"Generate Neighborhood (level t)\"];\n    G --&gt; Connector_H([To Part 2: Start Inner Loop]);\n\n\n\n\n\n\n\n\n\n\n\ngraph TD\n    %% --- Part 2: Inner Loop - Neighbor Evaluation ---\n\n    Connector_G([From Part 1: Generate Neighborhood]) --&gt; H{\"Inner Loop: For each neighbor\"};\n\n    H -- Next Neighbor --&gt; I{\"Predict with clf: prediction, P(0)\"};\n    I -- Error Predicting --&gt; I_Err[\"Log Error, Assume P=0\"];\n    I_Err --&gt; J;\n    I -- Success --&gt; J{\"Perform Expensive Check? (Pred=1 OR P(0) &lt; threshold)\"};\n    J -- No --&gt; H_Next[Next Neighbor]; %% Skip expensive check\n    J -- Yes --&gt; K{\"Calculate True Cost (Expensive Objective Func)\"};\n    K -- Error --&gt; K_Err[\"Log Error\"];\n    K_Err --&gt; H_Next;\n    K -- Success --&gt; L{\"Is neighbor truly better? (cost_neighbor &lt; cost_star)\"};\n\n    %% Path 1: Improvement Found\n    L -- Yes --&gt; M[\"Update x_star, cost_star, T\"];\n    M --&gt; N[\"Set found_better=True, t=1, restart_count++\"];\n    N --&gt; O[\"Break Inner Loop\"];\n    O --&gt; Connector_F1([To Part 1: Outer Loop Check]); %% Connects back to F\n\n    %% Path 2: No Improvement\n    L -- No --&gt; P{\"Misprediction? (Pred=1 AND Actual=0)\"};\n    P -- No --&gt; Q[\"Log Borderline/Correct Pred=0\"];\n    Q --&gt; H_Next;\n    P -- Yes --&gt; R[\"Log Misprediction\"];\n    R --&gt; Connector_S([To Part 3: Start Retraining]); %% Trigger Retraining\n\n    %% Loop Control\n    H_Next --&gt; H; %% Process next neighbor\n    H -- End of Neighbors --&gt; BB{\"End Inner Loop\"};\n    BB --&gt; Connector_BB([To Part 3: Check Level Result]);\n\n\n\n\n\n\n\n\n\n\n\ngraph TD\n    %% --- Part 3: Retraining Sub-routine & Loop Control ---\n\n    %% Retraining Sub-routine Start\n    Connector_R([From Part 2: Misprediction Detected]) --&gt; S[\"Start Retraining Sub-routine\"];\n    subgraph Retraining Sub-routine\n        direction TB\n        S --&gt; T{\"Calculate True Costs for ALL neighbors at level t\"};\n        T --&gt; U{\"Opportunistic Better Found during Cost Calc?\"};\n        U -- Yes --&gt; V[\"Update x_star, cost_star, T\"];\n        V --&gt; W[\"Set found_better_retrain=True\"];\n        W --&gt; X[\"Collect Data: Append features/labels for update\"];\n        U -- No --&gt; X;\n        X --&gt; X_Loop{\"More neighbors to process for retraining?\"};\n        X_Loop -- Yes --&gt; T;\n        X_Loop -- No --&gt; Y_Fit{\"Fit clf incrementally\"};\n        Y_Fit -- Error --&gt; Y_FitErr[\"Log Fit Error\"];\n        Y_FitErr --&gt; Z_CheckOpp{\"Check if found_better_retrain?\"};\n        Y_Fit -- Success --&gt; Z_CheckOpp;\n    end\n\n    %% Retraining Outcome\n    Z_CheckOpp -- Yes --&gt; AA[\"Set found_better=True, t=1, restart_count++\"];\n    AA --&gt; Connector_O([To Part 1: Outer Loop Check via Break]); %% Connects back to F via O\n    Z_CheckOpp -- No --&gt; Connector_H_Next([To Part 2: Next Neighbor]); %% Retraining finished, continue inner loop\n\n    %% Inner Loop Finished - Level Control Logic\n    Connector_BB([From Part 2: End Inner Loop]) --&gt; CC{\"Found better solution at level t?\"};\n    CC -- Yes --&gt; Connector_F2([To Part 1: Outer Loop Check]); %% Restart checks from t=1\n    CC -- No --&gt; DD[\"Increment t\"];\n    DD --&gt; Connector_F3([To Part 1: Outer Loop Check]); %% Continue outer loop with next t\n\n\n\n\n\n\n\ndef local_search_predict(\n    x: List[int],\n    w: float,\n    v_star: np.ndarray,\n    clf: xgb.XGBClassifier,\n    obj_func_params: Dict[str, Any],\n    size: int = 2,\n    restarts: int = 3,\n    check_proba_threshold: float = 0.7,\n    retrain_on: Literal['both', 'fp', 'fn', 'none'] = 'fp'\n) -&gt; Tuple[List[int], xgb.XGBClassifier]:\n    \"\"\"\n    Performs local search guided by an XGBClassifier, minimizing expensive\n    objective calls. Verifies prediction=0 if P(class=0) is below threshold.\n    Updates the classifier incrementally when specified mispredictions occur.\n    Uses logging instead of print statements. T is inferred from len(x).\n\n    Args:\n        x (List[int]): Starting point.\n        w (float): Weight for combining objectives.\n        v_star (np.ndarray): Current best overall solution (used for guidance).\n        clf (xgb.XGBClassifier): Pre-trained XGBoost Classifier.\n        obj_func_params (Dict[str, Any]): Parameters for objective function.\n        size (int, optional): Max neighborhood size. Defaults to 2.\n        restarts (int, optional): Max restarts. Defaults to 3.\n        check_proba_threshold (float, optional): Threshold for P(class=0) verification. Defaults to 0.7. # Corrected default in comment\n        retrain_on (Literal['both', 'fp', 'fn', 'none'], optional):\n            Specifies when to trigger retraining based on misprediction type:\n            - 'both': Retrain on False Positives (P=1, A=0) and False Negatives (P=0, A=1).\n            - 'fp': Retrain only on False Positives. (Default) # Corrected default in comment\n            - 'fn': Retrain only on False Negatives.\n            - 'none': Never retrain based on mispredictions.\n            Defaults to 'fp'.\n\n    Returns:\n        Tuple[List[int], xgb.XGBClassifier]: Best solution found and potentially updated classifier.\n    \"\"\"\n    # --- Input Validation ---\n    # Check if clf appears fitted (basic check)\n    if not hasattr(clf, 'classes_') or not hasattr(clf, 'n_features_in_'):\n         logger.warning(\"Classifier 'clf' may not be fitted. Proceeding with caution.\")\n         # Depending on strictness, you might raise an error here instead.\n         # raise ValueError(\"Classifier 'clf' must be fitted before use.\")\n\n    if not x:\n        logger.error(\"Input schedule x cannot be empty (length must be positive).\")\n        raise ValueError(\"Input schedule x cannot be empty (length must be positive).\")\n\n    allowed_retrain_values = {'both', 'fp', 'fn', 'none'}\n    if retrain_on not in allowed_retrain_values:\n        logger.error(\"Invalid value for 'retrain_on': %s. Must be one of %s\", retrain_on, allowed_retrain_values)\n        raise ValueError(f\"Invalid value for 'retrain_on'. Must be one of {allowed_retrain_values}\")\n\n    # --- Initialization ---\n    x_star = list(x) # Work with a copy\n    T = len(x_star) # Infer T from the length - calculated once initially\n    restart_count = 0\n    t = 1 # Start with neighborhood size 1\n\n    # Calculate initial cost\n    try:\n        logger.info(\"Calculating initial cost...\")\n        objectives_star = calculate_objective_serv_time_lookup(x_star, **obj_func_params)\n        cost_star = w * objectives_star[0] + (1 - w) * objectives_star[1]\n        logger.info(\"Initial solution cost: %.4f\", cost_star)\n    except Exception as e:\n        logger.exception(\"Error calculating initial cost: %s\", e)\n        return x_star, clf # Return current best and original classifier on error\n\n    # --- Main Search Loop ---\n    while t &lt;= size and restart_count &lt; restarts:\n        logger.info(\"--- Running local search level t=%d (Restart %d/%d) ---\", t, restart_count + 1, restarts)\n\n        ids_gen_iterable = powerset(range(T), t) # Use current T\n        # Pass x_star (current best) to neighborhood generation\n        neighborhood_iter = get_neighborhood(x_star, v_star, ids_gen_iterable)\n\n        found_better_solution_at_level_t = False\n        neighbors_data_at_level_t: List[Dict[str, Any]] = [] # Store data for potential retraining\n        neighbors_processed_count = 0\n\n        for neighbor_np in neighborhood_iter:\n            neighbors_processed_count += 1\n            neighbor = neighbor_np.tolist() # Convert numpy array to list\n            neighbor_info = {\"schedule\": neighbor, \"cost\": None, \"true_label\": None, \"prediction\": None}\n            neighbors_data_at_level_t.append(neighbor_info) # Add neighbor info early\n\n            # --- Feature Creation ---\n            # Feature is concatenation - ensure this matches how clf was trained\n            feature_pair = x_star + neighbor\n\n            # --- 1. Predict using the CHEAP classifier ---\n            prediction = 0 # Default prediction\n            proba_class_0 = 1.0 # Default probability\n            try:\n                # Reshape feature_pair for XGBoost if needed (expects 2D array)\n                feature_pair_np = np.array(feature_pair).reshape(1, -1)\n                prediction = clf.predict(feature_pair_np)[0]\n                proba = clf.predict_proba(feature_pair_np)[0]\n                # Ensure proba has expected structure (e.g., 2 elements for binary class)\n                if len(proba) &gt; 0:\n                   proba_class_0 = proba[0] # Probability of class 0\n                else:\n                   logger.warning(\"Predict_proba returned unexpected structure: %s. Using default P(0)=1.0\", proba)\n            except Exception as e:\n                logger.warning(\"Error predicting for neighbor %d: %s. Assuming prediction=0.\", neighbors_processed_count, e)\n                # Keep default prediction=0, proba_class_0=1.0\n\n            neighbor_info[\"prediction\"] = prediction # Store prediction\n            logger.debug(\"  Neighbor %d: Predicted=%d (P(0)=%.3f)\", neighbors_processed_count, prediction, proba_class_0)\n\n            # --- 2. Decide whether to perform expensive check ---\n            perform_expensive_check = False\n            check_reason = \"\"\n\n            if prediction == 1:\n                perform_expensive_check = True\n                check_reason = \"Predicted 1\"\n            elif proba_class_0 &lt; check_proba_threshold:\n                perform_expensive_check = True\n                check_reason = f\"Borderline P(0) &lt; {check_proba_threshold:.3f}\"\n            else: # prediction == 0 and proba_class_0 &gt;= threshold\n                logger.debug(\"  -&gt; Skipping objective function call (Confident P=0).\")\n\n            # --- 3. Perform EXPENSIVE check if needed ---\n            if perform_expensive_check:\n                logger.debug(\"  -&gt; Verifying (%s)...\", check_reason)\n                try:\n                    objectives_neighbor = calculate_objective_serv_time_lookup(neighbor, **obj_func_params)\n                    cost_neighbor = w * objectives_neighbor[0] + (1 - w) * objectives_neighbor[1]\n                    is_truly_better = cost_neighbor &lt; cost_star\n                    true_label = 1 if is_truly_better else 0\n\n                    # Store results in neighbor_info\n                    neighbor_info[\"cost\"] = cost_neighbor\n                    neighbor_info[\"true_label\"] = true_label\n\n                    logger.debug(\"      True Cost=%.4f (Current Best=%.4f) -&gt; Actual Better=%s\",\n                                 cost_neighbor, cost_star, is_truly_better)\n\n                    # --- 4. Check for Misprediction and Trigger Retraining (Conditional) ---\n                    misprediction = (prediction != true_label)\n                    trigger_retraining = False\n                    opportunistic_update_occurred = False # Reset for this neighbor check\n\n                    if misprediction and retrain_on != 'none':\n                        misprediction_type = \"\"\n                        should_retrain_this_type = False\n\n                        if prediction == 1 and not is_truly_better: # False Positive (P=1, A=0)\n                            misprediction_type = \"False Positive (P=1, A=0)\"\n                            should_retrain_this_type = retrain_on in ['both', 'fp']\n                        elif prediction == 0 and is_truly_better: # False Negative (P=0, A=1)\n                            misprediction_type = \"False Negative (P=0, A=1)\"\n                            should_retrain_this_type = retrain_on in ['both', 'fn']\n\n                        if should_retrain_this_type:\n                            logger.warning(\"      Misprediction! (%s). Triggering retraining process based on 'retrain_on=%s'.\",\n                                           misprediction_type, retrain_on)\n                            trigger_retraining = True\n                        elif misprediction_type: # Misprediction occurred but not the type we retrain on\n                             logger.info(\"      Misprediction occurred (%s), but retraining is disabled for this type ('retrain_on=%s').\",\n                                         misprediction_type, retrain_on)\n\n                    # --- Retraining Sub-routine (if triggered) ---\n                    if trigger_retraining:\n                        features_for_update: List[List[int]] = []\n                        labels_for_update: List[int] = []\n                        best_opportunistic_neighbor = None\n                        best_opportunistic_cost = cost_star # Initialize with current best cost\n\n                        logger.info(\"      Calculating true costs for %d neighbors at level %d for retraining...\",\n                                    len(neighbors_data_at_level_t), t)\n\n                        for n_idx, n_info in enumerate(neighbors_data_at_level_t):\n                            n_schedule = n_info[\"schedule\"]\n                            n_cost = n_info[\"cost\"]\n                            n_true_label = n_info[\"true_label\"]\n\n                            # Calculate cost if not already done (e.g., for neighbors skipped earlier)\n                            if n_cost is None or n_true_label is None:\n                                try:\n                                    logger.debug(\"          Calculating missing cost for neighbor %d...\", n_idx+1)\n                                    n_objectives = calculate_objective_serv_time_lookup(n_schedule, **obj_func_params)\n                                    n_cost = w * n_objectives[0] + (1 - w) * n_objectives[1]\n                                    n_is_better = n_cost &lt; cost_star\n                                    n_true_label = 1 if n_is_better else 0\n                                    n_info[\"cost\"] = n_cost # Update info cache\n                                    n_info[\"true_label\"] = n_true_label\n                                except Exception as e:\n                                    logger.warning(\"          Error calculating cost for neighbor %d (%s) during retraining: %s. Skipping.\",\n                                                   n_idx+1, n_schedule, e)\n                                    continue # Skip this neighbor for training data\n\n                            # Prepare data for fitting\n                            n_feature_pair = x_star + n_schedule # Create feature pair for this neighbor\n                            features_for_update.append(n_feature_pair)\n                            labels_for_update.append(n_true_label)\n                            logger.debug(\"          Neighbor %d: Cost=%.4f, True Label=%d (Used for training)\",\n                                         n_idx+1, n_cost, n_true_label)\n\n                            # Check for opportunistic update (find the best neighbor *among those evaluated*)\n                            if n_true_label == 1 and n_cost &lt; best_opportunistic_cost:\n                                logger.info(\"          Opportunistic Update Candidate! Found/Confirmed better neighbor (%d) during cost calculation.\", n_idx+1)\n                                best_opportunistic_neighbor = list(n_schedule) # Store a copy of the schedule\n                                best_opportunistic_cost = n_cost # Update best cost found *during retraining*\n                                opportunistic_update_occurred = True\n\n\n                        # Perform incremental fit if data was gathered\n                        if features_for_update:\n                            logger.info(\"      Fitting model incrementally with %d data points...\", len(labels_for_update))\n                            try:\n                                X_update = np.array(features_for_update) # Convert list of lists to 2D numpy array\n                                y_update = np.array(labels_for_update)\n\n                                # Ensure clf is fitted before incremental update if it's the first time\n                                # XGBoost's fit with xgb_model handles this correctly.\n                                clf.fit(X_update, y_update, xgb_model=clf.get_booster()) # Pass the existing booster\n                                logger.info(\"      Model update complete.\")\n\n                            except Exception as e:\n                                logger.exception(\"      Error during incremental model update: %s\", e)\n                        else:\n                            logger.warning(\"      No valid data gathered for retraining.\")\n\n                        # If an opportunistic update was found, apply it now\n                        if opportunistic_update_occurred:\n                             logger.info(f\"      Applying opportunistic update. New best: {best_opportunistic_neighbor} with cost = {best_opportunistic_cost:.4f}.\")\n                             x_star = best_opportunistic_neighbor # Use the best one found (already a list)\n                             cost_star = best_opportunistic_cost\n                             T = len(x_star) # Update T as length might have changed\n                        # --- End of Retraining Sub-routine ---\n\n                    # --- 5. Handle Updates & Loop Control ---\n                    # Check if we should update x_star and restart the search level\n                    if opportunistic_update_occurred:\n                        found_better_solution_at_level_t = True # Mark improvement found\n                        t = 1 # Reset level\n                        restart_count += 1\n                        logger.info(\"      Restarting search from t=1 due to opportunistic update during retraining. Restart count: %d\", restart_count)\n                        break # Exit inner loop (for neighbor_np in neighborhood_iter)\n\n                    elif is_truly_better: # True Positive or handled False Negative (update to the current neighbor)\n                        logger.info(f\"      Confirmed better solution (or handled FN). Updating x_star to {neighbor} with cost = {cost_neighbor:.4f}.\")\n                        # CORRECTED: Assign neighbor directly as it's already a list\n                        x_star = neighbor\n                        cost_star = cost_neighbor\n                        T = len(x_star) # Update T as length might have changed\n                        found_better_solution_at_level_t = True\n                        t = 1 # Reset level\n                        restart_count += 1\n                        logger.info(\"      Restarting search from t=1. Restart count: %d\", restart_count)\n                        break # Exit inner loop (for neighbor_np in neighborhood_iter)\n\n                    # else: (Not truly better and no opportunistic update) -&gt; continue to next neighbor implicitly\n\n                except Exception as e:\n                    logger.warning(\"  Error calculating objective or handling result for neighbor %d (%s): %s.\",\n                                   neighbors_processed_count, neighbor, e)\n            # --- End of 'if perform_expensive_check:' ---\n\n        # --- End of neighbor loop (for neighbor_np in neighborhood_iter) ---\n\n        # If we finished the loop for level t without finding a better solution (or breaking early)\n        if not found_better_solution_at_level_t:\n            if neighbors_processed_count &gt; 0:\n                logger.info(\"No improving solution found or confirmed at level t=%d.\", t)\n            else:\n                logger.info(\"No neighbors generated or processed at level t=%d.\", t)\n            t += 1 # Move to the next neighborhood size level\n\n    # --- End of outer while loop ---\n    logger.info(\"Local search finished after %d restarts or reaching max size %d.\", restart_count, size)\n    logger.info(\"Final solution: %s\", x_star)\n    logger.info(\"Final cost: %.4f\", cost_star)\n\n    return x_star, clf\n\n\nfrom functions import calculate_objective_serv_time_lookup\nstart = time.time()\n# Define the path to the saved model\nmodel_path = \"models/classifier_large_instance.json\" # Make sure this path is correct\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\n# Load the model directly from the file path\nclf.load_model(model_path)\n\nintial_objectives = calculate_objective_serv_time_lookup(x, d, convolutions)\ninitial_c_star = w * intial_objectives[0] + (1 - w) * intial_objectives[1]\nx_star = local_search_predict(x, w, v_star, clf, {'d': d, 'convolutions': convolutions}, size=T, restarts=T)[0]\nfinal_objectives = calculate_objective_serv_time_lookup(x_star, d, convolutions)\nfinal_c_star = w * final_objectives[0] + (1 - w) * final_objectives[1]\nend = time.time()\nprint(f\"\\nInitial schedule: {x}, with objective value: {initial_c_star}.\\nFinal schedule: {x_star}, with objective value: {final_c_star}. Search time {end - start:.2f} seconds.\")\n\n\nInitial schedule: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], with objective value: 24.028625804839624.\nFinal schedule: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], with objective value: 24.028625804839624. Search time 830.96 seconds.\n\n\n\n\n5.5.4 Run the conventional local search algorithm for validation\nWe will run a conventional local search algorithm to evaluate the new method, assessing both the quality of the results and its computational efficiency.\n\nfrom functions import local_search\n# Computing optimal solution with real cost\nprint(f\"Initial schedule: {x}\")\nstart = time.time()\ntest_x = local_search(x, d, convolutions, w, v_star, T, echo=True)\nend = time.time()\n\nInitial schedule: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]\nInitial solution: [2 2 0 2 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 3], cost: 24.028625804839624\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 17\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 139\nRunning local search with switching 3 patient(s)\nSize of neighborhood: 728\nRunning local search with switching 4 patient(s)\nSize of neighborhood: 2743\nRunning local search with switching 5 patient(s)\nSize of neighborhood: 7913\nRunning local search with switching 6 patient(s)\nSize of neighborhood: 18152\nRunning local search with switching 7 patient(s)\nSize of neighborhood: 33931\nRunning local search with switching 8 patient(s)\nSize of neighborhood: 52520\nRunning local search with switching 9 patient(s)\nSize of neighborhood: 68003\nRunning local search with switching 10 patient(s)\nSize of neighborhood: 74074\nRunning local search with switching 11 patient(s)\nSize of neighborhood: 68003\nRunning local search with switching 12 patient(s)\nSize of neighborhood: 52520\nRunning local search with switching 13 patient(s)\nSize of neighborhood: 33931\nFound better solution: [2 2 0 2 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2], cost: 23.443089273560844\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 18\nFound better solution: [1 2 0 2 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3], cost: 23.290731519864124\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 18\nFound better solution: [1 2 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3], cost: 23.17349058000479\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 19\nFound better solution: [2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3], cost: 23.049992753251537\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 19\nFound better solution: [2 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 3], cost: 22.966437323340017\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 19\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 172\nRunning local search with switching 3 patient(s)\nSize of neighborhood: 987\nRunning local search with switching 4 patient(s)\nSize of neighborhood: 4029\nRunning local search with switching 5 patient(s)\nSize of neighborhood: 12444\nRunning local search with switching 6 patient(s)\nSize of neighborhood: 30192\nRunning local search with switching 7 patient(s)\nSize of neighborhood: 58956\nRunning local search with switching 8 patient(s)\nSize of neighborhood: 94146\nRunning local search with switching 9 patient(s)\nSize of neighborhood: 124202\nRunning local search with switching 10 patient(s)\nSize of neighborhood: 136136\nRunning local search with switching 11 patient(s)\nSize of neighborhood: 124202\nRunning local search with switching 12 patient(s)\nSize of neighborhood: 94146\nRunning local search with switching 13 patient(s)\nSize of neighborhood: 58956\nRunning local search with switching 14 patient(s)\nSize of neighborhood: 30192\nFound better solution: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2], cost: 22.627834923300007\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 20\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 190\nRunning local search with switching 3 patient(s)\nSize of neighborhood: 1140\nRunning local search with switching 4 patient(s)\nSize of neighborhood: 4845\nRunning local search with switching 5 patient(s)\nSize of neighborhood: 15504\nRunning local search with switching 6 patient(s)\nSize of neighborhood: 38760\nRunning local search with switching 7 patient(s)\nSize of neighborhood: 77520\nRunning local search with switching 8 patient(s)\nSize of neighborhood: 125970\nRunning local search with switching 9 patient(s)\nSize of neighborhood: 167960\nRunning local search with switching 10 patient(s)\nSize of neighborhood: 184756\nRunning local search with switching 11 patient(s)\nSize of neighborhood: 167960\nRunning local search with switching 12 patient(s)\nSize of neighborhood: 125970\nRunning local search with switching 13 patient(s)\nSize of neighborhood: 77520\nRunning local search with switching 14 patient(s)\nSize of neighborhood: 38760\nRunning local search with switching 15 patient(s)\nSize of neighborhood: 15504\nRunning local search with switching 16 patient(s)\nSize of neighborhood: 4845\nRunning local search with switching 17 patient(s)\nSize of neighborhood: 1140\nRunning local search with switching 18 patient(s)\nSize of neighborhood: 190\nRunning local search with switching 19 patient(s)\nSize of neighborhood: 20\n\n\n\nprint(f\"Initial schedule: {x}\\nFinal schedule: {test_x[0]}\\nDifference: {test_x[0] - x}\\nObjective value: {test_x[1]}. Search time: {end - start:.2f} seconds.\")\ntest_res = calculate_objective_serv_time_lookup(test_x[0], d, convolutions)\n\nInitial schedule: [2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]\nFinal schedule: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\nDifference: [ 0 -1  1 -1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0 -1]\nObjective value: 22.627834923300007. Search time: 968.40 seconds.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#discussion",
    "href": "local-search-ranking-large.html#discussion",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.6 Discussion",
    "text": "5.6 Discussion",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#timeline",
    "href": "local-search-ranking-large.html#timeline",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.7 Timeline",
    "text": "5.7 Timeline\nThis experiment was started on 01-04-2025 and concluded on 17-04-2025",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-ranking-large.html#references",
    "href": "local-search-ranking-large.html#references",
    "title": "5  Large instance local search with trained XGBoost regressor model",
    "section": "5.8 References",
    "text": "5.8 References",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html",
    "href": "combinatorial-bayes-optimization.html",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "",
    "text": "6.1 Objective\nThe objective of this experiment is to evaluate and compare the performance of two distinct Combinatorial Bayesian Optimization (CBO) strategies for an outpatient appointment scheduling problem. We investigate:\nWe aim to determine which strategy is most effective in identifying an optimal or near-optimal schedule, as measured by the objective function value, leveraging dictionary-based embeddings for the high-dimensional combinatorial space (Deshwal et al. 2023).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#objective",
    "href": "combinatorial-bayes-optimization.html#objective",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "",
    "text": "CBO utilizing Expected Improvement (EI) as the acquisition function.\nCBO utilizing Lower Confidence Bound (LCB) as the acquisition function with a fixed kappa (\\(\\kappa\\)) value.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#background",
    "href": "combinatorial-bayes-optimization.html#background",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.2 Background",
    "text": "6.2 Background\nWe consider an outpatient appointment scheduling problem as described by Kaandorp and Koole (2007) where the schedule is represented by a vector \\(\\mathbf{x} = (x_0, x_1, \\ldots, x_{T-1})^T\\). This vector comprises \\(T\\) components, where \\(x_j\\) denotes the non-negative allocation (number of patients) to time slot \\(j\\), for \\(j = 0, \\ldots, T-1\\). A fundamental constraint is that the total allocation across all time slots must equal a fixed constant \\(N\\): \\[\\sum_{j=0}^{T-1} x_j = N\\] We require \\(x_j \\ge 0\\) for all \\(j = 0, \\ldots, T-1\\). Consequently, a valid schedule \\(\\mathbf{x}\\) belongs to the feasible set \\(\\mathcal{F} = \\{ \\mathbf{z} \\in \\mathbb{D}^{T} \\mid \\sum_{j=0}^{T-1} z_j = N, z_j \\ge 0 \\text{ for all } j\\}\\), where \\(\\mathbb{D}\\) is the set of non-negative integers (\\(\\mathbb{Z}_{\\ge 0}\\)).\nKaandorp and Koole (2007) define a neighborhood structure for local search based on perturbation vectors derived from a set of \\(T\\) basis change vectors, \\(v_i \\in \\mathbb{D}^{T}\\), for \\(i = 0, \\ldots, T-1\\). These basis vectors represent elementary shifts of allocation between time slots:\n\n\\(v_0 = (-1, 0, \\ldots, 0, 1)\\) (Shift unit from slot 0 to slot \\(T-1\\))\n\\(v_1 = (1, -1, 0, \\ldots, 0)\\) (Shift unit from slot 1 to slot 0)\n\\(v_i = (0, \\ldots, 0, \\underbrace{1}_{\\text{pos } i-1}, \\underbrace{-1}_{\\text{pos } i}, 0, \\ldots, 0)\\) for \\(i = 2, \\ldots, T-1\\) (Shift unit from slot \\(i\\) to slot \\(i-1\\))\n\nA key property of these basis vectors is that the sum of components for each vector is zero: \\(\\sum_{j=0}^{T-1} v_{ij} = 0\\) for all \\(i=0, \\ldots, T-1\\).\nPerturbations are constructed using a binary selection vector \\(\\mathbf{U} = (u_0, u_1, \\ldots, u_{T-1})\\), where \\(u_i \\in \\{0, 1\\}\\). Each \\(u_i\\) indicates whether the basis change \\(v_i\\) is included in the perturbation. The resulting perturbation vector \\(\\mathbf{r}(\\mathbf{U}) \\in \\mathbb{D}^{T}\\) is the linear combination: \\[\\mathbf{r}(\\mathbf{U}) := \\sum_{i=0}^{T-1} u_i v_i\\]\nSince each \\(v_i\\) sums to zero, any perturbation \\(\\mathbf{r}(\\mathbf{U})\\) also sums to zero: \\(\\sum_{j=0}^{T-1} r_j(\\mathbf{U}) = 0\\). This ensures that applying such a perturbation to a valid schedule \\(\\mathbf{x}\\) preserves the total allocation \\(N\\).\nThe neighborhood of a schedule \\(\\mathbf{x} \\in \\mathcal{F}\\), denoted by \\(\\mathcal{N}(\\mathbf{x})\\), comprises all distinct, feasible schedules \\(\\mathbf{x}'\\) reachable by applying a non-zero perturbation \\(\\mathbf{r}(\\mathbf{U})\\) (Kaandorp and Koole (2007), use a slightly different but related neighborhood definition based on combinations of these basis vectors).\nThe objective function to be minimized is a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP), as defined by Kaandorp and Koole (2007): \\[C(\\mathbf{x}) = w \\cdot EWT(\\mathbf{x}) + (1-w) \\cdot ESP(\\mathbf{x})\\] Kaandorp and Koole (2007) prove that this objective function is multimodular, which guarantees that a local search algorithm using their defined neighborhood converges to the global optimum.\nHowever, evaluating \\(C(\\mathbf{x})\\) can be computationally expensive, especially for large \\(N\\) and \\(T\\). Furthermore, the search space defined by the binary vectors \\(\\mathbf{U}\\) is high-dimensional (\\(2^T - 2\\) possibilities, excluding \\(\\mathbf{0}\\) and \\(\\mathbf{1}\\)). Bayesian Optimization (BO) is a suitable framework for optimizing such expensive black-box functions. Standard BO methods often struggle with high-dimensional combinatorial spaces. Deshwal et al. (2023) propose a method using dictionary-based embeddings (Hamming Embedding via Dictionaries - HED) to map the high-dimensional binary space of \\(\\mathbf{U}\\) vectors into a lower-dimensional continuous space, where standard Gaussian Process (GP) models can be effectively applied. This experiment applies the HED approach within a BO framework to solve the scheduling problem formulated by Kaandorp and Koole (2007).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#hypothesis",
    "href": "combinatorial-bayes-optimization.html#hypothesis",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.3 Hypothesis",
    "text": "6.3 Hypothesis\nWe hypothesize that:\n\nBoth CBO strategies, leveraging the HED embedding (Deshwal et al. 2023), will be capable of finding schedules superior to the initial schedule derived from the Bailey-Welch method (@).\nCBO strategies employing Lower Confidence Bound (LCB) may exhibit superior performance or faster convergence compared to Expected Improvement (EI), due to the explicit exploration-exploitation trade-off inherent in LCB.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#methodology",
    "href": "combinatorial-bayes-optimization.html#methodology",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.4 Methodology",
    "text": "6.4 Methodology\n\n6.4.1 Tools and Materials\n\nProgramming Language: Python 3\nCore Libraries: NumPy, SciPy\nMachine Learning: Scikit-learn (for GaussianProcessRegressor, MinMaxScaler)\nData Structures: Standard Python lists and dictionaries, NumPy arrays.\nImported functions: bailey_welch_schedule, get_v_star, compute_convolutions, calculate_objective_serv_time_lookup (implementing the logic from Bailey (1952), assumed to be in an external functions.py file).\n\n\n\n6.4.2 Experimental Design\nThree distinct Bayesian optimization experiments are conducted, applying the HED embedding approach (Deshwal et al. 2023) to the scheduling problem:\n\nExperiment 1: Expected Improvement (EI)\n\nAcquisition Function: Expected Improvement.\nObjective: Minimize \\(C(\\mathbf{x})\\) by iteratively selecting candidate vectors \\(\\mathbf{U}\\) (via their embeddings) that maximize the EI.\n\nExperiment 2: Lower Confidence Bound (LCB) - Fixed Kappa\n\nAcquisition Function: Lower Confidence Bound.\nObjective: Minimize \\(C(\\mathbf{x})\\) using a fixed kappa (\\(\\kappa\\)) value in the LCB acquisition function applied to the GP model over the embedded space.\n\n\nFor all experiments, Hamming Distance Embedding (HED) with a “diverse random” dictionary construction strategy (Deshwal et al. 2023) is employed to map the binary perturbation vectors \\(\\mathbf{U}\\) to a continuous embedding space. A Gaussian Process (GP) model with Automatic Relevance Determination (ARD) kernels models the (negative) objective function in this embedded space.\n\n\n6.4.3 Variables\n\nIndependent Variables:\n\nType of acquisition function (EI, LCB).\nThe specific binary perturbation vector \\(\\mathbf{U}\\) selected in each iteration (chosen via optimizing the acquisition function over the embedded space).\n\nDependent Variables:\n\nThe objective function value \\(C(\\mathbf{x}')\\) for the resulting schedule \\(\\mathbf{x}' = \\mathbf{x} + \\mathbf{r}(\\mathbf{U})\\) (calculated using the method from Kaandorp and Koole (2007)).\nThe best objective function value found throughout the optimization process.\n\n\n\n\n6.4.4 Data Collection\nData, comprising evaluated pairs \\((\\mathbf{U}, C(\\mathbf{x}'))\\), is collected iteratively:\n\nAn initial set of N_INITIAL randomly generated \\(\\mathbf{U}\\) vectors is evaluated.\nIn each of the subsequent N_ITERATIONS, BATCH_SIZE_q new \\(\\mathbf{U}\\) vectors are selected by optimizing the respective acquisition function over NUM_CANDIDATES_Acqf randomly generated candidate vectors in the original binary space (evaluated via their embeddings). These newly selected vectors are then evaluated, and the results are added to the dataset.\n\n\n\n6.4.5 Sample Size and Selection\n\nN_INITIAL: 20 (number of initial random evaluations)\nN_ITERATIONS: 20 (number of Bayesian optimization iterations)\nBATCH_SIZE_q: 5 (number of candidates selected and evaluated per iteration)\nNUM_CANDIDATES_Acqf: \\(T \\times 1024 = 20 \\times 1024 = 20480\\) (number of random candidates generated for optimizing the acquisition function in each iteration)\nm: 128 (dimensionality of the HED embedding space, following Deshwal et al. (2023))\n\nThe selection of new points for evaluation is guided by the respective acquisition function (EI or LCB) optimized over the embedded space representation of candidate \\(\\mathbf{U}\\) vectors.\n\n\n6.4.6 Experimental Procedure\n\n6.4.6.1 1. Setup\nImport necessary libraries and configure warning filters.\n\n# Core Libraries\nimport numpy as np\nimport time\nimport math\nimport warnings\nfrom scipy.optimize import minimize\nfrom typing import List, Dict, Tuple, Callable, Optional, Union, Any, Iterable\n\n# Scikit-learn for GP, Scaling, and potentially acquisition functions\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.exceptions import ConvergenceWarning\n\n# SciPy for statistics (needed for Expected Improvement calculation)\nfrom scipy.stats import norm\n\nfrom functions import bailey_welch_schedule, get_v_star, compute_convolutions, calculate_objective_serv_time_lookup\n\n# Filter warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning) # GP fitting might not always converge perfectly\n\n\n\n6.4.6.2 2. Constants\nDefinition of problem parameters and initial configuration.\n\n# --- Problem Definition ---\n\n# Fixed Data (Use your actual data)\nN = 24 # Total number of patients\nT = 20 # Dimension of the binary vector U\nd = 10 # Length of each interval\nmax_s = 30 # Maximum service time\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.1 # Weight for the waiting time in objective function\nl = 14\nv_star = get_v_star(T) # Get the V* matrix(T x T)\n# Create service time distribution\ndef generate_weighted_list(max_s: int, l: float, i: int) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Generates a service time probability distribution using optimization.\n\n    This function creates a discrete probability distribution over max_s possible\n    service times (from 1 to max_s). It uses optimization (SLSQP) to find a\n    distribution whose weighted average service time is as close as possible\n    to a target value 'l', subject to the constraint that the probabilities\n    sum to 1 and each probability is between 0 and 1.\n\n    After finding the distribution, it sorts the probabilities: the first 'i'\n    probabilities (corresponding to service times 1 to i) are sorted in\n    ascending order, and the remaining probabilities (service times i+1 to max_s)\n    are sorted in descending order.\n\n    Note:\n        - Requires NumPy and SciPy libraries (specifically scipy.optimize.minimize).\n\n    Args:\n        max_s (int): Maximum service time parameter (number of probability bins).\n                     Must be a positive integer.\n        l (float): The target weighted average service time for the distribution.\n                   Must be between 1 and max_s, inclusive.\n        i (int): The index determining the sorting split point. Probabilities\n                 for service times 1 to 'i' are sorted ascendingly, and\n                 probabilities for service times 'i+1' to 'max_s' are sorted\n                 descendingly. Must be between 1 and max_s-1 for meaningful sorting.\n\n    Returns:\n        numpy.ndarray: An array of size max_s+1. The first element (index 0) is 0.\n                       Elements from index 1 to max_s represent the calculated\n                       and sorted probability distribution, summing to 1.\n                       Returns None if optimization fails or inputs are invalid.\n    \"\"\"\n\n    # --- Input Validation ---\n    if not isinstance(max_s, int) or max_s &lt;= 0:\n        print(f\"Error: max_s must be a positive integer, but got {max_s}\")\n        return None\n    if not isinstance(l, (int, float)) or not (1 &lt;= l &lt;= max_s):\n        print(f\"Error: Target average 'l' ({l}) must be between 1 and max_s ({max_s}).\")\n        return None\n    if not isinstance(i, int) or not (0 &lt; i &lt; max_s):\n        print(f\"Error: Sorting index 'i' ({i}) must be between 1 and max_s-1 ({max_s-1}).\")\n        # If clamping is desired instead of error:\n        # print(f\"Warning: Index 'i' ({i}) is outside the valid range (1 to {max_s-1}). Clamping i.\")\n        # i = max(1, min(i, max_s - 1))\n        return None # Strict check based on docstring requirement\n\n    # --- Inner helper function for optimization ---\n    def objective(x: np.ndarray) -&gt; float:\n        \"\"\"Objective function: Squared difference between weighted average and target l.\"\"\"\n        # x represents probabilities P(1) to P(max_s)\n        service_times = np.arange(1, max_s + 1)\n        weighted_avg = np.dot(service_times, x) # Equivalent to sum(k * P(k) for k=1 to max_s)\n        return (weighted_avg - l) ** 2\n\n    # --- Constraints for optimization ---\n    # Constraint 1: The sum of the probabilities must be 1\n    constraints = ({\n        'type': 'eq',\n        'fun': lambda x: np.sum(x) - 1.0 # Ensure float comparison\n    })\n\n    # Bounds: Each probability value x[k] must be between 0 and 1\n    # Creates a list of max_s tuples, e.g., [(0, 1), (0, 1), ..., (0, 1)]\n    bounds = [(0, 1)] * max_s\n\n    # Initial guess: Use Dirichlet distribution to get a random distribution that sums to 1.\n    # Provides a starting point for the optimizer. np.ones(max_s) gives equal weights initially.\n    initial_guess = np.random.dirichlet(np.ones(max_s))\n\n    # --- Perform Optimization ---\n    try:\n        result = minimize(\n            objective,\n            initial_guess,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            # options={'disp': False} # Set True for detailed optimizer output\n        )\n\n        # Check if optimization was successful\n        if not result.success:\n            print(f\"Warning: Optimization failed! Message: {result.message}\")\n            # Optionally print result object for more details: print(result)\n            return None # Indicate failure\n\n        # The optimized probabilities (P(1) to P(max_s))\n        optimized_probs = result.x\n\n        # --- Post-process: Correct potential floating point inaccuracies ---\n        # Ensure probabilities are non-negative and sum *exactly* to 1\n        optimized_probs[optimized_probs &lt; 0] = 0 # Clamp small negatives to 0\n        current_sum = np.sum(optimized_probs)\n        if not np.isclose(current_sum, 1.0):\n            if current_sum &gt; 0: # Avoid division by zero\n                 optimized_probs /= current_sum # Normalize to sum to 1\n            else:\n                 print(\"Warning: Optimization resulted in zero sum probabilities after clamping negatives.\")\n                 # Handle this case - maybe return uniform distribution or None\n                 return None # Or return uniform: np.ones(max_s) / max_s\n\n    except Exception as e:\n        print(f\"An error occurred during optimization: {e}\")\n        return None\n\n    # --- Reorder the probabilities based on the index 'i' ---\n    # Split the probabilities P(1)...P(i) and P(i+1)...P(max_s)\n    # Note: Python slicing is exclusive of the end index, array indexing is 0-based.\n    # result.x[0] corresponds to P(1), result.x[i-1] to P(i).\n    # result.x[i] corresponds to P(i+1), result.x[max_s-1] to P(max_s).\n\n    first_part_probs = optimized_probs[:i]   # Probabilities P(1) to P(i)\n    second_part_probs = optimized_probs[i:]  # Probabilities P(i+1) to P(max_s)\n\n    # Sort the first part ascending, the second part descending\n    sorted_first_part = np.sort(first_part_probs)\n    sorted_second_part = np.sort(second_part_probs)[::-1] # [::-1] reverses\n\n    # --- Create final output array ---\n    # Array of size max_s + 1, initialized to zeros. Index 0 unused.\n    values = np.zeros(max_s + 1)\n\n    # Assign the sorted probabilities back into the correct slots (index 1 onwards)\n    values[1 : i + 1] = sorted_first_part      # Assign P(1)...P(i)\n    values[i + 1 : max_s + 1] = sorted_second_part # Assign P(i+1)...P(max_s)\n\n    # Final check on sum after potential normalization/sorting\n    if not np.isclose(np.sum(values[1:]), 1.0):\n         print(f\"Warning: Final distribution sum is {np.sum(values[1:])}, not 1.0. Check logic.\")\n\n    # Return the final array with the sorted probability distribution\n    return values\n\ni = 10  # First 5 highest values in ascending order, rest in descending order\ns = generate_weighted_list(max_s, l, i)\nprint(f\"Average generated service time: {np.dot(np.arange(len(s)), s)}\")\nconvolutions = compute_convolutions(s, N, q)\nX = np.array(bailey_welch_schedule(T, d, N, s))\nprint(f\"Initial schedule: {X}\")\n# Objective Function Calculation\nLARGE_PENALTY = 1e10 # Penalty for infeasible solutions\newt, esp = calculate_objective_serv_time_lookup(X, d, convolutions)\ninitial_objective_value = w * ewt + (1 - w) * esp\nprint(f\"Initial objective value: {initial_objective_value}\")\n\nAverage generated service time: 12.942391896136673\nInitial schedule: [2 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 8]\nInitial objective value: 120.67426858005447\n\n\n\n\n6.4.6.3 3. Common Functions (Objective Evaluation and HED)\nObjective evaluation implements \\(C(\\mathbf{x})\\) from Kaandorp and Koole (2007). HED implementation follows Deshwal et al. (2023).\n\ndef evaluate_objective(U_np, X_vec, v_star, convolutions, d, w):\n    \"\"\"\n    Target function: Evaluates objective for a single binary numpy array U.\n    Returns a float.\n    \"\"\"\n    # Input validation (same as before)\n    if not isinstance(U_np, np.ndarray):\n        raise TypeError(\"Input U must be a numpy array\")\n    if U_np.ndim != 1:\n         raise ValueError(\"Input U must be 1-dimensional\")\n    if U_np.shape[0] != v_star.shape[0]:\n         raise ValueError(f\"Dimension mismatch: U length {U_np.shape[0]} != V* rows {v_star.shape[0]}.\")\n    if X_vec.shape[0] != v_star.shape[1]:\n         raise ValueError(\"Dimension mismatch: X length must match V* columns.\")\n    if not np.all((U_np == 0) | (U_np == 1)):\n         raise ValueError(\"Input U must be binary (0s and 1s).\")\n\n    # Calculate Y based on selected rows of V_star\n    V_sum = np.sum(v_star[U_np == 1, :], axis=0)\n    Y = X_vec + V_sum\n\n    # Check feasibility and calculate objective\n    if np.all(Y &gt;= 0):\n        ewt, esp = calculate_objective_serv_time_lookup(Y, d, convolutions)\n        objective_value = w * ewt + (1 - w) * esp\n        return objective_value\n    else:\n        # Infeasible solution\n        return LARGE_PENALTY\n\n# --- HED Implementation ---\n\ndef hamming_distance(u1, u2):\n    \"\"\"Calculates Hamming distance between two binary numpy arrays.\"\"\"\n    return np.sum(u1 != u2)\n\ndef generate_diverse_random_dictionary(T, m):\n    \"\"\"Generates the random dictionary A for HED.\"\"\"\n    dictionary_A = np.zeros((m, T), dtype=int)\n    for i in range(m):\n        # Sample theta for density of 1s in this dictionary vector\n        theta = np.random.uniform(0, 1)\n        row = (np.random.rand(T) &lt; theta).astype(int)\n        dictionary_A[i, :] = row\n    return dictionary_A\n\ndef _generate_binary_hadamard_matrix_recursive(dim):\n    \"\"\"\n    Generates a binary (0/1) Hadamard-like matrix of size dim x dim.\n    'dim' must be a power of 2.\n    This uses the Sylvester's construction H_2n = [[H_n, H_n], [H_n, 1-H_n]]\n    starting with H_1 = [[1]].\n    \"\"\"\n    if not (dim &gt; 0 and (dim & (dim - 1) == 0)): # Checks if dim is a power of 2\n        raise ValueError(\"Dimension must be a power of 2.\")\n\n    if dim == 1:\n        return np.array([[1]], dtype=int)\n    else:\n        h_prev = _generate_binary_hadamard_matrix_recursive(dim // 2)\n        h_top = np.hstack((h_prev, h_prev))\n        h_bottom = np.hstack((h_prev, 1 - h_prev)) # 1-H_n for binary\n        return np.vstack((h_top, h_bottom))\n\ndef generate_wavelet_dictionary(T, m):\n    \"\"\"\n    Generates a dictionary A of size m x T using the subsampled binary wavelet approach.\n\n    Args:\n        T (int): The dimensionality of the input space (number of columns in dictionary).\n        m (int): The desired number of dictionary elements (number of rows).\n\n    Returns:\n        np.ndarray: An m x T integer numpy array representing the dictionary.\n    \"\"\"\n    if T &lt;= 0:\n        raise ValueError(\"T (dimensionality) must be positive.\")\n    if m &lt;= 0:\n        raise ValueError(\"m (dictionary size) must be positive.\")\n\n    # 1. Determine the smallest power of 2 &gt;= T for the full wavelet matrix\n    if T == 1:\n        n_wavelet = 1\n    elif (T &gt; 0 and (T & (T - 1) == 0)): # T is already a power of 2\n        n_wavelet = T\n    else:\n        n_wavelet = 2**math.ceil(math.log2(T))\n\n    # 2. Generate the full n_wavelet x n_wavelet binary Hadamard matrix\n    # print(f\"Generating full wavelet matrix of size: {n_wavelet}x{n_wavelet}\")\n    full_wavelet_matrix = _generate_binary_hadamard_matrix_recursive(n_wavelet)\n\n    # 3. Subsample T columns if n_wavelet &gt; T\n    if n_wavelet &gt; T:\n        # print(f\"Subsampling {T} columns from {n_wavelet} columns.\")\n        col_indices = np.random.choice(n_wavelet, size=T, replace=False)\n        col_indices.sort() # Optional: for deterministic testing if seed is set\n        wavelet_matrix_T_cols = full_wavelet_matrix[:, col_indices]\n    else:\n        wavelet_matrix_T_cols = full_wavelet_matrix # n_wavelet == T\n\n    # 4. Subsample m rows\n    num_available_rows = wavelet_matrix_T_cols.shape[0]\n    if m &gt; num_available_rows:\n        print(f\"Warning: Requested dictionary size m ({m}) is greater than \"\n              f\"available unique wavelet rows ({num_available_rows}). \"\n              f\"Using all available rows and repeating if necessary, or consider reducing m.\")\n        # For simplicity, if m &gt; num_available_rows, we'll sample with replacement\n        # or you could choose to error, or return fewer rows.\n        # The paper implies m should be less than or equal to the rows of B_d.\n        # If sampling with replacement is needed:\n        row_indices = np.random.choice(num_available_rows, size=m, replace=True)\n        # If strictly no replacement and m &gt; num_available_rows, one might error or cap m\n        # row_indices = np.random.choice(num_available_rows, size=min(m, num_available_rows), replace=False)\n        # if m &gt; num_available_rows:\n        #     # Handle the case where more rows are needed than available unique ones\n        #     # This might involve repeating rows or another strategy\n        #     pass\n    else:\n        # print(f\"Subsampling {m} rows from {num_available_rows} available rows.\")\n        row_indices = np.random.choice(num_available_rows, size=m, replace=False)\n\n    row_indices.sort() # Optional: for deterministic testing if seed is set\n    dictionary_A = wavelet_matrix_T_cols[row_indices, :]\n\n    return dictionary_A\n\ndef embed_vector(U_np, dictionary_A):\n    \"\"\"Embeds a single binary vector U using HED.\"\"\"\n    m = dictionary_A.shape[0]\n    embedding_phi = np.zeros(m, dtype=float) # Use float for GP\n    for i in range(m):\n        embedding_phi[i] = hamming_distance(U_np, dictionary_A[i, :])\n    return embedding_phi\n\ndef embed_batch(U_batch_np, dictionary_A):\n    \"\"\"Embeds a batch of binary vectors U.\"\"\"\n    # Input U_batch_np is expected to be a NumPy array\n    m = dictionary_A.shape[0]\n    if U_batch_np.ndim == 1: # Handle single vector case\n        U_batch_np = U_batch_np.reshape(1, -1)\n\n    batch_size = U_batch_np.shape[0]\n    embeddings_np = np.zeros((batch_size, m), dtype=float) # Use float for GP\n\n    for j in range(batch_size):\n        embeddings_np[j, :] = embed_vector(U_batch_np[j, :], dictionary_A)\n\n    # Return NumPy array directly\n    return embeddings_np\n\n\n\n6.4.6.4 4. Experiment 1: CBO with Expected Improvement (EI)\nApplies the methodology from Deshwal et al. (2023) using EI.\n\n# --- BO Helper Functions ---\n\ndef get_fitted_model(train_X_embedded_scaled, train_Y, m):\n    \"\"\"\n    Fits a GaussianProcessRegressor model to the SCALED embedded data.\n    Assumes train_Y contains negative objective values for maximization.\n    \"\"\"\n    if train_Y.ndim &gt; 1 and train_Y.shape[1] == 1:\n        train_Y = train_Y.ravel() # sklearn GP expects 1D target array\n\n    # Define the kernel for the Gaussian Process\n    # Matern kernel is a common choice, nu=2.5 is smooth (twice differentiable)\n    # ConstantKernel handles the overall variance scaling\n    # WhiteKernel handles the observation noise\n    kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \\\n             Matern(length_scale=np.ones(m), # Enable ARD, initialize length scales to 1\n                    length_scale_bounds=(1e-2, 1e2),\n                    nu=2.5) + \\\n             WhiteKernel(noise_level=1e-10, # Small value for numerical stability\n                         noise_level_bounds=\"fixed\") # Bounds for noise optimization\n\n    # Instantiate the Gaussian Process Regressor\n    # alpha: Value added to the diagonal of the kernel matrix during fitting\n    #        for numerical stability (can also be seen as additional noise)\n    # n_restarts_optimizer: Restarts optimizer to find better hyperparameters\n    gp_model = GaussianProcessRegressor(\n        kernel=kernel,\n        alpha=1e-10, # Small value for numerical stability\n        n_restarts_optimizer=10, # More restarts -&gt; better hyperparams but slower\n        random_state=42 # For reproducibility of optimizer restarts\n    )\n\n    # Fit the GP model\n    gp_model.fit(train_X_embedded_scaled, train_Y)\n    return gp_model\n\ndef expected_improvement(mu, sigma, f_best, xi=0.01):\n    \"\"\"\n    Computes the Expected Improvement acquisition function.\n    Assumes maximization (f_best is the current maximum observed value).\n    mu, sigma: Predicted mean and standard deviation (NumPy arrays).\n    f_best: Current best observed function value (scalar).\n    xi: Exploration-exploitation trade-off parameter.\n    \"\"\"\n    # Ensure sigma is positive and non-zero to avoid division errors\n    sigma = np.maximum(sigma, 1e-9)\n    Z = (mu - f_best - xi) / sigma\n\n    ei = (mu - f_best - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n\n    # Set EI to 0 where variance is negligible\n    ei[sigma &lt;= 1e-9] = 0.0\n    return ei\n\n# MODIFIED: Accepts the scaler and uses scikit-learn GP + EI\ndef optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, current_best_neg_f_val):\n    \"\"\"\n    Optimizes acquisition function (Expected Improvement) by sampling random\n    binary candidates, embedding, SCALING, predicting with GP, and calculating EI.\n    Selects the top q candidates based on EI.\n    Returns candidates as a numpy array (q x T).\n    \"\"\"\n    m = dictionary_A.shape[0]\n\n    # 1. Generate Random Binary Candidates\n    candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))\n    # Optional: Ensure unique candidates if needed (adds overhead)\n    # candidate_u_vectors_np = np.unique(candidate_u_vectors_np, axis=0)\n    # num_candidates = candidate_u_vectors_np.shape[0] # Update count\n\n    # 2. Embed the Candidates\n    embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)\n\n    # 3. Scale the Embedded Candidates\n    # Handle potential warning if scaler expects float64 (already float here)\n    # Use the *fitted* scaler from the training data\n    embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)\n\n    # 4. Predict Mean and Std Dev using the GP Model\n    mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)\n\n    # 5. Calculate Acquisition Function (Expected Improvement)\n    # current_best_neg_f_val is the maximum of the (negative) objectives seen so far\n    acq_values = expected_improvement(mu, std, current_best_neg_f_val, xi=0.01)\n\n    # 6. Select Top Candidates\n    # Use np.argsort to find indices that would sort the array (ascending)\n    # Select the last q indices for the highest EI values\n    # If q=1, np.argmax(acq_values) is simpler but argsort works generally\n    top_indices = np.argsort(acq_values)[-q:]\n\n    # Ensure indices are returned in descending order of acquisition value (optional but nice)\n    top_indices = top_indices[::-1]\n\n    return candidate_u_vectors_np[top_indices, :]\n# --- BO Loop ---\n\n# Parameters\nN_INITIAL = 49\nN_ITERATIONS = 25\nBATCH_SIZE_q = 5\nNUM_CANDIDATES_Acqf = T*3*1024 # Might need more for higher T\nm = math.ceil(T/4) # Dimension of the embedding space\n\n# Store evaluated points (using NumPy arrays)\nevaluated_U_np_list = [] # List to store evaluated U vectors (binary)\nevaluated_f_vals = []    # List to store raw objective values (lower is better)\ntrain_Y_list = []        # List to store NEGATED objective values for GP (higher is better)\n\n# 1. Initialization\nprint(f\"Generating {N_INITIAL} initial points...\")\ninitial_candidates = [np.zeros(T, dtype=int)]\nwhile len(initial_candidates) &lt; N_INITIAL + 1: # +1 for the zero vector = initial X\n    U_init = np.random.randint(0, 2, size=T)\n    # Ensure unique initial points\n    is_duplicate = any(np.array_equal(U_init, u) for u in initial_candidates)\n    if not is_duplicate:\n        initial_candidates.append(U_init)\n\nfor U_init in initial_candidates:\n    f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)\n    neg_f_val = -f_val\n\n    evaluated_U_np_list.append(U_init)\n    evaluated_f_vals.append(f_val)\n    train_Y_list.append(neg_f_val)\n\n# Convert lists to NumPy arrays for GP fitting\ntrain_Y = np.array(train_Y_list).reshape(-1, 1) # Keep as column vector initially\n\nbest_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')\ninitial_best_obj_so_far_ei = best_obj_so_far\nprint(f\"Initial best objective value: {best_obj_so_far}\")\nif not np.isfinite(best_obj_so_far):\n     print(\"Warning: Initial best objective is infinite, possibly all initial points were infeasible.\")\n\n\n# 2. BO Iterations\nfor iteration in range(N_ITERATIONS):\n    start_time = time.time()\n    print(f\"\\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---\")\n\n    # a. Generate dictionary A for HED\n    current_dictionary_A = generate_diverse_random_dictionary(T, m)\n\n    # b. Embed ALL evaluated U vectors so far\n    if not evaluated_U_np_list:\n        print(\"Warning: No points evaluated yet. Skipping iteration.\")\n        continue\n    evaluated_U_np_array = np.array(evaluated_U_np_list)\n    embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)\n\n    # c. Scale the embedded training data\n    scaler = MinMaxScaler()\n    # Fit scaler only if there's data\n    if embedded_train_X.shape[0] &gt; 0:\n        # Fit and transform\n        embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)\n    else:\n        # Handle case with no data (shouldn't happen after init)\n        embedded_train_X_scaled = embedded_train_X # Will be empty\n\n    # Ensure train_Y is a NumPy array for fitting\n    train_Y_for_fit = np.array(train_Y_list) # Use the list directly\n\n    # d. Fit GP Model using SCALED data\n    print(\"Fitting GP model...\")\n    if embedded_train_X_scaled.shape[0] &gt; 0 and train_Y_for_fit.shape[0] == embedded_train_X_scaled.shape[0]:\n        gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)\n        print(\"GP model fitted.\")\n    else:\n         print(\"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration.\")\n         continue # Skip if no data or mismatch\n\n    # e. Determine current best value for Acquisition Function\n    # We are maximizing the negative objective in the GP\n    current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size &gt; 0 else -float('inf')\n\n    # Prevent potential issues if all points were infeasible (very large negative best_f)\n    if current_best_neg_f_val &lt;= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):\n         print(f\"Warning: Current best value ({current_best_neg_f_val:.2f}) is very low (likely from penalties). Acqf might behave unexpectedly.\")\n\n\n    # f. Optimize Acquisition Function (Expected Improvement)\n    print(\"Optimizing acquisition function...\")\n    next_U_candidates_np = optimize_acqf_discrete_via_embedding(\n        gp_model=gp_model,\n        scaler=scaler, # Pass the fitted scaler\n        dictionary_A=current_dictionary_A,\n        T=T,\n        q=BATCH_SIZE_q,\n        num_candidates=NUM_CANDIDATES_Acqf,\n        current_best_neg_f_val=current_best_neg_f_val\n    )\n    print(f\"Selected {next_U_candidates_np.shape[0]} candidate(s).\")\n\n    # g. Evaluate Objective for the selected candidate(s)\n    newly_evaluated_U = []\n    newly_evaluated_f = []\n    newly_evaluated_neg_f = []\n\n    for i in range(next_U_candidates_np.shape[0]):\n        next_U = next_U_candidates_np[i, :]\n\n        # Check if this candidate was already evaluated\n        # Use a tolerance for floating point comparisons if U were continuous\n        # For binary, exact comparison is fine\n        already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)\n\n        if already_evaluated:\n            print(f\"  Candidate {i} was already evaluated. Skipping re-evaluation.\")\n            # TODO: Optionally, could try to generate a *different* candidate here\n            #       e.g., by running optimize_acqf again excluding this one,\n            #       or sampling randomly near it. For now, just skip.\n            continue # Skip to next candidate\n\n        # Evaluate the objective\n        next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)\n        next_neg_f = -next_f\n        V_sum = np.sum(v_star[next_U == 1, :], axis=0)\n        Y = X + V_sum\n        print(f\"  Candidate {i}: Obj = {next_f:.4f}, schedule = {Y}\")\n        # Add to temporary lists for this iteration\n        newly_evaluated_U.append(next_U)\n        newly_evaluated_f.append(next_f)\n        newly_evaluated_neg_f.append(next_neg_f)\n\n        # Update overall best objective found\n        if next_f &lt; best_obj_so_far:\n            best_obj_so_far = next_f\n\n    # h. Augment Dataset for next iteration\n    evaluated_U_np_list.extend(newly_evaluated_U)\n    evaluated_f_vals.extend(newly_evaluated_f)\n    train_Y_list.extend(newly_evaluated_neg_f) # Add negative values for next GP fit\n\n    # Convert train_Y_list back to array for potential use (though we rebuild it next iter)\n    train_Y = np.array(train_Y_list).reshape(-1, 1)\n\n    iter_time = time.time() - start_time\n    print(f\"Best objective value found so far: {best_obj_so_far:.4f}\")\n    print(f\"Total points evaluated: {len(evaluated_f_vals)}\")\n    print(f\"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.\")\n\n\n# --- Results ---\nprint(\"\\n--- Optimization Finished ---\")\nif not evaluated_f_vals:\n    print(\"No points were successfully evaluated.\")\nelse:\n    # Find the best point among all evaluated points\n    final_best_idx_ei = np.argmin(evaluated_f_vals) # Index of minimum raw objective\n    final_best_U_ei = evaluated_U_np_list[final_best_idx_ei]\n    final_best_f_ei = evaluated_f_vals[final_best_idx_ei]\n    nr_evaluated_f_vals_ei = len(evaluated_f_vals) # Saved for reporting results\n    print(f\"Total evaluations: {len(evaluated_f_vals)}\") \n    print(f\"Best Objective Value Found: {final_best_f_ei}\")\n    # Ensure U is printed correctly if it's long\n    print(f\"Best U vector Found: {final_best_U_ei}\")\n    # print(f\"Best U vector Found (Indices of 1s): {np.where(final_best_U_ei == 1)[0]}\")\n\n\n    # Verification - Recalculate Y for the best U found\n    V_sum_best = np.sum(v_star[final_best_U_ei == 1, :], axis=0)\n    Y_best_ei = X + V_sum_best\n    is_feasible = np.all(Y_best_ei &gt;= 0)\n    if is_feasible:\n        ewt, esp = calculate_objective_serv_time_lookup(Y_best_ei, d, convolutions)\n        recalculated_obj = w * ewt + (1 - w) * esp\n        \n    else:\n        LARGE_PENALTY\n\n    print(f\"\\n--- Verification ---\")\n    print(f\"Is the best U feasible? {is_feasible}\")\n    if is_feasible:\n        print(f\"Resulting Y vector for best U: {Y_best_ei}\")\n        print(f\"Objective value (recalculated): {recalculated_obj:.4f}\")\n        if not np.isclose(final_best_f_ei, recalculated_obj):\n             print(f\"Warning: Stored best objective ({final_best_f_ei}) does not match recalculation ({recalculated_obj})!\")\n    elif final_best_f &lt; LARGE_PENALTY:\n         print(f\"Warning: Best objective ({final_best_f_ei}) is not the penalty value, but feasibility check failed.\")\n         print(f\"Resulting Y vector (infeasible): {Y_best_ei}\")\n    else:\n         print(\"Best solution found corresponds to an infeasible penalty value.\")\n\nGenerating 49 initial points...\nInitial best objective value: 118.87100166955729\n\n--- Iteration 1/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 114.9636, schedule = [2 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 2 0 1 7]\n  Candidate 1: Obj = 130.2052, schedule = [1 1 1 1 1 1 1 0 1 1 0 2 1 0 1 0 2 0 0 9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  1  1  1 -1  2  0  2  1  0  1  1  0  1  0  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  1  0  1  2  1  0  1  0  2  1  0  1  0  2 -1  1  9]\n  Candidate 4: Obj = 131.1795, schedule = [1 1 2 1 0 1 1 1 0 1 0 2 0 1 1 0 2 0 0 9]\nBest objective value found so far: 114.9636\nTotal points evaluated: 55\nIteration 1 completed in 2.91 seconds.\n\n--- Iteration 2/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 124.1641, schedule = [3 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 2 0 0 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1 -1  1  1  1  2  0  0  1  2  0  0  8]\n  Candidate 2: Obj = 123.1027, schedule = [3 0 1 2 0 1 1 1 0 0 1 1 1 1 0 1 2 0 0 8]\n  Candidate 3: Obj = 124.6251, schedule = [3 0 2 1 0 1 0 1 0 1 1 2 1 0 0 1 2 0 0 8]\n  Candidate 4: Obj = 124.1919, schedule = [3 1 0 2 0 1 1 0 1 0 2 0 1 0 1 1 2 0 0 8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 60\nIteration 2 completed in 2.75 seconds.\n\n--- Iteration 3/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  1  1  1 -1  2  1  0  2 -1  1  2  1 -1  2  8]\n  Candidate 1: Obj = 126.5321, schedule = [2 1 1 0 1 1 0 2 0 1 1 0 1 0 1 2 1 0 1 8]\n  Candidate 2: Obj = 122.9236, schedule = [2 1 2 0 1 1 1 0 1 0 2 1 1 0 1 0 2 0 0 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  0  0  2  1  0  1  0  1  2  1 -1  2  0  2  0  1  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  0  0  2  0  2  1 -1  1  1  2  0  1  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 65\nIteration 3 completed in 2.41 seconds.\n\n--- Iteration 4/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  2  0  1  0  2  0  2  1  0  0  1  2 -1  2  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  1  1  0  0  2  1  1  1  0  0  1  2 -1  1  9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  1  1  1  1  1  1  1  0  0  1  2 -1  2  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  0  1  1  1  1  1  1  0  0  1  2 -1  2  8]\n  Candidate 4: Obj = 132.3160, schedule = [2 0 2 1 0 1 0 1 1 1 0 2 1 0 0 1 2 0 0 9]\nBest objective value found so far: 114.9636\nTotal points evaluated: 70\nIteration 4 completed in 2.65 seconds.\n\n--- Iteration 5/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  1  0  1  1  1  1 -1  2  1  1  0  1  7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  2  0  1  1  1  0  1  2 -1  1  1  1  1  1  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  1  1  1  1  0  2  0  2 -1  2  0  2  0  1  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  1  0  0  2  1 -1  1  1  2  0  1  0  2  0  0  1  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  2 -1  2  1  0  1  0  1  2  1 -1  2  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 75\nIteration 5 completed in 2.52 seconds.\n\n--- Iteration 6/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  1  1  0  0  1  1  1  0  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  1  2  0  1  1  0  1  1  1  0  1  1  1  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  1  1  0  1  1  0  0  1  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  1  0  1  1  1  0  1  2  0  0  2  1 -1  2  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  1  1  1  1  0  2 -1  2  0  1  1  0  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 80\nIteration 6 completed in 2.68 seconds.\n\n--- Iteration 7/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 116.6354, schedule = [3 0 2 0 1 1 0 1 1 1 1 1 1 0 1 0 2 0 1 7]\n  Candidate 1: Obj = 116.6189, schedule = [3 1 1 1 0 1 0 1 1 1 1 0 2 0 1 1 1 0 1 7]\n  Candidate 2: Obj = 124.8705, schedule = [2 0 1 2 0 1 1 0 1 1 1 1 0 1 0 1 2 0 1 8]\n  Candidate 3: Obj = 123.0720, schedule = [3 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  1  1  0  1  1  1  1 -1  2  0  2 -1  2  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 85\nIteration 7 completed in 2.61 seconds.\n\n--- Iteration 8/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 125.8226, schedule = [2 1 1 0 1 0 1 2 0 0 2 0 1 1 1 0 2 0 1 8]\n  Candidate 1: Obj = 122.2661, schedule = [2 1 1 1 1 1 0 1 0 1 2 0 1 0 2 1 1 0 0 8]\n  Candidate 2: Obj = 126.1646, schedule = [3 1 1 0 0 2 0 1 0 1 1 2 1 0 0 2 0 0 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  0  2  0  1  0  2  1 -1  2  0  1  1  0  9]\n  Candidate 4: Obj = 125.4905, schedule = [2 1 2 1 0 0 1 1 0 2 0 2 1 0 0 2 0 0 1 8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 90\nIteration 8 completed in 2.83 seconds.\n\n--- Iteration 9/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  2  1 -1  2  0  1  1  0  2  0  2 -1  2  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  1  0  0  2  1 -1  2  0  1  1  0  2  0  2 -1  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  0  2  0  0  2  0  2  1 -1  1  2  1 -1  1  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  0  2  1 -1  1  1  2  0  0  1  2  1 -1  2  8]\n  Candidate 4: Obj = 132.6410, schedule = [2 0 2 1 0 0 2 0 1 1 0 2 0 0 1 1 1 0 2 8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 95\nIteration 9 completed in 2.84 seconds.\n\n--- Iteration 10/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 122.2296, schedule = [2 2 0 1 1 0 2 0 1 1 0 2 0 1 0 2 0 0 2 7]\n  Candidate 1: Obj = 119.2311, schedule = [3 1 0 1 1 0 2 0 0 1 1 2 1 0 0 1 1 1 1 7]\n  Candidate 2: Obj = 121.8186, schedule = [3 1 0 1 0 1 1 1 1 0 1 2 1 0 1 1 0 1 0 8]\n  Candidate 3: Obj = 130.3095, schedule = [1 2 0 1 1 1 0 1 1 0 1 2 0 1 1 0 1 0 2 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  0  1  1  1  0  1  2  1 -1  1  2  0  1  1  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 100\nIteration 10 completed in 2.78 seconds.\n\n--- Iteration 11/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  1  0  1  0  2  0  2 -1  1  1  2 -1  1  9]\n  Candidate 1: Obj = 132.3651, schedule = [2 0 1 1 1 1 1 0 0 2 0 2 0 1 0 1 2 0 0 9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  0  1  1  1  0  2  1 -1  2  0  2 -1  1  9]\n  Candidate 3: Obj = 132.7032, schedule = [1 1 1 2 0 0 2 0 1 1 0 2 0 0 2 0 2 0 0 9]\n  Candidate 4: Obj = 133.3754, schedule = [2 0 1 2 0 1 1 0 0 2 0 2 0 0 2 0 1 1 0 9]\nBest objective value found so far: 114.9636\nTotal points evaluated: 105\nIteration 11 completed in 2.70 seconds.\n\n--- Iteration 12/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  1  0  0  1  1  1  1  1  0  2 -1  1  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  0  0  2  0  2  0  0  1  2  1  0  1  0  2 -1  1  9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  0  1  0  1  2 -1  1  2  1  0  1  0  2  1  0  1  8]\n  Candidate 3: Obj = 127.0694, schedule = [2 0 2 0 0 1 2 1 0 0 1 2 0 1 1 0 2 0 1 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  1  1  1  0  0  1  1  1  1  0  1  2 -1  2  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 110\nIteration 12 completed in 2.93 seconds.\n\n--- Iteration 13/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 134.6761, schedule = [1 2 1 0 0 1 2 0 0 1 1 2 0 0 1 1 1 0 1 9]\n  Candidate 1: Obj = 134.2275, schedule = [1 1 1 2 0 0 2 0 0 2 0 1 1 0 2 0 1 0 1 9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  2  1  1 -1  1  1  2  1 -1  1  1  1  0  1  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  0  1  0  2  0  2 -1  1  1  1  1  0  2  0  1  1  0  9]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  1 -1  2  0  1  1  0  1  2  0  1  0  9]\nBest objective value found so far: 114.9636\nTotal points evaluated: 115\nIteration 13 completed in 3.68 seconds.\n\n--- Iteration 14/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  0  1  2 -1  1  2  1  0  0  2  0  1  0  2  7]\n  Candidate 1: Obj = 122.5544, schedule = [3 1 1 0 1 0 1 1 0 2 0 1 1 0 1 1 1 1 0 8]\n  Candidate 2: Obj = 119.2175, schedule = [2 1 2 0 1 1 1 0 0 2 1 0 1 0 1 1 2 0 1 7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  2  0  1  1  0  2  0  2 -1  2  0  1  1  0  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  2  1  0  1  0  2  0  1  1  1  0  2 -1  1  1  1  1  1  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 120\nIteration 14 completed in 3.42 seconds.\n\n--- Iteration 15/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  1  1 -1  2  1  1  0  0  2  0  2  0  0  9]\n  Candidate 1: Obj = 133.5979, schedule = [2 0 2 0 0 2 1 0 0 1 1 2 1 0 1 0 1 0 2 8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  1  0  1  1  1  1  0  1  0  2  1  1 -1  2  7]\n  Candidate 3: Obj = 125.6929, schedule = [3 1 1 0 1 1 1 0 1 0 2 1 1 0 1 0 1 0 1 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  0  1  1  1  1  0  2 -1  2  1  0  1  1  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 125\nIteration 15 completed in 4.66 seconds.\n\n--- Iteration 16/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 131.6450, schedule = [2 0 1 1 0 1 2 0 1 1 0 1 2 0 0 1 2 0 0 9]\n  Candidate 1: Obj = 131.8712, schedule = [2 1 0 1 0 2 0 1 1 1 0 1 2 0 0 1 2 0 0 9]\n  Candidate 2: Obj = 132.0733, schedule = [2 1 0 1 0 2 0 2 0 1 0 1 2 0 1 0 2 0 0 9]\n  Candidate 3: Obj = 130.7426, schedule = [2 0 1 1 0 1 2 0 1 1 0 1 2 0 1 1 1 0 0 9]\n  Candidate 4: Obj = 131.2668, schedule = [2 1 0 1 0 1 1 2 0 1 0 1 2 0 1 1 1 0 0 9]\nBest objective value found so far: 114.9636\nTotal points evaluated: 130\nIteration 16 completed in 3.87 seconds.\n\n--- Iteration 17/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  1 -1  2  1  1 -1  1  1  2  0  0  1  1  2  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  0  2 -1  1  1  2  0  1  0  2  1 -1  1  9]\n  Candidate 2: Obj = 126.8993, schedule = [1 1 1 1 1 1 0 1 0 2 0 2 1 0 0 2 0 1 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  1  1  1  1 -1  1  2  1  0  0  1  2  1  0  1  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  2  0  2 -1  2  0  2  1 -1  1  1  2  0  1  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 135\nIteration 17 completed in 3.84 seconds.\n\n--- Iteration 18/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  1  2  0  0  1  2  0  1  1  1  0  2 -1  2  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  0  0  2  1  1  0  1  0  1  2 -1  2  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  1  2  1 -1  1  2  1  0  1  1  0  2 -1  2  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  2  0  1  1  0  2  1  1  0  1  0  2 -1  2  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  1 -1  1  2  0  1  1  1  0  2 -1  2  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 140\nIteration 18 completed in 4.55 seconds.\n\n--- Iteration 19/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  1  2 -1  2  1  0  1  0  1  1  2 -1  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1  0  0  1  1  2 -1  1  1  2 -1  1  8]\n  Candidate 2: Obj = 134.0474, schedule = [1 2 0 1 0 1 2 0 0 1 2 0 1 1 1 1 0 0 1 9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  0  1  2 -1  2  1  1  0  0  1  1  1  1  1  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  0  1  1  0  1  2  0  1  1  1  0  1  1  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 145\nIteration 19 completed in 5.49 seconds.\n\n--- Iteration 20/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  0  1  0  1  2  0  0  1  1  2  0  1  0  1  2 -1  1  8]\n  Candidate 1: Obj = 132.0745, schedule = [1 1 2 0 0 1 2 0 0 1 1 1 2 0 0 1 1 1 0 9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  1  2  0  0  1  1  1  0  1  1  1  0  2  7]\n  Candidate 3: Obj = 123.1035, schedule = [2 1 2 0 0 1 1 1 0 1 2 1 0 0 1 1 1 0 1 8]\n  Candidate 4: Obj = 130.1952, schedule = [1 1 1 1 0 1 1 1 0 2 0 1 1 1 0 1 1 0 2 8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 150\nIteration 20 completed in 4.79 seconds.\n\n--- Iteration 21/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  0  1  2  1  0  0  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  1  0  1  2  0  1  1  0  1  2 -1  1  1  2  0  0  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  2  0  0  1  2  1  0  1  1  1  0  1  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  1  1  0  0  1  1  1  1  1  0  2  0  0  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  1  2  0  0  2  1  0  1  1  0  1  1  0  1  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 155\nIteration 21 completed in 6.42 seconds.\n\n--- Iteration 22/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  2  0  0  1  2  0  0  1  1  2  0  1  0  1  2 -1  2  7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  1  2  1 -1  2  1  1  0  0  1  1  1  1  0  9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  0  2  1 -1  2  1  0  2  0  1  0  1  0  2  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  1  0  1  1  1  0  2  0  1  1  0  1  0  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  1  1  0  1  1  0  0  1  2  0  2 -1  2  1  1  0  1  7]\nBest objective value found so far: 114.9636\nTotal points evaluated: 160\nIteration 22 completed in 4.67 seconds.\n\n--- Iteration 23/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  2  0  1  0  2 -1  2  0  2  1  0  1  0  2  0  1  8]\n  Candidate 1: Obj = 126.1819, schedule = [2 1 0 2 0 1 0 2 0 0 2 1 0 1 1 0 2 0 1 8]\n  Candidate 2: Obj = 131.9391, schedule = [2 1 0 2 0 1 0 2 0 1 0 2 1 0 1 0 2 0 0 9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  0  2 -1  2  0  2  1  0  1  0  2  0  1  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  2  1  0  1  1  0  2  0  1  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 165\nIteration 23 completed in 4.24 seconds.\n\n--- Iteration 24/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  1  2 -1  2  0  2  0  0  1  1  2 -1  2  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  2  0  0  2  0  2  1  0  0  1  2 -1  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  1  1  0  2  0  1  1  0  2  0  0  1  1  2 -1  2  8]\n  Candidate 3: Obj = 132.0435, schedule = [1 2 0 1 0 1 1 1 0 2 0 2 0 0 1 1 1 0 2 8]\n  Candidate 4: Obj = 128.0151, schedule = [1 2 0 1 0 1 2 0 0 1 1 2 0 0 1 1 1 1 1 8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 170\nIteration 24 completed in 3.59 seconds.\n\n--- Iteration 25/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  1  0  1  1  1  1  1 -1  1  2  1 -1  2  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  2  0  2 -1  2  1  0  2  0  0  2  1 -1  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  2  1  0  0  2  1  0  2  0  1  1  1 -1  2  8]\n  Candidate 3: Obj = 126.7964, schedule = [2 1 0 1 1 1 0 1 0 2 0 1 2 0 0 2 1 0 1 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  0  2 -1  2  0  1  2  0  0  2  1  0  1  8]\nBest objective value found so far: 114.9636\nTotal points evaluated: 175\nIteration 25 completed in 4.78 seconds.\n\n--- Optimization Finished ---\nTotal evaluations: 175\nBest Objective Value Found: 114.96364292044709\nBest U vector Found: [0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1]\n\n--- Verification ---\nIs the best U feasible? True\nResulting Y vector for best U: [2 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 2 0 1 7]\nObjective value (recalculated): 114.9636\n\n\n\n\n6.4.6.5 5. Experiment 2: CBO with Lower Confidence Bound (LCB) - Fixed Kappa\nApplies the methodology from Deshwal et al. (2023) using LCB with fixed \\(\\kappa\\).\n\n# --- BO Helper Functions ---\n\n# --- get_fitted_model function remains the same ---\ndef get_fitted_model(train_X_embedded_scaled, train_Y, m):\n    # ... (implementation is unchanged) ...\n    if train_Y.ndim &gt; 1 and train_Y.shape[1] == 1: train_Y = train_Y.ravel()\n    kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \\\n             Matern(length_scale=np.ones(m), length_scale_bounds=(1e-2, 1e2), nu=2.5) + \\\n             WhiteKernel(noise_level=1e-10, # Small value for numerical stability\n                         noise_level_bounds=\"fixed\") # Bounds for noise optimization\n    gp_model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, n_restarts_optimizer=10, random_state=42)\n    gp_model.fit(train_X_embedded_scaled, train_Y)\n    return gp_model\n\ndef lower_confidence_bound(mu, sigma, kappa=2.576):\n    \"\"\"\n    Computes the Lower Confidence Bound (LCB) acquisition function.\n    Assumes maximization of this value guides the search (since mu is neg objective).\n    Higher LCB means lower predicted objective or lower penalty for uncertainty.\n\n    mu, sigma: Predicted mean and standard deviation (NumPy arrays).\n    kappa: Controls the balance between exploitation (high mu -&gt; low original objective)\n           and exploration (low sigma).\n    \"\"\"\n    # Ensure sigma is non-negative\n    sigma = np.maximum(sigma, 0)\n    return mu - kappa * sigma # &lt;&lt;&lt; Sign flipped from UCB\n\ndef optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, kappa):\n    \"\"\"\n    Optimizes LCB acquisition function by sampling random binary candidates,\n    embedding, SCALING, predicting with GP, and calculating LCB.\n    Selects the top q candidates based on LCB.\n    Returns candidates as a numpy array (q x T).\n    \"\"\"\n    m = dictionary_A.shape[0]\n\n    # 1. Generate Random Binary Candidates\n    candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))\n\n    # 2. Embed the Candidates\n    embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)\n\n    # 3. Scale the Embedded Candidates\n    embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)\n\n    # 4. Predict Mean and Std Dev using the GP Model\n    mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)\n\n    # 5. Calculate Acquisition Function (Lower Confidence Bound) &lt;&lt;&lt; CHANGED HERE\n    acq_values = lower_confidence_bound(mu, std, kappa=kappa) # Use LCB\n\n    # 6. Select Top Candidates (based on highest LCB) &lt;&lt;&lt; COMMENT UPDATED\n    # We maximize LCB = mu - kappa*sigma, where mu is neg_objective\n    top_indices = np.argsort(acq_values)[-q:]\n    top_indices = top_indices[::-1] # Ensure descending order of LCB\n\n    return candidate_u_vectors_np[top_indices, :]\n\n# --- BO Loop ---\n\n# Parameters\nKAPPA = 2.576 # Exploration parameter for LCB. Adjust as needed.\nN_INITIAL = 49 # The initial schedule will always be included\nN_ITERATIONS = 25\nBATCH_SIZE_q = 5\nNUM_CANDIDATES_Acqf = T*5*1024 # Might need more for higher T\nm = math.ceil(T/4) # Dimension of the embedding space\n\n# Store evaluated points (using NumPy arrays)\nevaluated_U_np_list = [] # List to store evaluated U vectors (binary)\nevaluated_f_vals = []    # List to store raw objective values (lower is better)\ntrain_Y_list = []        # List to store NEGATED objective values for GP (higher is better)\n\n# 1. Initialization\nfor U_init in initial_candidates:\n    f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)\n    neg_f_val = -f_val\n    evaluated_U_np_list.append(U_init)\n    evaluated_f_vals.append(f_val)\n    train_Y_list.append(neg_f_val)\n  \n# Convert lists to NumPy arrays for GP fitting\ntrain_Y = np.array(train_Y_list).reshape(-1, 1) # Keep as column vector initially\n\nbest_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')\ninitial_best_obj_so_far_lcb = best_obj_so_far # Saved for reporting results\nprint(f\"Initial best objective value: {best_obj_so_far}\")\nif not np.isfinite(best_obj_so_far):\n     print(\"Warning: Initial best objective is infinite, possibly all initial points were infeasible.\")\n\n# 2. BO Iterations\nfor iteration in range(N_ITERATIONS):\n    start_time = time.time()\n    print(f\"\\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---\")\n\n    # a. Generate dictionary A (remains the same)\n    current_dictionary_A = generate_diverse_random_dictionary(T, m)\n\n    # b. Embed ALL evaluated U vectors (remains the same)\n    if not evaluated_U_np_list: continue\n    evaluated_U_np_array = np.array(evaluated_U_np_list)\n    embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)\n\n    # c. Scale the embedded training data (remains the same)\n    scaler = MinMaxScaler()\n    if embedded_train_X.shape[0] &gt; 0: embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)\n    else: embedded_train_X_scaled = embedded_train_X\n\n    # Ensure train_Y is NumPy array\n    train_Y_for_fit = np.array(train_Y_list)\n\n    # d. Fit GP Model (remains the same)\n    print(\"Fitting GP model...\")\n    if embedded_train_X_scaled.shape[0] &gt; 0 and train_Y_for_fit.shape[0] == embedded_train_X_scaled.shape[0]:\n        gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)\n        print(\"GP model fitted.\")\n    else:\n        print(\"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration.\")\n        continue\n\n    # e. Determine current best neg value (useful for tracking, not directly used in LCB calculation)\n    current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size &gt; 0 else -float('inf')\n    if current_best_neg_f_val &lt;= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):\n        print(f\"Warning: Current best NEGATIVE objective value ({current_best_neg_f_val:.2f}) is very low (likely from penalties).\")\n\n    # f. Optimize Acquisition Function (LCB) &lt;&lt;&lt; MODIFIED CALL & COMMENT\n    print(\"Optimizing acquisition function (LCB)...\") # Comment updated\n    next_U_candidates_np = optimize_acqf_discrete_via_embedding(\n        gp_model=gp_model,\n        scaler=scaler,\n        dictionary_A=current_dictionary_A,\n        T=T,\n        q=BATCH_SIZE_q,\n        num_candidates=NUM_CANDIDATES_Acqf,\n        kappa=KAPPA # Pass kappa\n    )\n    print(f\"Selected {next_U_candidates_np.shape[0]} candidate(s).\")\n\n    # g. Evaluate Objective (remains the same)\n    newly_evaluated_U = []; newly_evaluated_f = []; newly_evaluated_neg_f = []\n    for i in range(next_U_candidates_np.shape[0]):\n        next_U = next_U_candidates_np[i, :]\n        already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)\n        if already_evaluated: print(f\"  Candidate {i} was already evaluated. Skipping.\"); continue\n\n        next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)\n        next_neg_f = -next_f\n        V_sum = np.sum(v_star[next_U == 1, :], axis=0)\n        Y = X + V_sum\n        print(f\"  Candidate {i}: Obj = {next_f:.4f}, schedule = {Y}\")\n        newly_evaluated_U.append(next_U); newly_evaluated_f.append(next_f); newly_evaluated_neg_f.append(next_neg_f)\n        if next_f &lt; best_obj_so_far: best_obj_so_far = next_f\n\n    # h. Augment Dataset (remains the same)\n    evaluated_U_np_list.extend(newly_evaluated_U); evaluated_f_vals.extend(newly_evaluated_f); train_Y_list.extend(newly_evaluated_neg_f)\n    train_Y = np.array(train_Y_list).reshape(-1, 1)\n\n    iter_time = time.time() - start_time\n    print(f\"Best objective value found so far: {best_obj_so_far:.4f}\")\n    print(f\"Total points evaluated: {len(evaluated_f_vals)}\")\n    print(f\"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.\")\n\n\n# --- Results ---\nprint(\"\\n--- Optimization Finished ---\")\nif not evaluated_f_vals: print(\"No points were successfully evaluated.\")\nelse:\n    final_best_idx_lcb = np.argmin(evaluated_f_vals)\n    final_best_U_lcb = evaluated_U_np_list[final_best_idx_lcb]\n    final_best_f_lcb = evaluated_f_vals[final_best_idx_lcb]\n    nr_evaluated_f_vals_lcb = len(evaluated_f_vals) # Saved for reporting results\n    print(f\"Total evaluations: {nr_evaluated_f_vals_lcb}\")\n    print(f\"Best Objective Value Found: {final_best_f_lcb}\")\n    print(f\"Best U vector Found: {final_best_U_lcb}\")\n\n    # Verification\n    V_sum_best = np.sum(v_star[final_best_U_lcb == 1, :], axis=0)\n    Y_best_lcb = X + V_sum_best\n    is_feasible = np.all(Y_best_lcb &gt;= 0)\n    recalculated_obj = LARGE_PENALTY\n    if is_feasible:\n        ewt, esp = calculate_objective_serv_time_lookup(Y_best_lcb, d, convolutions)\n        recalculated_obj = w * ewt + (1 - w) * esp\n\n    print(f\"\\n--- Verification ---\")\n    print(f\"Is the best U feasible? {is_feasible}\")\n    if is_feasible:\n        print(f\"Resulting Y vector for best U: {Y_best_lcb}\")\n        print(f\"Objective value (recalculated): {recalculated_obj:.4f}\")\n        if not np.isclose(final_best_f_lcb, recalculated_obj): print(f\"Warning: Stored best objective ({final_best_f:.4f}) does not match recalculation ({recalculated_obj:.4f})!\")\n    elif final_best_f_lcb &lt; LARGE_PENALTY: print(f\"Warning: Best objective ({final_best_f_lcb:.4f}) is not the penalty value, but feasibility check failed.\"); print(f\"Resulting Y vector (infeasible): {Y_best_lcb}\")\n    else: print(\"Best solution found corresponds to an infeasible penalty value.\")\n\nInitial best objective value: 118.87100166955729\n\n--- Iteration 1/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  1  1  1  0  0  2  1  1  0  1  0  1  2 -1  1  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  0  2 -1  1  1  2  0  0  1  1  1  1  1  8]\n  Candidate 2: Obj = 133.2394, schedule = [1 2 0 2 0 1 1 0 0 2 1 0 1 0 2 0 1 1 0 9]\n  Candidate 3: Obj = 134.0944, schedule = [2 1 1 0 0 2 0 1 0 2 0 2 0 0 2 1 0 1 0 9]\n  Candidate 4: Obj = 135.2522, schedule = [2 1 1 1 0 1 1 0 0 1 2 1 0 0 1 1 1 0 1 9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 55\nIteration 1 completed in 4.63 seconds.\n\n--- Iteration 2/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 129.3169, schedule = [1 2 1 1 0 0 1 1 0 2 1 1 0 0 1 2 1 0 1 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  0  1  1  0  2  1  1  1 -1  1  2  1  0  1  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  2  0  2 -1  2  1  1  1  0  0  1  2  0  1  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  0  2  0  0  1  2 -1  2  1  1  1 -1  1  2  1  0  1  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  0  1  2 -1  2  1  1  1 -1  1  1  2  0  1  7]\nBest objective value found so far: 118.8710\nTotal points evaluated: 60\nIteration 2 completed in 4.04 seconds.\n\n--- Iteration 3/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  0  2  1 -1  2  0  1  1  1  0  2  0  1  0  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  2 -1  2  1  1  1  0  1  1  0  1  0  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  2  1  0  1  1  1  1  0  1  1  1  0  1  0  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  1  1  1  0  2  0  1  2 -1  2  0  2  0  1  7]\n  Candidate 4: Obj = 117.6316, schedule = [2 1 1 1 0 1 2 0 0 1 2 0 1 0 1 2 1 0 1 7]\nBest objective value found so far: 117.6316\nTotal points evaluated: 65\nIteration 3 completed in 4.27 seconds.\n\n--- Iteration 4/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  1  0  1  0  2  0  0  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  1  1  1  1  0  0  8]\n  Candidate 2: Obj = 117.4455, schedule = [2 1 1 2 0 1 1 0 1 0 2 0 2 0 1 0 2 0 1 7]\n  Candidate 3: Obj = 118.6866, schedule = [3 0 1 2 0 1 1 0 1 0 2 1 0 1 0 2 0 1 1 7]\n  Candidate 4: Obj = 115.6020, schedule = [2 1 2 0 1 1 0 1 1 0 2 0 2 0 1 1 1 0 1 7]\nBest objective value found so far: 115.6020\nTotal points evaluated: 70\nIteration 4 completed in 4.70 seconds.\n\n--- Iteration 5/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  1 -1  1  1  2  1  0  1  0  2  0  1  7]\n  Candidate 1: Obj = 120.3275, schedule = [3 1 1 1 0 1 1 1 0 0 1 1 1 0 2 1 0 1 1 7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  1  0  1  1  1  1 -1  2  0  2  1 -1  2  1  0  1  0  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  2  1 -1  2  1  1  1 -1  2  0  1  0  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  1  0  1  1  0  0  2  0  2  1 -1  2  0  2  0  1  8]\nBest objective value found so far: 115.6020\nTotal points evaluated: 75\nIteration 5 completed in 3.88 seconds.\n\n--- Iteration 6/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  1  0  1  0  1  1  1  0  1  2  1  0  1  8]\n  Candidate 1: Obj = 128.5334, schedule = [2 1 1 0 0 1 2 1 0 0 1 1 1 0 1 2 1 0 1 8]\n  Candidate 2: Obj = 127.5458, schedule = [2 0 2 0 0 2 1 0 1 1 0 1 1 0 1 2 1 0 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  2  1 -1  1  2  0  1  1  1  0  2 -1  1  2  1  0  1  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  0  1  1  0  1  1  0  1  2  1 -1  1  9]\nBest objective value found so far: 115.6020\nTotal points evaluated: 80\nIteration 6 completed in 3.95 seconds.\n\n--- Iteration 7/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  0  1  1  1  0  1  1  0  1  2 -1  2  0  1  1  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  0  2 -1  2  0  1  2  0  0  2  1  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  1 -1  2  0  1  2 -1  1  2  1  0  1  8]\n  Candidate 3: Obj = 125.7593, schedule = [2 0 2 0 0 2 0 1 1 1 0 1 2 0 1 0 2 0 1 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  0  2  0  1  0  1  2 -1  1  2  1  0  1  8]\nBest objective value found so far: 115.6020\nTotal points evaluated: 85\nIteration 7 completed in 4.11 seconds.\n\n--- Iteration 8/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 123.2298, schedule = [2 1 2 0 1 0 2 0 1 0 1 1 2 0 0 1 1 0 1 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  2  0  1  0  2  0  1  0  2  0  2 -1  1  1  1  0  1  8]\n  Candidate 2: Obj = 123.1074, schedule = [2 1 2 0 0 1 2 0 1 1 0 1 2 0 0 1 1 0 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  0  1  0  1  2  1 -1  1  1  1  0  1  8]\n  Candidate 4: Obj = 124.3234, schedule = [2 1 2 0 0 2 1 0 1 0 2 1 0 0 1 1 1 0 1 8]\nBest objective value found so far: 115.6020\nTotal points evaluated: 90\nIteration 8 completed in 3.96 seconds.\n\n--- Iteration 9/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 130.8021, schedule = [1 2 0 2 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 9]\n  Candidate 1: Obj = 130.5450, schedule = [2 1 0 2 0 1 1 1 0 1 0 1 2 0 1 0 1 1 0 9]\n  Candidate 2: Obj = 124.2772, schedule = [2 1 0 2 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 8]\n  Candidate 3: Obj = 126.1602, schedule = [1 2 0 2 0 1 1 1 0 1 0 2 0 1 0 1 2 0 1 8]\n  Candidate 4: Obj = 132.6468, schedule = [2 1 0 2 0 1 1 1 0 0 2 1 1 0 0 1 1 1 0 9]\nBest objective value found so far: 115.6020\nTotal points evaluated: 95\nIteration 9 completed in 4.18 seconds.\n\n--- Iteration 10/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  0  2 -1  2  1  0  1  1  0  2  1  0  1  1  0  1  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  1  2  1  0  1  0  2  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  0  1  2  1  0  1  0  2  0  1  8]\n  Candidate 3: Obj = 128.4867, schedule = [1 1 2 0 0 2 1 1 0 0 2 1 1 0 0 2 1 0 1 8]\n  Candidate 4: Obj = 130.2438, schedule = [1 1 1 1 0 2 1 1 0 1 1 1 1 0 1 1 1 0 0 9]\nBest objective value found so far: 115.6020\nTotal points evaluated: 100\nIteration 10 completed in 5.25 seconds.\n\n--- Iteration 11/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 130.5600, schedule = [2 0 1 1 1 0 2 0 1 1 0 1 1 1 0 2 0 0 2 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  2  0  1  1  1  1  0  0  1  1  1  0  2  8]\n  Candidate 2: Obj = 134.2707, schedule = [2 0 1 1 0 2 1 0 1 1 1 1 0 0 1 2 0 0 1 9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  1  2  0  1  0  1  2  1 -1  1  2  1 -1  1  9]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  1  0  1  2  1  0  0  2  0  0  2  8]\nBest objective value found so far: 115.6020\nTotal points evaluated: 105\nIteration 11 completed in 4.73 seconds.\n\n--- Iteration 12/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  1  1  0  1  1  1  0  0  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  0  2  1 -1  2  1  0  2  0  1  1  1  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  0  2  0  1  1  1  0  1  0  2  1 -1  2  1  1  0  1  7]\n  Candidate 3: Obj = 125.1870, schedule = [1 2 0 2 0 0 2 1 0 1 1 1 1 0 1 0 2 0 1 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2  0  1  1  1 -1  2  1  0  2  0  1  1  1  0  1  8]\nBest objective value found so far: 115.6020\nTotal points evaluated: 110\nIteration 12 completed in 5.29 seconds.\n\n--- Iteration 13/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 131.4070, schedule = [2 1 1 0 1 0 1 1 0 1 1 2 0 1 0 1 1 1 0 9]\n  Candidate 1: Obj = 122.3589, schedule = [2 2 1 0 1 0 1 2 0 0 1 2 0 1 0 1 1 1 0 8]\n  Candidate 2: Obj = 131.4070, schedule = [2 1 1 0 1 0 1 1 0 1 1 2 0 1 0 1 1 1 0 9]\n  Candidate 3: Obj = 131.4662, schedule = [2 1 1 0 1 0 1 1 1 0 1 2 0 0 1 1 1 1 0 9]\n  Candidate 4: Obj = 122.4985, schedule = [3 1 0 1 1 0 1 2 0 0 1 2 0 1 0 1 1 0 2 7]\nBest objective value found so far: 115.6020\nTotal points evaluated: 115\nIteration 13 completed in 8.04 seconds.\n\n--- Iteration 14/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 122.3147, schedule = [3 0 2 0 0 1 2 0 0 1 2 0 1 1 1 1 0 1 0 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  1  1  2 -1  1  1  1  1  0  2  1  0  1  0  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  2  1 -1  2  1  0  1  0  2  0  1  1  0  8]\n  Candidate 3: Obj = 115.1129, schedule = [2 1 1 1 0 1 2 0 0 1 2 0 1 1 1 1 1 0 1 7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  1  2  0  0  1  1  2  0  0  2  0  1  1  0  8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 120\nIteration 14 completed in 7.87 seconds.\n\n--- Iteration 15/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 123.3545, schedule = [2 1 2 0 0 2 1 1 0 1 0 1 1 0 2 0 2 0 0 8]\n  Candidate 1: Obj = 118.9808, schedule = [2 1 2 0 0 2 1 1 0 0 1 1 1 0 2 0 2 0 1 7]\n  Candidate 2: Obj = 124.7961, schedule = [3 1 0 2 0 0 2 0 0 2 0 2 0 1 0 2 0 0 2 7]\n  Candidate 3: Obj = 122.3054, schedule = [2 2 0 2 0 0 1 1 1 1 1 1 1 0 0 1 1 0 2 7]\n  Candidate 4: Obj = 133.7135, schedule = [2 0 2 0 0 2 1 0 0 2 0 1 1 0 2 1 0 1 0 9]\nBest objective value found so far: 115.1129\nTotal points evaluated: 125\nIteration 15 completed in 6.16 seconds.\n\n--- Iteration 16/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 124.3527, schedule = [3 1 0 2 0 0 2 0 1 1 0 2 0 0 1 1 2 0 0 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  2  0  0  1  2  1  1 -1  2  0  2 -1  2  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  0  1  1  1  0  2  1  0  0  2  0  2 -1  1  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  0  2 -1  2  1  1  0  0  1  1  2  0  0  8]\n  Candidate 4: Obj = 132.6420, schedule = [2 0 1 2 0 0 1 1 0 1 2 0 1 0 1 2 0 0 2 8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 130\nIteration 16 completed in 6.82 seconds.\n\n--- Iteration 17/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  1  1  0  1  0  1  2  0  1  0  1  1  2 -1  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  0  1  1  1  0  1  0  1  2  0  1  0  1  1  2 -1  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  0  1  1  0  1  1  1  0  2  1  1  0  0  1  2 -1  1  8]\n  Candidate 3: Obj = 123.5410, schedule = [2 2 0 1 1 1 1 0 0 1 2 0 1 1 0 1 1 0 1 8]\n  Candidate 4: Obj = 122.4941, schedule = [2 2 0 1 1 0 1 1 1 1 0 1 2 0 0 1 1 0 1 8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 135\nIteration 17 completed in 7.43 seconds.\n\n--- Iteration 18/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  1  0  1  0  2  1 -1  2  0  1  1  0  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  2 -1  2  1  1  0  1  0  2  0  1  0  1  1  1  0  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  2  1  1 -1  2  1  1  0  0  1  1  1  1  0  2  0  1  0  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  2  0  2  0  1  0  1  1  0  1  2  0  1  0  9]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  1  0  2 -1  2  1  1  0  0  1  1  1  0  2  1  0  1  0  8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 140\nIteration 18 completed in 8.02 seconds.\n\n--- Iteration 19/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  1  1  0  0  2  1  1 -1  2  1  1  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  1  0  1  1  2 -1  1  1  1  1  0  1  1  1  1  1  7]\n  Candidate 2: Obj = 132.4621, schedule = [2 1 1 0 1 1 0 2 0 0 2 1 1 0 1 1 0 0 2 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  1  2 -1  2  1  0  1  0  2  0  1  0  1  8]\n  Candidate 4: Obj = 133.4902, schedule = [1 1 1 1 0 1 2 0 0 2 0 1 1 0 2 0 1 0 1 9]\nBest objective value found so far: 115.1129\nTotal points evaluated: 145\nIteration 19 completed in 6.84 seconds.\n\n--- Iteration 20/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  2  0  1  0  1  0  2  1  1  1 -1  2  1  0  1  0  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  1  2  0  1  0  2 -1  2  0  2  0  1  0  1  1  0  2  8]\n  Candidate 2: Obj = 126.6556, schedule = [1 2 0 1 0 1 1 2 0 1 1 0 1 0 2 1 0 1 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  0  0  2  1  1  0  0  1  1  1  1  0  1  2 -1  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  2  1  0  0  1  2 -1  2  0  1  1  0  2  1  0  1  1  7]\nBest objective value found so far: 115.1129\nTotal points evaluated: 150\nIteration 20 completed in 8.16 seconds.\n\n--- Iteration 21/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 123.3261, schedule = [2 1 2 1 0 1 0 2 0 0 1 1 2 0 1 0 2 0 0 8]\n  Candidate 1: Obj = 123.2211, schedule = [2 1 2 1 0 1 0 2 0 0 1 2 0 1 1 0 2 0 0 8]\n  Candidate 2: Obj = 122.8762, schedule = [2 1 2 1 0 1 1 1 0 0 1 1 2 0 1 0 1 1 0 8]\n  Candidate 3: Obj = 132.0113, schedule = [1 1 2 1 0 1 0 2 0 0 1 1 2 0 1 0 1 0 2 8]\n  Candidate 4: Obj = 118.8922, schedule = [2 2 0 2 0 1 1 0 0 1 1 2 1 0 1 0 1 1 1 7]\nBest objective value found so far: 115.1129\nTotal points evaluated: 155\nIteration 21 completed in 7.71 seconds.\n\n--- Iteration 22/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 124.9031, schedule = [3 0 2 1 0 0 2 1 0 1 1 0 1 0 2 0 2 0 0 8]\n  Candidate 1: Obj = 120.0952, schedule = [3 0 2 1 0 0 2 1 0 1 0 1 1 0 2 0 2 0 1 7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  0  1  1  1  0  2 -1  1  2  1  0  0  8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  1  1  0  1  1  0  2 -1  2  0  1  1  0  8]\n  Candidate 4: Obj = 119.4426, schedule = [2 1 2 1 0 0 2 1 0 1 1 0 1 0 2 0 2 0 1 7]\nBest objective value found so far: 115.1129\nTotal points evaluated: 160\nIteration 22 completed in 6.18 seconds.\n\n--- Iteration 23/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  1  1  0  1  0  2  0  2 -1  2  0  2  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  2  0  2 -1  2  1  1  0  1  1  1  0  1  1  0  2  0  1  7]\n  Candidate 2: Obj = 123.1513, schedule = [1 1 1 1 1 1 0 2 0 1 0 2 0 1 1 1 0 1 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  0  1  1  1  1  0  1  1  1  1  1 -1  2  0  2 -1  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  2  1  1  0  1  1  0  1  1  1  1  1 -1  2  8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 165\nIteration 23 completed in 4.94 seconds.\n\n--- Iteration 24/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 125.8798, schedule = [2 1 1 1 0 0 1 1 1 1 1 1 1 0 0 2 1 0 1 8]\n  Candidate 1: Obj = 127.9569, schedule = [2 1 1 1 0 0 2 0 1 0 2 1 1 0 0 2 1 0 1 8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  2  0  1  1  1  1  1  0  0  2  1 -1  2  8]\n  Candidate 3: Obj = 127.9569, schedule = [2 1 1 1 0 0 2 0 1 0 2 1 1 0 0 2 1 0 1 8]\n  Candidate 4: Obj = 126.5368, schedule = [2 1 1 1 0 0 2 0 1 1 1 1 1 0 0 1 1 1 1 8]\nBest objective value found so far: 115.1129\nTotal points evaluated: 170\nIteration 24 completed in 6.99 seconds.\n\n--- Iteration 25/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  2  1  0  0  2  1 -1  2  0  2  1 -1  1  2  1  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  1  0  1  1  1  1 -1  1  1  2  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  1  0  1  1  1  1 -1  1  2  1  0  1  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  0  2  1  0  1  1  1  1 -1  1  2  1  0  1  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  1 -1  2  1  1  0  1  1  1  1 -1  1  2  1  0  0  9]\nBest objective value found so far: 115.1129\nTotal points evaluated: 175\nIteration 25 completed in 6.32 seconds.\n\n--- Optimization Finished ---\nTotal evaluations: 175\nBest Objective Value Found: 115.11287490459011\nBest U vector Found: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1]\n\n--- Verification ---\nIs the best U feasible? True\nResulting Y vector for best U: [2 1 1 1 0 1 2 0 0 1 2 0 1 1 1 1 1 0 1 7]\nObjective value (recalculated): 115.1129\n\n\n\n\n6.4.6.6 6. Experiment 3: CBO with LCB and wavelet dictionary.\n\n# --- BO Helper Functions ---\n\n# --- get_fitted_model function remains the same ---\ndef get_fitted_model(train_X_embedded_scaled, train_Y, m):\n    # ... (implementation is unchanged) ...\n    if train_Y.ndim &gt; 1 and train_Y.shape[1] == 1: train_Y = train_Y.ravel()\n    kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \\\n             Matern(length_scale=np.ones(m), length_scale_bounds=(1e-2, 1e2), nu=2.5) + \\\n             WhiteKernel(noise_level=1e-10, # Small value for numerical stability\n                         noise_level_bounds=\"fixed\") # Bounds for noise optimization\n    gp_model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, n_restarts_optimizer=10, random_state=42)\n    gp_model.fit(train_X_embedded_scaled, train_Y)\n    return gp_model\n\ndef lower_confidence_bound(mu, sigma, kappa=2.576):\n    \"\"\"\n    Computes the Lower Confidence Bound (LCB) acquisition function.\n    Assumes maximization of this value guides the search (since mu is neg objective).\n    Higher LCB means lower predicted objective or lower penalty for uncertainty.\n\n    mu, sigma: Predicted mean and standard deviation (NumPy arrays).\n    kappa: Controls the balance between exploitation (high mu -&gt; low original objective)\n           and exploration (low sigma).\n    \"\"\"\n    # Ensure sigma is non-negative\n    sigma = np.maximum(sigma, 0)\n    return mu - kappa * sigma # &lt;&lt;&lt; Sign flipped from UCB\n\ndef optimize_acqf_discrete_via_embedding(gp_model, scaler, dictionary_A, T, q, num_candidates, kappa):\n    \"\"\"\n    Optimizes LCB acquisition function by sampling random binary candidates,\n    embedding, SCALING, predicting with GP, and calculating LCB.\n    Selects the top q candidates based on LCB.\n    Returns candidates as a numpy array (q x T).\n    \"\"\"\n    m = dictionary_A.shape[0]\n\n    # 1. Generate Random Binary Candidates\n    candidate_u_vectors_np = np.random.randint(0, 2, size=(num_candidates, T))\n\n    # 2. Embed the Candidates\n    embedded_candidates_np = embed_batch(candidate_u_vectors_np, dictionary_A)\n\n    # 3. Scale the Embedded Candidates\n    embedded_candidates_scaled_np = scaler.transform(embedded_candidates_np)\n\n    # 4. Predict Mean and Std Dev using the GP Model\n    mu, std = gp_model.predict(embedded_candidates_scaled_np, return_std=True)\n\n    # 5. Calculate Acquisition Function (Lower Confidence Bound) &lt;&lt;&lt; CHANGED HERE\n    acq_values = lower_confidence_bound(mu, std, kappa=kappa) # Use LCB\n\n    # 6. Select Top Candidates (based on highest LCB) &lt;&lt;&lt; COMMENT UPDATED\n    # We maximize LCB = mu - kappa*sigma, where mu is neg_objective\n    top_indices = np.argsort(acq_values)[-q:]\n    top_indices = top_indices[::-1] # Ensure descending order of LCB\n\n    return candidate_u_vectors_np[top_indices, :]\n\n# --- BO Loop ---\n\n# Parameters\nKAPPA = 2.576 # Exploration parameter for LCB. Adjust as needed.\nN_INITIAL = 49 # The initial schedule will always be included\nN_ITERATIONS = 25\nBATCH_SIZE_q = 5\nNUM_CANDIDATES_Acqf = T*5*1024 # Might need more for higher T\nm = math.ceil(T/4) # Dimension of the embedding space\n\n# Store evaluated points (using NumPy arrays)\nevaluated_U_np_list = [] # List to store evaluated U vectors (binary)\nevaluated_f_vals = []    # List to store raw objective values (lower is better)\ntrain_Y_list = []        # List to store NEGATED objective values for GP (higher is better)\n\n# 1. Initialization\nfor U_init in initial_candidates:\n    f_val = evaluate_objective(U_init, X, v_star, convolutions, d, w)\n    neg_f_val = -f_val\n    evaluated_U_np_list.append(U_init)\n    evaluated_f_vals.append(f_val)\n    train_Y_list.append(neg_f_val)\n  \n# Convert lists to NumPy arrays for GP fitting\ntrain_Y = np.array(train_Y_list).reshape(-1, 1) # Keep as column vector initially\n\nbest_obj_so_far = min(evaluated_f_vals) if evaluated_f_vals else float('inf')\ninitial_best_obj_so_far_lcb = best_obj_so_far # Saved for reporting results\nprint(f\"Initial best objective value: {best_obj_so_far}\")\nif not np.isfinite(best_obj_so_far):\n     print(\"Warning: Initial best objective is infinite, possibly all initial points were infeasible.\")\n\n# 2. BO Iterations\nfor iteration in range(N_ITERATIONS):\n    start_time = time.time()\n    print(f\"\\n--- Iteration {iteration + 1}/{N_ITERATIONS} ---\")\n\n    # a. Generate dictionary A (remains the same)\n    current_dictionary_A = generate_wavelet_dictionary(T, m)\n\n    # b. Embed ALL evaluated U vectors (remains the same)\n    if not evaluated_U_np_list: continue\n    evaluated_U_np_array = np.array(evaluated_U_np_list)\n    embedded_train_X = embed_batch(evaluated_U_np_array, current_dictionary_A)\n\n    # c. Scale the embedded training data (remains the same)\n    scaler = MinMaxScaler()\n    if embedded_train_X.shape[0] &gt; 0: embedded_train_X_scaled = scaler.fit_transform(embedded_train_X)\n    else: embedded_train_X_scaled = embedded_train_X\n\n    # Ensure train_Y is NumPy array\n    train_Y_for_fit = np.array(train_Y_list)\n\n    # d. Fit GP Model (remains the same)\n    print(\"Fitting GP model...\")\n    if embedded_train_X_scaled.shape[0] &gt; 0 and train_Y_for_fit.shape[0] == embedded_train_X_scaled.shape[0]:\n        gp_model = get_fitted_model(embedded_train_X_scaled, train_Y_for_fit, m)\n        print(\"GP model fitted.\")\n    else:\n        print(\"Warning: Not enough data or data mismatch to fit GP model. Skipping iteration.\")\n        continue\n\n    # e. Determine current best neg value (useful for tracking, not directly used in LCB calculation)\n    current_best_neg_f_val = np.max(train_Y_for_fit) if train_Y_for_fit.size &gt; 0 else -float('inf')\n    if current_best_neg_f_val &lt;= -LARGE_PENALTY / 2 and np.isfinite(current_best_neg_f_val):\n        print(f\"Warning: Current best NEGATIVE objective value ({current_best_neg_f_val:.2f}) is very low (likely from penalties).\")\n\n    # f. Optimize Acquisition Function (LCB) &lt;&lt;&lt; MODIFIED CALL & COMMENT\n    print(\"Optimizing acquisition function (LCB)...\") # Comment updated\n    next_U_candidates_np = optimize_acqf_discrete_via_embedding(\n        gp_model=gp_model,\n        scaler=scaler,\n        dictionary_A=current_dictionary_A,\n        T=T,\n        q=BATCH_SIZE_q,\n        num_candidates=NUM_CANDIDATES_Acqf,\n        kappa=KAPPA # Pass kappa\n    )\n    print(f\"Selected {next_U_candidates_np.shape[0]} candidate(s).\")\n\n    # g. Evaluate Objective (remains the same)\n    newly_evaluated_U = []; newly_evaluated_f = []; newly_evaluated_neg_f = []\n    for i in range(next_U_candidates_np.shape[0]):\n        next_U = next_U_candidates_np[i, :]\n        already_evaluated = any(np.array_equal(next_U, u) for u in evaluated_U_np_list)\n        if already_evaluated: print(f\"  Candidate {i} was already evaluated. Skipping.\"); continue\n\n        next_f = evaluate_objective(next_U, X, v_star, convolutions, d, w)\n        next_neg_f = -next_f\n        V_sum = np.sum(v_star[next_U == 1, :], axis=0)\n        Y = X + V_sum\n        print(f\"  Candidate {i}: Obj = {next_f:.4f}, schedule = {Y}\")\n        newly_evaluated_U.append(next_U); newly_evaluated_f.append(next_f); newly_evaluated_neg_f.append(next_neg_f)\n        if next_f &lt; best_obj_so_far: best_obj_so_far = next_f\n\n    # h. Augment Dataset (remains the same)\n    evaluated_U_np_list.extend(newly_evaluated_U); evaluated_f_vals.extend(newly_evaluated_f); train_Y_list.extend(newly_evaluated_neg_f)\n    train_Y = np.array(train_Y_list).reshape(-1, 1)\n\n    iter_time = time.time() - start_time\n    print(f\"Best objective value found so far: {best_obj_so_far:.4f}\")\n    print(f\"Total points evaluated: {len(evaluated_f_vals)}\")\n    print(f\"Iteration {iteration + 1} completed in {iter_time:.2f} seconds.\")\n\n\n# --- Results ---\nprint(\"\\n--- Optimization Finished ---\")\nif not evaluated_f_vals: print(\"No points were successfully evaluated.\")\nelse:\n    final_best_idx_lcb = np.argmin(evaluated_f_vals)\n    final_best_U_lcb = evaluated_U_np_list[final_best_idx_lcb]\n    final_best_f_lcb = evaluated_f_vals[final_best_idx_lcb]\n    nr_evaluated_f_vals_lcb = len(evaluated_f_vals) # Saved for reporting results\n    print(f\"Total evaluations: {nr_evaluated_f_vals_lcb}\")\n    print(f\"Best Objective Value Found: {final_best_f_lcb}\")\n    print(f\"Best U vector Found: {final_best_U_lcb}\")\n\n    # Verification\n    V_sum_best = np.sum(v_star[final_best_U_lcb == 1, :], axis=0)\n    Y_best_lcb = X + V_sum_best\n    is_feasible = np.all(Y_best_lcb &gt;= 0)\n    recalculated_obj = LARGE_PENALTY\n    if is_feasible:\n        ewt, esp = calculate_objective_serv_time_lookup(Y_best_lcb, d, convolutions)\n        recalculated_obj = w * ewt + (1 - w) * esp\n\n    print(f\"\\n--- Verification ---\")\n    print(f\"Is the best U feasible? {is_feasible}\")\n    if is_feasible:\n        print(f\"Resulting Y vector for best U: {Y_best_lcb}\")\n        print(f\"Objective value (recalculated): {recalculated_obj:.4f}\")\n        if not np.isclose(final_best_f_lcb, recalculated_obj): print(f\"Warning: Stored best objective ({final_best_f:.4f}) does not match recalculation ({recalculated_obj:.4f})!\")\n    elif final_best_f_lcb &lt; LARGE_PENALTY: print(f\"Warning: Best objective ({final_best_f_lcb:.4f}) is not the penalty value, but feasibility check failed.\"); print(f\"Resulting Y vector (infeasible): {Y_best_lcb}\")\n    else: print(\"Best solution found corresponds to an infeasible penalty value.\")\n\nInitial best objective value: 118.87100166955729\n\n--- Iteration 1/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  1  0  0  2  0  2  1  0  0  1  1  1  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  2  0  1  0  1  1  2  1  0  1  1  0  0  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  1  1  1  1  1  1 -1  2  0  1  1  1  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  1  1  1  0  2  0  1  1  1  0  2  1 -1  1  8]\n  Candidate 4: Obj = 123.5187, schedule = [2 1 1 1 0 2 1 0 0 1 1 2 0 1 1 1 0 0 1 8]\nBest objective value found so far: 118.8710\nTotal points evaluated: 55\nIteration 1 completed in 3.57 seconds.\n\n--- Iteration 2/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 130.8475, schedule = [1 2 0 1 1 1 0 2 0 1 1 0 1 1 0 2 1 0 0 9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  1  1  1  0  2 -1  2  0  2  0  1  0  2  1  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  0  1  1  1  1  0  1  0  2  0  0  1  2  1 -1  1  9]\n  Candidate 3: Obj = 121.4522, schedule = [2 1 2 0 1 1 1 0 1 1 0 2 0 1 1 1 1 0 0 8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  1  1  0  1  0  2  1 -1  1  2  0  1  1  8]\nBest objective value found so far: 118.8710\nTotal points evaluated: 60\nIteration 2 completed in 3.65 seconds.\n\n--- Iteration 3/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 131.7503, schedule = [1 2 0 2 0 1 0 2 0 1 1 1 0 1 0 2 1 0 0 9]\n  Candidate 1: Obj = 124.4007, schedule = [3 1 0 1 1 1 1 1 0 1 0 2 1 0 0 2 1 0 0 8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  0  2  0  1  1  1  1 -1  1  2  1 -1  2  8]\n  Candidate 3: Obj = 123.8613, schedule = [3 1 0 1 1 1 0 2 0 1 1 1 1 0 0 2 1 0 0 8]\n  Candidate 4: Obj = 127.0363, schedule = [2 1 0 1 0 2 1 1 0 1 0 1 2 0 0 2 1 0 1 8]\nBest objective value found so far: 118.8710\nTotal points evaluated: 65\nIteration 3 completed in 3.93 seconds.\n\n--- Iteration 4/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  0  1  2 -1  2  1  0  2 -1  2  0  2  0  0  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  0  1  0  2  1  0  1  0  1  1  0  1  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  0  1  0  1  1  1  0  2  1  1  0  0  2  0  2 -1  2  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  0  2 -1  1  2  0  0  2  1  0  2 -1  2  1  0  1  0  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  0  1  0  2  0  2 -1  1  9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 70\nIteration 4 completed in 4.20 seconds.\n\n--- Iteration 5/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  1  1  1  1  1  0  0  2  1  0  1  0  9]\n  Candidate 1: Obj = 128.2031, schedule = [2 1 1 0 0 1 2 1 0 1 0 2 1 0 0 2 0 1 1 8]\n  Candidate 2: Obj = 125.0659, schedule = [1 1 1 1 0 1 2 0 1 1 1 1 0 1 0 2 0 1 1 8]\n  Candidate 3: Obj = 131.4179, schedule = [2 1 0 1 0 1 2 1 0 1 1 0 2 0 1 1 1 0 0 9]\n  Candidate 4: Obj = 132.0015, schedule = [2 0 1 1 0 1 1 1 1 1 1 1 0 0 2 1 1 0 0 9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 75\nIteration 5 completed in 4.52 seconds.\n\n--- Iteration 6/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  2  0  1  0  1  2  1  1 -1  1  1  2  0  0  9]\n  Candidate 1: Obj = 123.5175, schedule = [2 1 1 1 0 2 0 1 0 1 1 2 0 0 2 1 0 0 1 8]\n  Candidate 2: Obj = 123.2617, schedule = [3 0 1 1 0 1 1 1 0 2 1 0 1 0 2 0 1 0 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  1  0  2  0  1  1  1  0  1  0  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  1  0  1  2  0  1  1  0  2  0  0  2  0  2 -1  1  9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 80\nIteration 6 completed in 4.32 seconds.\n\n--- Iteration 7/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  0  2 -1  2  1  0  1  0  2  0  1  1  0  9]\n  Candidate 1: Obj = 133.3148, schedule = [2 1 1 0 0 2 0 1 0 1 2 0 1 0 2 0 1 0 2 8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  2  1 -1  2  1  0  1  1  0  2  0  1  0  1  1  1  1  7]\n  Candidate 3: Obj = 124.1344, schedule = [3 1 1 0 1 1 1 0 0 2 0 1 1 1 0 2 0 0 2 7]\n  Candidate 4: Obj = 132.5415, schedule = [1 1 1 2 0 1 0 2 0 1 0 1 1 1 1 1 0 0 1 9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 85\nIteration 7 completed in 4.17 seconds.\n\n--- Iteration 8/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  2  1  0  0  1  2  0  0  1  2  1  1 -1  2  1  0  0  2  7]\n  Candidate 1: Obj = 124.7751, schedule = [3 0 1 2 0 0 2 0 1 0 1 2 1 0 1 0 1 0 1 8]\n  Candidate 2: Obj = 122.3063, schedule = [2 1 2 0 0 1 2 1 0 1 1 1 1 0 1 0 1 0 2 7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  2  1  1  0  0  1  1  0  1  1  2  0  0  1  1  2 -1  1  8]\n  Candidate 4: Obj = 132.8389, schedule = [2 0 2 1 0 1 0 1 1 0 1 2 0 0 1 2 0 0 2 8]\nBest objective value found so far: 118.8710\nTotal points evaluated: 90\nIteration 8 completed in 4.06 seconds.\n\n--- Iteration 9/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  2  0  1  1  0  2 -1  1  1  2  1  0  0  2  1  0  1  8]\n  Candidate 1: Obj = 132.6826, schedule = [2 1 0 2 0 0 2 1 0 0 1 1 1 1 0 2 0 0 2 8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  1  2  1  0  1  0  1  2  0  0  1  1  1  1  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  2  0  2  0  0  1  1  2 -1  1  1  1  1  0  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  0  1  2  0  1  0  1  2 -1  2  0  1  0  2  7]\nBest objective value found so far: 118.8710\nTotal points evaluated: 95\nIteration 9 completed in 3.84 seconds.\n\n--- Iteration 10/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1  0  0  2  1 -1  2  0  1  2  0  1  0  1  1  1  7]\n  Candidate 1: Obj = 131.3891, schedule = [2 0 1 1 1 1 1 0 0 2 0 1 2 0 1 0 1 1 0 9]\n  Candidate 2: Obj = 132.6630, schedule = [2 0 1 2 0 1 1 0 0 1 1 1 2 0 0 2 0 1 0 9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  2  1  0  1  1  0  0  2  0  1  1  1  0  2  1 -1  2  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  2  1  1  0  1  1  0  1  1  0  1  1  0  1  9]\nBest objective value found so far: 118.8710\nTotal points evaluated: 100\nIteration 10 completed in 4.38 seconds.\n\n--- Iteration 11/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 119.2401, schedule = [2 1 2 0 1 1 1 0 0 1 2 1 0 0 1 1 1 1 1 7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  1  2  0  0  2  1  0  0  1  2  1  1 -1  1  1  1  0  2  8]\n  Candidate 2: Obj = 129.2138, schedule = [1 1 2 0 0 2 1 0 0 1 2 1 0 0 1 1 1 1 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  2  0  0  2  0  2  0  0  1  2  1 -1  1  1  1  0  2  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  2  0  2 -1  1  1  2  0  0  2  0  1  0  2  7]\nBest objective value found so far: 118.8710\nTotal points evaluated: 105\nIteration 11 completed in 4.10 seconds.\n\n--- Iteration 12/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  1  2  0  0  2  1  0  1  0  1  1  1  0  2  7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 1  2  0  2 -1  2  1  0  0  2  1  0  2 -1  2  0  1  1  0  9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  1  0  1  0  2  1 -1  2  1  0  2 -1  2  0  1  1  0  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  1  1  1 -1  2  1  0  2 -1  1  2  0  0  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  0  2 -1  2  1  1 -1  2  1  0  1  0  2  1  0  0  2  8]\nBest objective value found so far: 118.8710\nTotal points evaluated: 110\nIteration 12 completed in 4.41 seconds.\n\n--- Iteration 13/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 118.2240, schedule = [3 0 1 2 0 0 1 1 1 0 2 0 1 0 2 0 1 1 1 7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  2 -1  2  0  1  1  0  2  0  1  1  1  8]\n  Candidate 2: Obj = 117.9711, schedule = [3 0 1 2 0 0 1 1 1 0 1 1 1 0 2 0 2 0 1 7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 2  0  1  2 -1  1  1  2 -1  2  0  1  1  1  1  0  1  0  2  8]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  0  1  1  1  1  0  2  0  0  2  0  2 -1  1  8]\nBest objective value found so far: 117.9711\nTotal points evaluated: 115\nIteration 13 completed in 4.59 seconds.\n\n--- Iteration 14/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 123.3827, schedule = [3 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 2 0 0 8]\n  Candidate 1: Obj = 132.5767, schedule = [2 1 1 0 1 0 2 1 0 0 2 1 1 0 1 1 1 0 0 9]\n  Candidate 2: Obj = 124.9912, schedule = [3 1 1 1 0 0 2 1 0 1 0 2 1 0 1 1 1 0 0 8]\n  Candidate 3: Obj = 119.2593, schedule = [3 1 1 1 0 1 1 0 1 1 1 0 2 0 0 2 1 0 1 7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  1  2  0  0  2  1  1 -1  2  1  1  0  1  8]\nBest objective value found so far: 117.9711\nTotal points evaluated: 120\nIteration 14 completed in 4.59 seconds.\n\n--- Iteration 15/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 132.2421, schedule = [2 1 1 0 0 1 1 2 0 0 1 1 1 1 0 1 2 0 0 9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  2  0  1  0  2  1  1 -1  1  2  0  1  1  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  0  2  0  1  0  1  1  0  1  1  2 -1  2  7]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  0  1  1  0  2  1  1  0  1  1  1  1 -1  2  0  2 -1  2  7]\n  Candidate 4: Obj = 117.2325, schedule = [3 0 1 1 0 2 0 1 1 1 1 0 2 0 0 2 1 0 1 7]\nBest objective value found so far: 117.2325\nTotal points evaluated: 125\nIteration 15 completed in 4.36 seconds.\n\n--- Iteration 16/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  1  0  0  2  1  0  1  1  0  1  2  0  0  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  1  0  2  1  0  2  0  0  1  2  0  0  8]\n  Candidate 2: Obj = 120.2212, schedule = [3 1 1 0 0 2 0 1 0 2 1 0 1 0 1 1 2 0 1 7]\n  Candidate 3: Obj = 122.3628, schedule = [2 2 0 1 0 2 0 1 0 2 1 0 1 1 0 1 2 0 0 8]\n  Candidate 4: Obj = 118.6656, schedule = [2 2 1 0 0 2 0 1 0 2 1 0 1 1 0 1 2 0 1 7]\nBest objective value found so far: 117.2325\nTotal points evaluated: 130\nIteration 16 completed in 4.65 seconds.\n\n--- Iteration 17/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 133.4606, schedule = [1 2 0 2 0 0 1 1 1 0 1 2 0 1 1 1 0 0 1 9]\n  Candidate 1: Obj = 124.3333, schedule = [3 1 0 2 0 0 2 0 1 1 0 2 0 0 2 1 0 1 0 8]\n  Candidate 2: Obj = 124.4456, schedule = [3 1 0 1 0 1 2 0 1 0 1 2 0 1 0 2 0 0 1 8]\n  Candidate 3: Obj = 122.1176, schedule = [2 1 1 2 0 0 1 1 0 2 0 2 0 1 1 1 0 0 2 7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  1  1  0  2  0  2  0  1  0  1  1  0  1  8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 135\nIteration 17 completed in 5.23 seconds.\n\n--- Iteration 18/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  1  2  0  1  1  0  2  0  0  1  2  1  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  0  2  1  0  1  1  0  1  1  0  1  2  1 -1  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 1  2  1  1 -1  1  2  0  1  0  1  2  0  0  1  2  1  0  0  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  1  1  1  1  0  2  0  1  0  1  2  0  0  1  2  1 -1  2  8]\n  Candidate 4: Obj = 132.6467, schedule = [2 0 2 1 0 1 1 0 1 1 0 2 0 0 1 2 0 0 2 8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 140\nIteration 18 completed in 5.33 seconds.\n\n--- Iteration 19/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 132.7635, schedule = [1 2 1 0 1 1 0 1 1 0 1 2 0 1 0 1 1 0 1 9]\n  Candidate 1: Obj = 134.0218, schedule = [1 2 0 2 0 1 0 1 1 0 2 0 1 0 1 2 0 0 1 9]\n  Candidate 2: Obj = 132.6921, schedule = [1 2 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 9]\n  Candidate 3: Obj = 134.3468, schedule = [1 2 1 1 0 1 0 1 1 1 0 2 0 0 1 2 0 0 1 9]\n  Candidate 4: Obj = 131.9700, schedule = [2 1 1 1 0 1 0 1 0 1 1 2 0 1 0 1 1 1 0 9]\nBest objective value found so far: 117.2325\nTotal points evaluated: 145\nIteration 19 completed in 5.02 seconds.\n\n--- Iteration 20/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 124.8142, schedule = [2 1 0 2 0 1 0 2 0 0 1 2 1 0 1 1 1 0 1 8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  1  0  1  1  0  1  2 -1  2  0  1  1  0  9]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  2  0  1  1  0  0  2  0  1  2  0  0  2  1 -1  1  9]\n  Candidate 3: Obj = 133.0355, schedule = [2 1 0 2 0 1 1 1 0 0 1 2 0 0 1 2 0 1 0 9]\n  Candidate 4: Obj = 127.4777, schedule = [2 1 1 1 0 0 2 0 0 1 1 1 1 1 0 2 1 0 1 8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 150\nIteration 20 completed in 5.28 seconds.\n\n--- Iteration 21/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 3  0  2  1 -1  1  2  1  0  0  1  1  1  1  0  1  2 -1  2  7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  2  0  1  0  1  1  1  0  2  0  0  2  7]\n  Candidate 2: Obj = 118.8553, schedule = [2 2 1 0 0 2 0 1 1 0 1 2 0 0 2 1 0 1 1 7]\n  Candidate 3: Obj = 123.2719, schedule = [3 1 0 1 1 0 2 0 1 0 1 1 1 0 1 1 1 0 1 8]\n  Candidate 4: Obj = 122.1658, schedule = [3 1 0 1 1 0 2 1 0 1 1 0 1 1 0 1 1 1 0 8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 155\nIteration 21 completed in 5.98 seconds.\n\n--- Iteration 22/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 121.0466, schedule = [3 0 1 1 1 1 0 1 1 0 2 0 1 1 1 0 1 0 2 7]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  1 -1  1  2  1  0  0  2  1  1 -1  1  1  1  0  2  8]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 3  0  1  2  0  1  0  2 -1  1  1  2  1  0  1  1  1  0  1  7]\n  Candidate 3: Obj = 134.6840, schedule = [1 2 1 0 0 1 1 2 0 1 0 1 2 0 0 2 0 0 1 9]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  2 -1  2  1  1  0  1  0  2  0  1  0  1  1  0  1  8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 160\nIteration 22 completed in 5.36 seconds.\n\n--- Iteration 23/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 2  1  1  1  0  0  1  2 -1  1  2  0  1  1  0  2  1  0  1  8]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  0  2  0  1  1  0  1  0  2  0  2  0  1  1  0  2 -1  2  8]\n  Candidate 2: Obj = 128.1131, schedule = [2 1 0 1 0 1 2 1 0 0 2 0 2 0 0 2 0 1 1 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  0  1  0  1  2 -1  1  1  1  2 -1  1  1  1  1  1  7]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 3  0  1  1  1  1  1  1 -1  1  2  1  0  1  0  2  1  0  1  7]\nBest objective value found so far: 117.2325\nTotal points evaluated: 165\nIteration 23 completed in 5.23 seconds.\n\n--- Iteration 24/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  2  0  0  1  2  0  1  0  2  1  1  0  0  9]\n  Candidate 1: Obj = 10000000000.0000, schedule = [ 2  1  1  2 -1  1  2  1 -1  2  1  0  1  0  1  1  2  0  1  7]\n  Candidate 2: Obj = 10000000000.0000, schedule = [ 2  1  0  1  0  1  2  1  0  1  1  0  2  0  1  0  2 -1  1  9]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 1  2  0  2  0  0  2  1 -1  2  1  1  1  0  0  1  2 -1  1  9]\n  Candidate 4: Obj = 10000000000.0000, schedule = [ 1  1  1  2 -1  1  1  1  0  2  1  0  1  0  2  0  2  0  1  8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 170\nIteration 24 completed in 5.52 seconds.\n\n--- Iteration 25/25 ---\nFitting GP model...\nGP model fitted.\nOptimizing acquisition function (LCB)...\nSelected 5 candidate(s).\n  Candidate 0: Obj = 10000000000.0000, schedule = [ 1  2  1  1  0  1  0  2  0  0  2  0  1  0  2  1  1 -1  2  8]\n  Candidate 1: Obj = 124.5451, schedule = [3 0 2 0 0 1 2 0 1 0 2 0 2 0 1 0 1 0 1 8]\n  Candidate 2: Obj = 124.2147, schedule = [3 0 1 1 1 0 2 0 0 2 0 2 1 0 0 2 1 0 0 8]\n  Candidate 3: Obj = 10000000000.0000, schedule = [ 3  1  1  1 -1  2  0  1  0  2  0  2  0  0  1  1  1  1  1  7]\n  Candidate 4: Obj = 123.0855, schedule = [2 2 0 1 1 1 1 0 0 1 2 0 1 0 1 1 2 0 0 8]\nBest objective value found so far: 117.2325\nTotal points evaluated: 175\nIteration 25 completed in 6.93 seconds.\n\n--- Optimization Finished ---\nTotal evaluations: 175\nBest Objective Value Found: 117.23250201869716\nBest U vector Found: [0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1]\n\n--- Verification ---\nIs the best U feasible? True\nResulting Y vector for best U: [3 0 1 1 0 2 0 1 1 1 1 0 2 0 0 2 1 0 1 7]\nObjective value (recalculated): 117.2325",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#results",
    "href": "combinatorial-bayes-optimization.html#results",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.5 Results",
    "text": "6.5 Results\nThe initial schedule, derived using the Bailey-Welch method (bailey1952study), serves as a baseline. The objective function \\(C(\\mathbf{x})\\) combines Expected Waiting Time (\\(EWT\\)) and Expected Staff Penalty (\\(ESP\\)). Lower values of \\(C(\\mathbf{x})\\) are preferable. Each experiment consisted of \\(N_{INITIAL} = 20\\) initial random evaluations followed by \\(N_{ITERATIONS} =20\\) Bayesian optimization iterations, with \\(BATCH\\_SIZE_q = 5\\) evaluations per iteration, totaling approximately \\(20 + 20 \\times 5 = 120\\) evaluations per experiment. The optimization operates on the binary perturbation vector \\(\\mathbf{U}\\), using the HED embedding (Deshwal et al. 2023).\nThe key performance metric is the best (minimum) objective function value found.\n\n6.5.1 Experiment 1: CBO with Expected Improvement (EI)\n\nInitial Best Objective (after random search): 118.87100166955729\nFinal Best Objective Found: 114.96364292044709\nTotal Evaluations: 175\nBest Perturbation Vector \\(\\mathbf{U}_{EI}^*\\): array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\nResulting Optimal Schedule \\(\\mathbf{x}_{EI}^*\\): array([2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 1, 7])\n\n\n\n6.5.2 Experiment 2: CBO with Lower Confidence Bound (LCB) - \\(\\kappa =\\) 2.576\n\nInitial Best Objective (after random search): 118.87100166955729\nFinal Best Objective Found: 117.23250201869716\nTotal Evaluations: 175\nBest Perturbation Vector \\(\\mathbf{U}_{LCB\\_fixed}^*\\): array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])\nResulting Optimal Schedule \\(\\mathbf{x}_{LCB\\_fixed}^*\\): array([3, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 7])\n\n\n\n6.5.3 Summary of Best Objectives\n\n\n\n\n\n\n\nExperiment\nBest Objective \\(C(\\mathbf{x}^*)\\)\n\n\n\n\nCBO with EI\n114.96364292044709\n\n\nCBO with LCB (Fixed \\(\\kappa=\\) 2.576)\n117.23250201869716",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#discussion",
    "href": "combinatorial-bayes-optimization.html#discussion",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.6 Discussion",
    "text": "6.6 Discussion\nThe experiments aimed to compare two CBO strategies, leveraging the HED embedding technique (Deshwal et al. 2023), for optimizing the outpatient appointment scheduling problem formulated by Kaandorp and Koole (2007). Both methods successfully improved upon their respective initial random search results, demonstrating the applicability of BO with HED to this combinatorial problem.\n\nPerformance Comparison:\nHypothesis Evaluation:\n\nHypothesis 1\nHypothesis 2\n\nExploration vs. Exploitation:\nComputational Effort:\nLimitations and Future Work:\n\nThe optimality guarantee mentioned by Kaandorp and Koole (2007) applies to their specific local search algorithm operating directly on the schedule space \\(\\mathcal{F}\\), leveraging multimodularity. Our BO approach operates on the perturbation vector space \\(\\mathbf{U}\\) via HED embeddings. While BO aims for global optimization, it doesn’t inherit the same theoretical guarantee of finding the global optimum as the original local search, especially given the stochastic nature of GP modeling and acquisition function optimization.\nThe performance is likely sensitive to BO hyperparameters (dictionary size \\(m\\), \\(\\kappa\\) values, number of candidates for acquisition optimization).\nFurther investigation into different dictionary construction methods (e.g., binary wavelets as mentioned in Deshwal et al., 2023) or adaptive \\(\\kappa\\) schedules could be beneficial.\n\n\nIn conclusion, applying CBO with HED embeddings appears promising for this scheduling problem. The LCB acquisition function with a fixed, well-chosen \\(\\kappa\\) demonstrated the best performance in this study.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#timeline",
    "href": "combinatorial-bayes-optimization.html#timeline",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.7 Timeline",
    "text": "6.7 Timeline\n\nExperiment Setup and Code Implementation: 30-04-2025\nResults Analysis and Report Compilation: 07-05-2025",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "combinatorial-bayes-optimization.html#references",
    "href": "combinatorial-bayes-optimization.html#references",
    "title": "6  Combinatorial Bayesian Optimization Experiments",
    "section": "6.8 References",
    "text": "6.8 References\n\n\nAglietti, Virginia, Ira Ktena, Jessica Schrouff, Eleni Sgouritsa,\nFrancisco J. R. Ruiz, Alan Malek, Alexis Bellot, and Silvia Chiappa.\n2024. “FunBO: Discovering\nAcquisition Functions for\nBayesian Optimization with\nFunSearch.” arXiv. https://doi.org/10.48550/arXiv.2406.04824.\n\n\nAltman, Eitan, Bruno Gaujal, and Arie Hordijk. 2000.\n“Multimodularity, Convexity, and\nOptimization Properties.”\nMathematics of Operations Research 25 (2): 324–47. https://www.jstor.org/stable/3690584.\n\n\nBailey, Norman TJ. 1952. “A Study of Queues and Appointment\nSystems in Hospital Out-Patient Departments, with Special Reference to\nWaiting-Times.” Journal of the Royal Statistical Society\nSeries B: Statistical Methodology 14 (2): 185–99.\n\n\nBalandat, Maximilian, Brian Karrer, Daniel R. Jiang, Samuel Daulton,\nBenjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. 2020.\n“BoTorch: A Framework for Efficient\nMonte-Carlo Bayesian Optimization.” In Advances in\nNeural Information Processing Systems 33. http://arxiv.org/abs/1910.06403.\n\n\nDeshwal, Aryan, Sebastian Ament, Maximilian Balandat, Eytan Bakshy,\nJanardhan Rao Doppa, and David Eriksson. 2023. “Bayesian\nOptimization over\nHigh-Dimensional Combinatorial\nSpaces via Dictionary-Based\nEmbeddings.” In Proceedings of The\n26th International Conference on\nArtificial Intelligence and\nStatistics, 7021–39. PMLR. https://proceedings.mlr.press/v206/deshwal23a.html.\n\n\nGonzalez, Javier, Zhenwen Dai, Andreas Damianou, and Neil D. Lawrence.\n2017. “Preferential Bayesian\nOptimization.” arXiv. https://doi.org/10.48550/arXiv.1704.03651.\n\n\nKaandorp, Guido C., and Ger Koole. 2007. “Optimal Outpatient\nAppointment Scheduling.” Health Care Management Science\n10 (3): 217–29. https://doi.org/10.1007/s10729-007-9015-x.\n\n\nSwersky, Kevin, Yulia Rubanova, David Dohan, and Kevin Murphy. 2020.\n“Amortized Bayesian Optimization over\nDiscrete Spaces.” In Proceedings of\nthe 36th Conference on Uncertainty in\nArtificial Intelligence\n(UAI), 769–78. PMLR. https://proceedings.mlr.press/v124/swersky20a.html.\n\n\nZhang, Xinyu, Daolang Huang, Samuel Kaski, and Julien Martinelli. 2025.\n“PABBO: Preferential\nAmortized Black-Box\nOptimization.” arXiv. https://doi.org/10.48550/arXiv.2503.00924.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combinatorial Bayesian Optimization Experiments</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html",
    "href": "preferential-bayesian-optimization.html",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "",
    "text": "7.1 Objective\nThis experiment aims to apply Preferential Bayesian Optimization (PBO) to find optimal or near-optimal solutions for the outpatient appointment scheduling problem as defined by Kaandorp and Koole (2007). Specifically, the objective is to minimize a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP) by efficiently searching the space of schedule perturbations. The experiment leverages dictionary-based embeddings (HED) as proposed by Deshwal et al. (2023) to handle the high-dimensional combinatorial space of perturbation selection vectors within the PBO framework, drawing on the original preferential-BO formulation of Gonzalez et al. (2017).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#background",
    "href": "preferential-bayesian-optimization.html#background",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.2 Background",
    "text": "7.2 Background\nWe consider an outpatient appointment scheduling problem as described by Kaandorp and Koole (2007) where the schedule is represented by a vector \\(\\mathbf{x} = (x_0, x_1, \\ldots, x_{T-1})^T\\). This vector comprises \\(T\\) components, where \\(x_j\\) denotes the non-negative allocation (number of patients) to time slot \\(j\\), for \\(j = 0, \\ldots, T-1\\). A fundamental constraint is that the total allocation across all time slots must equal a fixed constant \\(N\\):\n\\[\\sum_{j=0}^{T-1} x_j = N\\] where \\(N\\) is the total number of patients to be scheduled. This constraint ensures that the schedule is feasible and respects the total patient load.\nWe require \\(x_j \\ge 0\\) for all \\(j = 0, \\ldots, T-1\\). Consequently, a valid schedule \\(\\mathbf{x}\\) belongs to the feasible set \\(\\mathcal{F} = { \\mathbf{z} \\in \\mathbb{D}^{T} \\mid \\sum_{j=0}^{T-1} z_j = N, z_j \\ge 0 \\text{ for all } j}\\), where \\(\\mathbb{D}\\) is the set of non-negative integers (\\(\\mathbb{Z}\\_{\\ge 0}\\))\nKaandorp and Koole (2007) define a neighborhood structure for local search based on perturbation vectors derived from a set of \\(T\\) basis change vectors, \\(v_i \\in \\mathbb{D}^{T}\\), for \\(i = 0, \\ldots, T-1\\). These basis vectors represent elementary shifts of allocation between time slots:\n\n\\(v_0 = (-1, 0, \\ldots, 0, 1)\\) (Shift unit from slot 0 to slot \\(T-1\\))\n\\(v_1 = (1, -1, 0, \\ldots, 0)\\) (Shift unit from slot 1 to slot 0)\n\\(v_i = (0, \\ldots, 0, \\underbrace{1}*{\\text{pos } i-1}, \\underbrace{-1}*{\\text{pos } i}, 0, \\ldots, 0)\\) for \\(i = 2, \\ldots, T-1\\) (Shift unit from slot \\(i\\) to slot \\(i-1\\))\n\nA key property of these basis vectors is that the sum of components for each vector is zero: \\(\\sum_{j=0}^{T-1} v_{ij} = 0\\) for all \\(i=0, \\ldots, T-1\\).\nPerturbations are constructed using a binary selection vector \\(\\mathbf{U} = (u_0, u_1, \\ldots, u_{T-1})\\), where \\(u_i \\in {0, 1}\\). Each \\(u_i\\) indicates whether the basis change \\(v_i\\) is included in the perturbation. The resulting perturbation vector \\(\\mathbf{r}(\\mathbf{U}) \\in \\mathbb{D}^{T}\\) is the linear combination:\n\\[\n\\mathbf{r}(\\mathbf{U}) := \\sum_{i=0}^{T-1} u_i v_i\n\\]\nSince each \\(v\\_i\\) sums to zero, any perturbation \\(\\mathbf{r}(\\mathbf{U})\\) also sums to zero: \\(\\sum\\_{j=0}^{T-1} r\\_j(\\mathbf{U}) = 0\\). This ensures that applying such a perturbation to a valid schedule \\(\\mathbf{x}\\) preserves the total allocation \\(N\\).\nThe neighborhood of a schedule \\(\\mathbf{x} \\in \\mathcal{F}\\), denoted by \\(\\mathcal{N}(\\mathbf{x})\\), comprises all distinct, feasible schedules \\(\\mathbf{x}'\\) reachable by applying a non-zero perturbation \\(\\mathbf{r}(\\mathbf{U})\\) (Kaandorp and Koole (2007), use a slightly different but related neighborhood definition based on combinations of these basis vectors [cite: 89, 93, 1645]).\nThe objective function to be minimized is a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP), as defined by Kaandorp and Koole (2007):\n\\[\nC(\\mathbf{x}) = w \\cdot EWT(\\mathbf{x}) + (1-w) \\cdot ESP(\\mathbf{x})\n\\]\nKaandorp and Koole (2007) prove that this objective function is multimodular, which guarantees that a local search algorithm using their defined neighborhood converges to the global optimum.\nHowever, evaluating this function can be computationally expensive for large \\(N\\) and \\(T\\), and the search space of binary vectors \\(\\mathbf{U}\\) is high-dimensional (\\(2^T - 2\\) possibilities).\nDictionary‐Based Hamming Embeddings. Deshwal et al. (2023) identify that directly modeling high-dimensional binary vectors with a Gaussian process is both statistically and computationally challenging, since the search space grows as \\(2^d\\). They propose Hamming Embedding via Dictionaries (HED): choose a small set of \\(m\\) “dictionary” vectors \\(\\{a_i\\}\\subset\\{0,1\\}^d\\) and embed any candidate \\(z\\) by its Hamming distances \\(\\phi_i(z)=\\mathrm{Hamming}(a_i,z)\\). By using carefully constructed binary-wavelet (Hadamard) dictionaries, they both dramatically reduce input dimensionality \\((m\\ll d)\\) and obtain provable regret bounds \\(\\widetilde O(\\sqrt{Tm})\\). Empirically on combinatorial tasks (e.g. MAX-SAT, feature selection, compiler flags), BO with HED (“BODi”) converges faster and to better optima than state-of-the-art discrete methods.\nPreferential Bayesian Optimization.\nGonzález et al. introduced the first PBO framework for optimizing a latent black-box function using only pairwise “duels.” They place a Gaussian-process prior over a latent utility function \\(f\\), then squash it through a probit (or logistic) likelihood to model the probability \\(\\pi_f([x, x'])\\) that \\(x\\) is preferred to \\(x'\\). From this they define acquisition functions—such as a Copeland-expected-improvement extension and a “dueling” Thompson–sampling rule—that balance exploration and exploitation by selecting the next pair \\([x_t, x'_t]\\) to query Gonzalez et al. (2017).\nBecause the preferential likelihood is non-conjugate, each iteration requires expensive approximate inference (refitting the GP classification model) and an inner optimization over pairs to maximize the acquisition. Although sample-efficient (drastically reducing the number of duels needed to find the Condorcet winner), this per-step computational overhead motivates integrating faster surrogate updates or approximate acquisition schemes—exactly the gap our HED-based embedding approach helps address by reducing problem dimensionality before applying PBO.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#hypothesis",
    "href": "preferential-bayesian-optimization.html#hypothesis",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.3 Hypothesis",
    "text": "7.3 Hypothesis\nBy applying PBO with HED embeddings and Thompson sampling, we expect to efficiently identify perturbation vectors \\(\\mathbf{U}\\) that yield significantly improved schedules (lower cost) compared to random or simple local search heuristics.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#methodology",
    "href": "preferential-bayesian-optimization.html#methodology",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.4 Methodology",
    "text": "7.4 Methodology\nWe are using Botorch for the PBO implementation (Balandat et al. 2020).\n\nimport torch\nimport numpy as np\nimport gpytorch\nfrom botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\nfrom botorch.fit import fit_gpytorch_mll\nfrom botorch.models.transforms.input import Normalize\nfrom scipy.linalg import hadamard\nfrom scipy.optimize import minimize\nimport random\nfrom typing import List, Tuple, Dict, Optional, Union\nimport plotly.graph_objects as go\n\nfrom functions import (\n    bailey_welch_schedule,\n    get_v_star,\n    compute_convolutions,\n    calculate_objective_serv_time_lookup,\n)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#helper-functions",
    "href": "preferential-bayesian-optimization.html#helper-functions",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.5 Helper Functions",
    "text": "7.5 Helper Functions\n\n# --- Helper: generate_weighted_list ---\ndef generate_weighted_list(max_s: int, l: float, i: int) -&gt; Optional[np.ndarray]:\n    if not isinstance(max_s, int) or max_s &lt;= 0: return None\n    if not isinstance(l, (int, float)) or not (1 &lt;= l &lt;= max_s): return None\n    if not isinstance(i, int) or not (0 &lt;= i &lt; max_s): return None\n    def objective_fn(x: np.ndarray) -&gt; float:\n        return (np.dot(np.arange(1, max_s + 1), x) - l) ** 2\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})\n    bounds = [(0, 1)] * max_s\n    initial_guess = np.random.dirichlet(np.ones(max_s))\n    try:\n        result = minimize(objective_fn, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints, options={'maxiter': 300, 'ftol': 1e-9})\n        if not result.success: return None\n        optimized_probs = result.x\n        optimized_probs[optimized_probs &lt; 0] = 0\n        current_sum = np.sum(optimized_probs)\n        if not np.isclose(current_sum, 1.0):\n            if current_sum &gt; 1e-8: optimized_probs /= current_sum\n            else: return None\n    except Exception: return None\n    first_part_probs = optimized_probs[:i] if i &gt; 0 else np.array([])\n    second_part_probs = optimized_probs[i:]\n    values = np.zeros(max_s + 1)\n    if i &gt; 0: values[1 : i + 1] = np.sort(first_part_probs)\n    values[i + 1 : max_s + 1] = np.sort(second_part_probs)[::-1]\n    final_sum = np.sum(values[1:])\n    if not np.isclose(final_sum, 1.0):\n        if final_sum &gt; 1e-8: values[1:] /= final_sum\n        else: return None\n    return values",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#problem-setup",
    "href": "preferential-bayesian-optimization.html#problem-setup",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.6 Problem Setup",
    "text": "7.6 Problem Setup\n\nN_patients = 50\nT_param = 48\nd_interval_len = 10\nmax_s_time = 30\nq_no_show = 0.20\nw_weight = 0.1\nl_target_avg_service_time = 14.0\ni_sorting_split = 10\n\nv_star_matrix = get_v_star(T_param)\ns_dist = generate_weighted_list(max_s_time, l_target_avg_service_time, i_sorting_split)\nif s_dist is None: raise ValueError(\"Failed to generate service time distribution.\")\nprint(f\"Service time distribution (s): {s_dist.tolist()}\")\n# Assuming s_dist is already defined\nfig = go.Figure(data=go.Bar(\n    x=np.arange(1, len(s_dist) + 1),\n    y=s_dist,\n    marker_line_width=1\n))\nfig.update_layout(\n    title=\"Service Time Distribution\",\n    xaxis_title=\"Service Time (units)\",\n    yaxis_title=\"Probability\",\n    template=\"plotly_white\"\n)\nfig.show()\nprint(f\"Average generated service time: {np.dot(np.arange(len(s_dist)), s_dist):.4f}\")\nconvolutions_dict = compute_convolutions(s_dist.tolist(), N_patients, q_no_show)\nX_initial_schedule = np.array(bailey_welch_schedule(T_param, d_interval_len, N_patients, s_dist))\nprint(f\"Initial base schedule (X_vec): {X_initial_schedule.tolist()}\")\nprint(f\"Sum of patients in X_vec: {np.sum(X_initial_schedule)}\")\nLARGE_PENALTY_VAL = 1e10\n\nService time distribution (s): [0.0, 0.0010182870243508066, 0.004383818596928343, 0.0072059574089277465, 0.019019241762008206, 0.02349126759082732, 0.02411042572052284, 0.036652289273485704, 0.05318511479116829, 0.06150071962665944, 0.08187670519847493, 0.1788545013306628, 0.07393315723224196, 0.0715779633838313, 0.0671838052994548, 0.05037559566484032, 0.04515039510431882, 0.03549795298413222, 0.03025627131841115, 0.02540926306634486, 0.02140321880236048, 0.02126470732882247, 0.019372014336892757, 0.011485516916314666, 0.010503815298936134, 0.010175822380668713, 0.007889358087376343, 0.002183484247262923, 0.0020919317092953096, 0.0015849218428687784, 0.0013624766861605455]\nAverage generated service time: 12.7394\nInitial base schedule (X_vec): [2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 12]\nSum of patients in X_vec: 50",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#objective-function",
    "href": "preferential-bayesian-optimization.html#objective-function",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.7 Objective Function",
    "text": "7.7 Objective Function\n\ndef evaluate_objective(U_np: Union[np.ndarray, List[int]], X_vec: np.ndarray, v_star: np.ndarray,\n                       conv_dict: Dict[int, np.ndarray], d_len: int, w_val: float) -&gt; float:\n    if not isinstance(U_np, np.ndarray): U_np = np.array(U_np, dtype=int)\n    if U_np.ndim != 1: raise ValueError(\"Input U must be 1-dimensional\")\n    if U_np.shape[0] != v_star.shape[0]: raise ValueError(f\"U length {U_np.shape[0]} != V* rows {v_star.shape[0]}.\")\n    if X_vec.shape[0] != v_star.shape[1]: raise ValueError(f\"X length {X_vec.shape[0]} != V* columns {v_star.shape[1]}.\")\n    if not np.all((U_np == 0) | (U_np == 1)): raise ValueError(\"Input U must be binary.\")\n    V_sum = np.sum(v_star[U_np == 1, :], axis=0)\n    Y_schedule = X_vec + V_sum\n    if np.all(Y_schedule &gt;= 0) and np.sum(Y_schedule) == np.sum(X_vec):\n        ewt, esp = calculate_objective_serv_time_lookup(Y_schedule.tolist(), d_len, conv_dict)\n        return w_val * ewt + (1 - w_val) * esp\n    return LARGE_PENALTY_VAL\n\nU_zeros = np.zeros(T_param, dtype=int)\ninitial_obj_val = evaluate_objective(U_zeros, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\nprint(f\"Initial objective value (U=zeros): {initial_obj_val:.4f}\")\n\nInitial objective value (U=zeros): 205.2664",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#pbo-setup",
    "href": "preferential-bayesian-optimization.html#pbo-setup",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.8 PBO Setup",
    "text": "7.8 PBO Setup\n\n# --- HED: Binary Wavelet Dictionary Construction ---\ndef get_binary_wavelet_dictionary(T_dim_U: int, m_dict_size: int) -&gt; np.ndarray:\n    d_hadamard = 1\n    while d_hadamard &lt; T_dim_U: d_hadamard *= 2\n    H = hadamard(d_hadamard)\n    if m_dict_size &gt; d_hadamard: m_dict_size = d_hadamard\n    dictionary = np.zeros((m_dict_size, T_dim_U), dtype=int)\n    for i in range(m_dict_size):\n        dictionary[i, :] = (H[i, :T_dim_U] + 1) // 2\n    return dictionary\n\ndef embed_HED(U_np: np.ndarray, dictionary: np.ndarray) -&gt; np.ndarray:\n    U_np_reshaped = U_np.reshape(1, -1) if U_np.ndim == 1 else U_np\n    hamming_distances = np.sum(dictionary != U_np_reshaped[:, np.newaxis, :], axis=2).T\n    return hamming_distances.flatten().astype(float) if U_np.ndim == 1 else hamming_distances.astype(float)\n\nm_dictionary_size = min(T_param * 2, 32 if T_param &lt;=20 else 64)\nhed_dictionary = get_binary_wavelet_dictionary(T_param, m_dictionary_size)\nprint(f\"HED dictionary shape: {hed_dictionary.shape}\")\n\nnum_total_initial_pairs = 10\nnum_initial_U_zeros_comparisons = 3 # Number of times to compare U_zeros with random U\nnum_purely_random_initial_pairs = num_total_initial_pairs - num_initial_U_zeros_comparisons\n\nnum_pbo_iterations = 50\nn_candidates_for_thompson = 200\nn_thompson_posterior_samples = 20\n\nall_U_vectors_list = []\nall_U_embeddings_tensor = None\ncomparison_pairs_indices = []\n\ndef add_U_to_master_list(U_np: np.ndarray, embedding: np.ndarray) -&gt; int:\n    global all_U_vectors_list, all_U_embeddings_tensor\n    U_np = U_np.astype(int) # Ensure consistent type\n    for i, existing_U_np_item in enumerate(all_U_vectors_list):\n        if np.array_equal(existing_U_np_item, U_np): return i\n    new_index = len(all_U_vectors_list)\n    all_U_vectors_list.append(U_np.copy())\n    if embedding.ndim &gt; 1: embedding = embedding.flatten()\n    embedding_tensor = torch.from_numpy(embedding).double().unsqueeze(0)\n    if all_U_embeddings_tensor is None: all_U_embeddings_tensor = embedding_tensor\n    else: all_U_embeddings_tensor = torch.cat([all_U_embeddings_tensor, embedding_tensor], dim=0)\n    return new_index\n\ndef generate_random_U_vector(dim: int) -&gt; np.ndarray:\n    return np.random.randint(0, 2, size=dim, dtype=int)\n\ndef get_hamming_neighbors(U_vector: np.ndarray, num_neighbors: int, max_flips: int = 1) -&gt; List[np.ndarray]:\n    neighbors = []\n    dim = len(U_vector)\n    if dim == 0: return []\n    for _ in range(num_neighbors):\n        neighbor = U_vector.copy()\n        actual_flips = np.random.randint(1, max_flips + 1)\n        flip_indices = np.random.choice(dim, size=min(actual_flips, dim), replace=False)\n        for idx in flip_indices: neighbor[idx] = 1 - neighbor[idx]\n        neighbors.append(neighbor)\n    return neighbors\n\nHED dictionary shape: (64, 48)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#pbo-initialization",
    "href": "preferential-bayesian-optimization.html#pbo-initialization",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.9 PBO Initialization",
    "text": "7.9 PBO Initialization\n\nprint(\"Starting PBO Initialization...\")\nbest_U_overall = U_zeros.copy() # Start with U_zeros as initial best\nbest_obj_overall = initial_obj_val\nbest_iter_found = 0 # 0 for initial U_zeros evaluation\n\n# Add U_zeros to the master list first\nidx_U_zeros = add_U_to_master_list(U_zeros, embed_HED(U_zeros, hed_dictionary))\nobj_U_zeros = initial_obj_val # Already calculated\n\n# --- Initial comparisons involving U_zeros ---\nprint(f\"Generating {num_initial_U_zeros_comparisons} initial comparisons involving U_zeros...\")\nfor i in range(num_initial_U_zeros_comparisons):\n    U_competitor = generate_random_U_vector(T_param)\n    attempts = 0\n    while np.array_equal(U_competitor, U_zeros) and attempts &lt; 100: # Avoid comparing U_zeros to itself\n        U_competitor = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_competitor, U_zeros): continue\n\n    obj_competitor = evaluate_objective(U_competitor, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"  Init U_zeros vs U_rand_{i}: Obj_U_zeros={obj_U_zeros:.4f}, Obj_U_rand={obj_competitor:.4f}\")\n\n    if obj_competitor &lt; best_obj_overall:\n        best_obj_overall = obj_competitor\n        best_U_overall = U_competitor.copy()\n        best_iter_found = 0 # Still initialization phase\n\n    idx_competitor = add_U_to_master_list(U_competitor, embed_HED(U_competitor, hed_dictionary))\n    \n    if not np.isclose(obj_U_zeros, obj_competitor):\n        pref_pair = None\n        if obj_U_zeros &lt; obj_competitor: pref_pair = [idx_U_zeros, idx_competitor]\n        elif obj_competitor &lt; obj_U_zeros: pref_pair = [idx_competitor, idx_U_zeros]\n        \n        if pref_pair and pref_pair not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair)\n\n# --- Purely random initial comparisons (excluding U_zeros unless randomly picked again) ---\nprint(f\"Generating {num_purely_random_initial_pairs} purely random initial comparisons...\")\nfor i in range(num_purely_random_initial_pairs):\n    U_A = generate_random_U_vector(T_param)\n    U_B = generate_random_U_vector(T_param)\n    attempts = 0\n    while np.array_equal(U_A, U_B) and attempts &lt; 100:\n        U_B = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_A, U_B): continue\n\n    obj_A = evaluate_objective(U_A, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    obj_B = evaluate_objective(U_B, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"  Init U_randA_{i} vs U_randB_{i}: Obj_A={obj_A:.4f}, Obj_B={obj_B:.4f}\")\n\n\n    if obj_A &lt; best_obj_overall: best_obj_overall = obj_A; best_U_overall = U_A.copy(); best_iter_found = 0\n    if obj_B &lt; best_obj_overall: best_obj_overall = obj_B; best_U_overall = U_B.copy(); best_iter_found = 0\n\n    idx_A = add_U_to_master_list(U_A, embed_HED(U_A, hed_dictionary))\n    idx_B = add_U_to_master_list(U_B, embed_HED(U_B, hed_dictionary))\n    \n    if not np.isclose(obj_A, obj_B):\n        pref_pair = None\n        if obj_A &lt; obj_B: pref_pair = [idx_A, idx_B]\n        elif obj_B &lt; obj_A: pref_pair = [idx_B, idx_A]\n\n        if pref_pair and pref_pair not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair)\n\nprint(f\"Initialization complete. Observed {len(all_U_vectors_list)} unique schedules.\")\nprint(f\"Number of preference pairs: {len(comparison_pairs_indices)}\")\nif best_U_overall is not None:\n    print(f\"Best U after initialization: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f}\")\n\nStarting PBO Initialization...\nGenerating 3 initial comparisons involving U_zeros...\n  Init U_zeros vs U_rand_0: Obj_U_zeros=205.2664, Obj_U_rand=10000000000.0000\n  Init U_zeros vs U_rand_1: Obj_U_zeros=205.2664, Obj_U_rand=10000000000.0000\n  Init U_zeros vs U_rand_2: Obj_U_zeros=205.2664, Obj_U_rand=10000000000.0000\nGenerating 7 purely random initial comparisons...\n  Init U_randA_0 vs U_randB_0: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_1 vs U_randB_1: Obj_A=10000000000.0000, Obj_B=207.1167\n  Init U_randA_2 vs U_randB_2: Obj_A=10000000000.0000, Obj_B=225.0753\n  Init U_randA_3 vs U_randB_3: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_4 vs U_randB_4: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_5 vs U_randB_5: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_6 vs U_randB_6: Obj_A=215.4007, Obj_B=10000000000.0000\nInitialization complete. Observed 18 unique schedules.\nNumber of preference pairs: 6\nBest U after initialization: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.2664",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#pbo-loop",
    "href": "preferential-bayesian-optimization.html#pbo-loop",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.10 PBO Loop",
    "text": "7.10 PBO Loop\n\nimport time\n\n# Start timer for PBO loop\nstart_time = time.time()\n\npairwise_model = None\n\nfor pbo_iter in range(num_pbo_iterations):\n    print(f\"\\n--- PBO Iteration {pbo_iter + 1}/{num_pbo_iterations} ---\")\n    if len(comparison_pairs_indices) &lt; 1 or all_U_embeddings_tensor is None or all_U_embeddings_tensor.shape[0] &lt; 2:\n        print(\"Not enough data for GP. Generating a random pair to add to comparisons.\")\n        # (Simplified fallback: add one random comparison)\n        U_A_fallback = generate_random_U_vector(T_param)\n        U_B_fallback = generate_random_U_vector(T_param)\n        attempts = 0\n        while np.array_equal(U_A_fallback, U_B_fallback) and attempts &lt; 100:\n            U_B_fallback = generate_random_U_vector(T_param)\n            attempts += 1\n        if np.array_equal(U_A_fallback, U_B_fallback):\n            continue\n\n        obj_A_fb = evaluate_objective(U_A_fallback, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n        obj_B_fb = evaluate_objective(U_B_fallback, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n        if obj_A_fb &lt; best_obj_overall:\n            best_obj_overall = obj_A_fb\n            best_U_overall = U_A_fallback.copy()\n            best_iter_found = pbo_iter + 1\n        if obj_B_fb &lt; best_obj_overall:\n            best_obj_overall = obj_B_fb\n            best_U_overall = U_B_fallback.copy()\n            best_iter_found = pbo_iter + 1\n\n        idx_A_fb = add_U_to_master_list(U_A_fallback, embed_HED(U_A_fallback, hed_dictionary))\n        idx_B_fb = add_U_to_master_list(U_B_fallback, embed_HED(U_B_fallback, hed_dictionary))\n        if not np.isclose(obj_A_fb, obj_B_fb):\n            pref_pair_fb = [idx_A_fb, idx_B_fb] if obj_A_fb &lt; obj_B_fb else [idx_B_fb, idx_A_fb]\n            if pref_pair_fb not in comparison_pairs_indices:\n                comparison_pairs_indices.append(pref_pair_fb)\n        if len(comparison_pairs_indices) &lt; 1 or all_U_embeddings_tensor.shape[0] &lt; 2:\n            continue\n\n    train_X_gp = all_U_embeddings_tensor.double()\n    train_Y_gp = torch.tensor(comparison_pairs_indices, dtype=torch.long)\n    min_bounds = torch.zeros(train_X_gp.shape[-1], dtype=torch.double)\n    max_bounds = torch.full((train_X_gp.shape[-1],), float(T_param), dtype=torch.double)\n    input_transform = Normalize(d=train_X_gp.shape[-1], bounds=torch.stack([min_bounds, max_bounds]))\n\n    pairwise_model = PairwiseGP(\n        train_X_gp,\n        train_Y_gp,\n        input_transform=input_transform,\n        covar_module=gpytorch.kernels.ScaleKernel(\n            gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=train_X_gp.shape[-1])\n        )\n    )\n    mll = PairwiseLaplaceMarginalLogLikelihood(pairwise_model.likelihood, pairwise_model)\n\n    U_query1, U_query2 = None, None\n    try:\n        fit_gpytorch_mll(mll)\n        U_cand_pool_list = []\n        for _ in range(n_candidates_for_thompson // 2):\n            U_cand_pool_list.append(generate_random_U_vector(T_param))\n        if best_U_overall is not None:\n            U_cand_pool_list.extend(\n                get_hamming_neighbors(best_U_overall, n_candidates_for_thompson // 2, max_flips=2)\n            )\n        else:\n            for _ in range(n_candidates_for_thompson // 2):\n                U_cand_pool_list.append(generate_random_U_vector(T_param))\n\n        unique_U_cand_tuples = {tuple(u.tolist()) for u in U_cand_pool_list}\n        U_cand_pool_np = np.array([list(t) for t in unique_U_cand_tuples], dtype=int)\n        if len(U_cand_pool_np) == 0:\n            raise ValueError(\"Candidate pool is empty.\")\n\n        embedded_candidates_np = np.array([embed_HED(u, hed_dictionary) for u in U_cand_pool_np])\n        embedded_candidates_torch = torch.from_numpy(embedded_candidates_np).double()\n\n        pairwise_model.eval()\n        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n            posterior_f = pairwise_model.posterior(input_transform(embedded_candidates_torch))\n            f_samples = posterior_f.sample(torch.Size([n_thompson_posterior_samples]))\n\n        best_indices_per_sample = torch.argmax(f_samples, dim=1)\n        query_idx1_in_cand_pool = best_indices_per_sample[0].item()\n        U_query1 = U_cand_pool_np[query_idx1_in_cand_pool]\n        query_idx2_in_cand_pool = -1\n\n        if len(U_cand_pool_np) &gt; 1:\n            if len(best_indices_per_sample) &gt; 1:\n                for i in range(1, len(best_indices_per_sample)):\n                    if best_indices_per_sample[i].item() != query_idx1_in_cand_pool:\n                        query_idx2_in_cand_pool = best_indices_per_sample[i].item()\n                        break\n            if (\n                query_idx2_in_cand_pool == -1\n                or query_idx1_in_cand_pool == query_idx2_in_cand_pool\n            ):\n                rand_indices = np.arange(len(U_cand_pool_np))\n                np.random.shuffle(rand_indices)\n                for rand_idx in rand_indices:\n                    if rand_idx != query_idx1_in_cand_pool:\n                        query_idx2_in_cand_pool = rand_idx\n                        break\n                U_query2 = (\n                    U_cand_pool_np[query_idx2_in_cand_pool]\n                    if query_idx2_in_cand_pool != -1\n                    else generate_random_U_vector(T_param)\n                )\n            else:\n                U_query2 = U_cand_pool_np[query_idx2_in_cand_pool]\n        else:\n            U_query2 = generate_random_U_vector(T_param)\n    except Exception as e:\n        print(f\"Error in GP/TS: {e}. Falling back to random.\")\n        U_query1 = generate_random_U_vector(T_param)\n        U_query2 = generate_random_U_vector(T_param)\n\n    attempts = 0\n    while np.array_equal(U_query1, U_query2) and attempts &lt; 100:\n        U_query2 = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_query1, U_query2):\n        continue\n\n    obj_q1 = evaluate_objective(\n        U_query1,\n        X_initial_schedule,\n        v_star_matrix,\n        convolutions_dict,\n        d_interval_len,\n        w_weight,\n    )\n    obj_q2 = evaluate_objective(\n        U_query2,\n        X_initial_schedule,\n        v_star_matrix,\n        convolutions_dict,\n        d_interval_len,\n        w_weight,\n    )\n    print(f\"  Query 1 (U): {U_query1.tolist()}, Obj: {obj_q1:.4f}\")\n    print(f\"  Query 2 (U): {U_query2.tolist()}, Obj: {obj_q2:.4f}\")\n\n    if obj_q1 &lt; best_obj_overall:\n        best_obj_overall = obj_q1\n        best_U_overall = U_query1.copy()\n        best_iter_found = pbo_iter + 1\n        print(\n            f\"  New best U from Q1: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f} (Iter: {best_iter_found})\"\n        )\n    if obj_q2 &lt; best_obj_overall:\n        best_obj_overall = obj_q2\n        best_U_overall = U_query2.copy()\n        best_iter_found = pbo_iter + 1\n        print(\n            f\"  New best U from Q2: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f} (Iter: {best_iter_found})\"\n        )\n\n    idx_q1 = add_U_to_master_list(\n        U_query1, embed_HED(U_query1, hed_dictionary)\n    )\n    idx_q2 = add_U_to_master_list(\n        U_query2, embed_HED(U_query2, hed_dictionary)\n    )\n\n    if not np.isclose(obj_q1, obj_q2):\n        pref_pair_iter = [idx_q1, idx_q2] if obj_q1 &lt; obj_q2 else [idx_q2, idx_q1]\n        print(f\"  Preference: {'Q1 &gt; Q2' if obj_q1 &lt; obj_q2 else 'Q2 &gt; Q1'}\")\n        if pref_pair_iter not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair_iter)\n        else:\n            print(\"  (Preference already recorded)\")\n    else:\n        print(\"  Preference: Tie\")\n    print(f\"  Total unique Us: {len(all_U_vectors_list)}, Total preference pairs: {len(comparison_pairs_indices)}\")\n\nprint(\"\\n--- PBO Experiment Finished ---\")\nif best_U_overall is not None:\n    print(f\"Best U vector found (by direct evaluation): {best_U_overall.tolist()}\")\n    final_Y_schedule = X_initial_schedule + np.sum(v_star_matrix[best_U_overall == 1, :], axis=0)\n    print(f\"Corresponding Y schedule: {final_Y_schedule.tolist()}\")\n    print(f\"Objective value: {best_obj_overall:.4f}\")\n    iter_str = \"during initialization (before PBO iterations)\" if best_iter_found == 0 else f\"at PBO iteration {best_iter_found}\"\n    print(f\"Found {iter_str}\")\n    print(f\"Patient count in final Y schedule: {np.sum(final_Y_schedule)}\")\nelse: print(\"No valid U vector found.\")\n\nif pairwise_model is not None and all_U_embeddings_tensor is not None and len(all_U_embeddings_tensor) &gt; 0:\n    pairwise_model.eval()\n    transformed_all_U_embeddings = input_transform(all_U_embeddings_tensor)\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n        posterior_f_all = pairwise_model.posterior(transformed_all_U_embeddings)\n        mean_f_all = posterior_f_all.mean\n    best_idx_model = torch.argmax(mean_f_all).item()\n    U_reco_model = all_U_vectors_list[best_idx_model]\n    obj_reco_model = evaluate_objective(U_reco_model, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"\\nRecommendation based on GP model (highest posterior mean utility over all {len(all_U_vectors_list)} evaluated Us):\")\n    print(f\"  U vector: {U_reco_model.tolist()}\")\n    Y_reco = X_initial_schedule + np.sum(v_star_matrix[U_reco_model == 1, :], axis=0)\n    print(f\"  Corresponding Y schedule: {Y_reco.tolist()}\")\n    print(f\"  Objective value of this GP recommended U: {obj_reco_model:.4f}\")\n    print(f\"  GP's posterior mean utility for this U: {mean_f_all[best_idx_model].item():.4f}\")\nelse: print(\"\\nGP model not available for recommendation.\")\n\n# End of PBO loop\nend_time = time.time()\nelapsed = end_time - start_time\nprint(f\"\\n--- PBO Experiment Finished in {elapsed:.2f} seconds ---\")\n\n\n--- PBO Iteration 1/50 ---\n  Query 1 (U): [0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.9627\n  Preference: Q2 &gt; Q1\n  Total unique Us: 20, Total preference pairs: 7\n\n--- PBO Iteration 2/50 ---\n  Query 1 (U): [1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 22, Total preference pairs: 7\n\n--- PBO Iteration 3/50 ---\n  Query 1 (U): [1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 24, Total preference pairs: 7\n\n--- PBO Iteration 4/50 ---\n  Query 1 (U): [1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 26, Total preference pairs: 7\n\n--- PBO Iteration 5/50 ---\n  Query 1 (U): [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 28, Total preference pairs: 7\n\n--- PBO Iteration 6/50 ---\n  Query 1 (U): [1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 30, Total preference pairs: 7\n\n--- PBO Iteration 7/50 ---\n  Query 1 (U): [1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 32, Total preference pairs: 7\n\n--- PBO Iteration 8/50 ---\n  Query 1 (U): [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 34, Total preference pairs: 7\n\n--- PBO Iteration 9/50 ---\n  Query 1 (U): [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 36, Total preference pairs: 7\n\n--- PBO Iteration 10/50 ---\n  Query 1 (U): [0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 38, Total preference pairs: 7\n\n--- PBO Iteration 11/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.6964\n  Query 2 (U): [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 40, Total preference pairs: 8\n\n--- PBO Iteration 12/50 ---\n  Query 1 (U): [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 207.0453\n  Query 2 (U): [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 42, Total preference pairs: 9\n\n--- PBO Iteration 13/50 ---\n  Query 1 (U): [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.8452\n  Preference: Q2 &gt; Q1\n  Total unique Us: 44, Total preference pairs: 10\n\n--- PBO Iteration 14/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.1122\n  Query 2 (U): [1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 46, Total preference pairs: 11\n\n--- PBO Iteration 15/50 ---\n  Query 1 (U): [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 48, Total preference pairs: 11\n\n--- PBO Iteration 16/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.7525\n  Query 2 (U): [0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 50, Total preference pairs: 12\n\n--- PBO Iteration 17/50 ---\n  Query 1 (U): [0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1], Obj: 207.0562\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 52, Total preference pairs: 13\n\n--- PBO Iteration 18/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 206.9445\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.5335\n  Preference: Q2 &gt; Q1\n  Total unique Us: 54, Total preference pairs: 14\n\n--- PBO Iteration 19/50 ---\n  Query 1 (U): [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 56, Total preference pairs: 14\n\n--- PBO Iteration 20/50 ---\n  Query 1 (U): [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 58, Total preference pairs: 14\n\n--- PBO Iteration 21/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.3939\n  Query 2 (U): [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 60, Total preference pairs: 15\n\n--- PBO Iteration 22/50 ---\n  Query 1 (U): [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 62, Total preference pairs: 15\n\n--- PBO Iteration 23/50 ---\n  Query 1 (U): [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 64, Total preference pairs: 15\n\n--- PBO Iteration 24/50 ---\n  Query 1 (U): [1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.0704\n  Preference: Q2 &gt; Q1\n  Total unique Us: 66, Total preference pairs: 16\n\n--- PBO Iteration 25/50 ---\n  Query 1 (U): [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 221.4890\n  Query 2 (U): [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 68, Total preference pairs: 17\n\n--- PBO Iteration 26/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.1706\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.1301\n  Preference: Q2 &gt; Q1\n  Total unique Us: 70, Total preference pairs: 18\n\n--- PBO Iteration 27/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 72, Total preference pairs: 18\n\n--- PBO Iteration 28/50 ---\n  Query 1 (U): [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.9641\n  Query 2 (U): [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 74, Total preference pairs: 19\n\n--- PBO Iteration 29/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 76, Total preference pairs: 19\n\n--- PBO Iteration 30/50 ---\n  Query 1 (U): [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 78, Total preference pairs: 19\n\n--- PBO Iteration 31/50 ---\n  Query 1 (U): [0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.8882\n  Preference: Q2 &gt; Q1\n  Total unique Us: 80, Total preference pairs: 20\n\n--- PBO Iteration 32/50 ---\n  Query 1 (U): [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 207.0182\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 82, Total preference pairs: 21\n\n--- PBO Iteration 33/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 84, Total preference pairs: 21\n\n--- PBO Iteration 34/50 ---\n  Query 1 (U): [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], Obj: 206.7306\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 86, Total preference pairs: 22\n\n--- PBO Iteration 35/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], Obj: 205.4661\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 &gt; Q2\n  Total unique Us: 88, Total preference pairs: 23\n\n--- PBO Iteration 36/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 90, Total preference pairs: 23\n\n--- PBO Iteration 37/50 ---\n  Query 1 (U): [0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 92, Total preference pairs: 23\n\n--- PBO Iteration 38/50 ---\n  Query 1 (U): [1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 94, Total preference pairs: 23\n\n--- PBO Iteration 39/50 ---\n  Query 1 (U): [1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.3123\n  Preference: Q2 &gt; Q1\n  Total unique Us: 96, Total preference pairs: 24\n\n--- PBO Iteration 40/50 ---\n  Query 1 (U): [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 98, Total preference pairs: 24\n\n--- PBO Iteration 41/50 ---\n  Query 1 (U): [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.7417\n  Preference: Q2 &gt; Q1\n  Total unique Us: 100, Total preference pairs: 25\n\n--- PBO Iteration 42/50 ---\n  Query 1 (U): [0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 206.8088\n  Preference: Q2 &gt; Q1\n  Total unique Us: 102, Total preference pairs: 26\n\n--- PBO Iteration 43/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.2584\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 207.0135\n  New best U from Q1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 205.2584 (Iter: 43)\n  Preference: Q1 &gt; Q2\n  Total unique Us: 104, Total preference pairs: 27\n\n--- PBO Iteration 44/50 ---\n  Query 1 (U): [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 106, Total preference pairs: 27\n\n--- PBO Iteration 45/50 ---\n  Query 1 (U): [1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 108, Total preference pairs: 27\n\n--- PBO Iteration 46/50 ---\n  Query 1 (U): [1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 110, Total preference pairs: 27\n\n--- PBO Iteration 47/50 ---\n  Query 1 (U): [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 112, Total preference pairs: 27\n\n--- PBO Iteration 48/50 ---\n  Query 1 (U): [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 114, Total preference pairs: 27\n\n--- PBO Iteration 49/50 ---\n  Query 1 (U): [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 116, Total preference pairs: 27\n\n--- PBO Iteration 50/50 ---\n  Query 1 (U): [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 118, Total preference pairs: 27\n\n--- PBO Experiment Finished ---\nBest U vector found (by direct evaluation): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nCorresponding Y schedule: [2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 12]\nObjective value: 205.2584\nFound at PBO iteration 43\nPatient count in final Y schedule: 50\n\nRecommendation based on GP model (highest posterior mean utility over all 118 evaluated Us):\n  U vector: [1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n  Corresponding Y schedule: [2, 0, 2, 0, 0, 2, 1, 0, 2, 0, 1, 0, 2, -1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 2, -1, 2, 0, 2, 0, 1, 1, 1, 1, -1, 13]\n  Objective value of this GP recommended U: 10000000000.0000\n  GP's posterior mean utility for this U: -0.1030\n\n--- PBO Experiment Finished in 55.63 seconds ---",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#discussion",
    "href": "preferential-bayesian-optimization.html#discussion",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.11 Discussion",
    "text": "7.11 Discussion\nIn this study, we demonstrated how Preferential Bayesian Optimization (PBO) combined with Hamming Embeddings via Dictionaries (HED) can efficiently navigate the high-dimensional binary space of schedule perturbations and deliver improved outpatient appointment schedules with far fewer objective evaluations than naïve random or local‐search heuristics.\n\n7.11.1 Future Directions\nAutomated Acquisition–Function Discovery with FunBO.\nAglietti et al. (2024) introduce FunBO, a technique that leverages large language models to programmatically generate, refine, and evaluate novel Bayesian‐optimization acquisition functions. By iterating between an LLM prompt (to propose new code variants) and empirical benchmarking, FunBO has discovered bespoke strategies that outperform classical rules like Expected Improvement or Upper Confidence Bound on standard continuous benchmarks.\n\nWhy this matters for HED+PBO: Our current pipeline uses off‐the‐shelf PBO acquisitions (e.g. Thompson sampling on Hamming‐dictionary inputs). FunBO could be tasked to propose duel‐specific acquisition rules—perhaps embedding‐aware diversity measures or adaptive exploration–exploitation schedules—that are tailor‐made for the combinatorial neighborhood of outpatient schedules. Systematically comparing these LLM‐generated acquisitions could lead to even faster convergence or better final schedules, especially in large or highly constrained clinics.\n\nInner–Loop Amortization via Learned Proposal Policies.\nSwersky et al. (2020) train a lightweight neural policy via reinforcement learning to amortize the inner maximization of discrete‐space acquisition functions. Instead of exhaustively scanning candidates at each BO step, the network instantly proposes high‐quality points, yielding dramatic per‐iteration speed‐ups on tasks such as protein‐sequence design.\n\nWhy this matters for HED+PBO: In our implementation, we still sample and score hundreds of Hamming‐neighbors each iteration—incurring nontrivial runtime as \\(T\\) and the dictionary size grow. By training a “deep evolutionary” proposal network on synthetic perturbation‐scheduling tasks (varying \\(N,T\\), service distributions, no‐show rates), we could replace that random/Hamming sampling step with a single neural forward pass, enabling near‐real‐time PBO for large‐scale or interactive applications.\n\nFully Amortized Preferential BO with Meta‐Learning.\nZhang et al. (2025) develop PABBO, a transformer‐based meta‐learner that jointly models both the surrogate posterior and the duel acquisition policy. Once pre‐trained on a diverse corpus of BO problems, it requires no GP refitting or inner‐loop optimization at test time—simply mapping past duels to new pair scores in one forward pass, and achieving orders‐of‐magnitude speed‐ups while matching or exceeding GP dynamics :contentReferenceoaicite:2.\n\nWhy this matters for HED+PBO: Although our HED+PairwiseGP already reduces input dimensionality, each iteration still fits a GP and samples dozens of candidates. A PABBO‐inspired extension could meta‐train on HED‐embedded scheduling duels, so that in a new clinic setting, the model instantly proposes top perturbations—unlocking truly interactive preferential optimization for clinician‐in‐the‐loop scheduling or adaptive appointment systems.\n\nBy exploring these directions—LLM‐driven acquisition design, learned inner‐loop proposals, and fully amortized PBO—we can further improve the scalability, runtime efficiency, and automation of HED‐based preferential optimization for outpatient scheduling.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#timeline",
    "href": "preferential-bayesian-optimization.html#timeline",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.12 Timeline",
    "text": "7.12 Timeline\n\nExperiment Design: 19-05-2025\nImplementation: 19-05-2025\nExecution: (to be filled after run)\nAnalysis: (to be filled after run)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "preferential-bayesian-optimization.html#references",
    "href": "preferential-bayesian-optimization.html#references",
    "title": "7  Preferential Bayesian Optimization for Outpatient Appointment Scheduling",
    "section": "7.13 References",
    "text": "7.13 References\n\n\nAglietti, Virginia, Ira Ktena, Jessica Schrouff, Eleni Sgouritsa, Francisco J. R. Ruiz, Alan Malek, Alexis Bellot, and Silvia Chiappa. 2024. “FunBO: Discovering Acquisition Functions for Bayesian Optimization with FunSearch.” arXiv. https://doi.org/10.48550/arXiv.2406.04824.\n\n\nBalandat, Maximilian, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. 2020. “BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization.” In Advances in Neural Information Processing Systems 33. http://arxiv.org/abs/1910.06403.\n\n\nDeshwal, Aryan, Sebastian Ament, Maximilian Balandat, Eytan Bakshy, Janardhan Rao Doppa, and David Eriksson. 2023. “Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-Based Embeddings.” In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, 7021–39. PMLR. https://proceedings.mlr.press/v206/deshwal23a.html.\n\n\nGonzalez, Javier, Zhenwen Dai, Andreas Damianou, and Neil D. Lawrence. 2017. “Preferential Bayesian Optimization.” arXiv. https://doi.org/10.48550/arXiv.1704.03651.\n\n\nKaandorp, Guido C., and Ger Koole. 2007. “Optimal Outpatient Appointment Scheduling.” Health Care Management Science 10 (3): 217–29. https://doi.org/10.1007/s10729-007-9015-x.\n\n\nSwersky, Kevin, Yulia Rubanova, David Dohan, and Kevin Murphy. 2020. “Amortized Bayesian Optimization over Discrete Spaces.” In Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI), 769–78. PMLR. https://proceedings.mlr.press/v124/swersky20a.html.\n\n\nZhang, Xinyu, Daolang Huang, Samuel Kaski, and Julien Martinelli. 2025. “PABBO: Preferential Amortized Black-Box Optimization.” arXiv. https://doi.org/10.48550/arXiv.2503.00924.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preferential Bayesian Optimization for Outpatient Appointment Scheduling</span>"
    ]
  },
  {
    "objectID": "filtered-solution-spaces.html",
    "href": "filtered-solution-spaces.html",
    "title": "8  Filtered solution spaces for outpatient appointment scheduling",
    "section": "",
    "text": "8.1 Introduction\nOutpatient appointment scheduling is a critical operational challenge in healthcare systems, striving to efficiently manage patient flow while balancing multiple, often conflicting, objectives. The core dilemma involves minimizing patient waiting times, reducing clinician idle time, and preventing clinic sessions from running excessively late (tardiness). Effectively addressing this requires robust scheduling policies that can adapt to inherent uncertainties, such as variable service times and patient no-shows.\nWork by Kaandorp and Koole (2007) provides a comprehensive mathematical framework for tackling this problem. They proposed an objective function that considers a weighted average of expected patient waiting times, doctor idle time, and session tardiness, explicitly incorporating the possibility of patient no-shows. A key contribution of their research was the demonstration that, under certain conditions, their objective function exhibits multimodularity. This property is significant because it guarantees that a local search algorithm can converge to a globally optimal appointment schedule. Their model assumes discrete time intervals and exponentially distributed service times.\nThis document details a computational exploration and implementation inspired by the principles and challenges outlined in the work of Kaandorp and Koole. Our primary objective is to investigate the characteristics of optimal, or near-optimal, appointment schedules under various parameter settings. While the original paper focuses on the theoretical properties and a local search method, this study employs a direct enumeration and evaluation approach for a specific class of schedule structures.\nSpecifically, we implement a Python-based model to:\nThrough this computational study, we aim to gain deeper insights into the sensitivity of optimal schedules to key operational parameters and to visualize the complex trade-offs inherent in outpatient appointment systems. The findings from this enumerative approach can also serve as a benchmark and provide foundational understanding for the development or comparison of more sophisticated heuristic or exact optimization algorithms.\nCode\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom scipy.linalg import hadamard\nfrom scipy.optimize import minimize\nimport random\nimport textwrap\nfrom typing import List, Tuple, Dict, Optional\nimport unittest\nimport time\n\nfrom functions import (\n    get_v_star,\n    compute_convolutions,\n    calculate_objective_serv_time_lookup,\n    local_search_w_timer\n)\nCode\n# --- Helper: generate_weighted_list ---\ndef generate_weighted_list(max_s: int, l: float, i: int) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Generates a list of probabilities (weights) for service times using optimization.\n\n    The function aims to find a probability distribution over `max_s` service times\n    such that the expected service time is close to `l`. The probabilities\n    are split at index `i`; those before `i` are sorted ascendingly, and those\n    from `i` onwards are sorted descendingly.\n\n    Args:\n        max_s (int): The maximum possible service time (number of discrete service\n                     time units, e.g., 30 means service times 1, 2, ..., 30).\n                     Must be a positive integer.\n        l (float): The target average service time. Must be between 1 and `max_s`\n                   (inclusive).\n        i (int): The index (0-based) relative to `max_s` at which to split the\n                 sorting of probabilities. `0 &lt;= i &lt; max_s`.\n                 Probabilities for service times 1 to `i` are sorted ascendingly.\n                 Probabilities for service times `i+1` to `max_s` are sorted descendingly.\n\n    Returns:\n        Optional[np.ndarray]: An array of probabilities (weights) of length `max_s + 1`.\n                              Index 0 is unused (set to 0). Indices 1 to `max_s` store\n                              the probabilities for service times 1 to `max_s` respectively.\n                              Returns `None` if input validation fails, optimization\n                              does not converge, or a valid probability distribution\n                              cannot be formed (e.g., sum of probabilities is too low).\n    \n    Notes:\n        Uses `scipy.optimize.minimize` with the 'SLSQP' method.\n        The objective is to minimize `(dot_product(service_times, probabilities) - l)^2`.\n        Probabilities are constrained to sum to 1 and be between 0 and 1.\n    \"\"\"\n    if not isinstance(max_s, int) or max_s &lt;= 0:\n        # print(\"Validation failed: max_s must be a positive integer.\")\n        return None\n    if not isinstance(l, (int, float)) or not (1 &lt;= l &lt;= max_s):\n        # print(f\"Validation failed: l (target avg service time) {l} must be between 1 and max_s {max_s}.\")\n        return None\n    if not isinstance(i, int) or not (0 &lt;= i &lt; max_s):\n        # print(f\"Validation failed: i (sorting split index) {i} must be between 0 and max_s-1 {max_s-1}.\")\n        return None\n\n    def objective_fn(x: np.ndarray) -&gt; float:\n        \"\"\"Objective function for optimization: squared difference from target mean.\"\"\"\n        return (np.dot(np.arange(1, max_s + 1), x) - l) ** 2\n\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})\n    bounds = [(0, 1)] * max_s # Probabilities must be between 0 and 1\n    \n    # Initial guess: Dirichlet distribution ensures sum to 1 and positive values\n    initial_guess = np.random.dirichlet(np.ones(max_s))\n\n    try:\n        result = minimize(objective_fn, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints, options={'maxiter': 300, 'ftol': 1e-9})\n        \n        if not result.success:\n            # print(f\"Optimization failed to converge: {result.message}\")\n            return None\n            \n        optimized_probs = result.x\n        # Clip small negative values that might arise from numerical precision issues\n        optimized_probs[optimized_probs &lt; 0] = 0\n        \n        # Normalize if sum is not exactly 1.0 (but close)\n        current_sum = np.sum(optimized_probs)\n        if not np.isclose(current_sum, 1.0):\n            if current_sum &gt; 1e-8: # Avoid division by zero or very small numbers\n                optimized_probs /= current_sum\n            else:\n                # print(\"Sum of optimized probabilities is too close to zero after optimization.\")\n                return None # Sum too low, cannot reliably normalize\n                \n    except Exception as e:\n        # print(f\"An exception occurred during optimization: {e}\")\n        return None\n\n    # Prepare the final array `values` of size max_s + 1 (index 0 unused)\n    values = np.zeros(max_s + 1)\n    \n    # Split and sort the probabilities\n    first_part_probs = optimized_probs[:i] if i &gt; 0 else np.array([])\n    second_part_probs = optimized_probs[i:]\n\n    if i &gt; 0:\n        values[1 : i + 1] = np.sort(first_part_probs) # Ascending sort for the first part\n    \n    # Descending sort for the second part\n    values[i + 1 : max_s + 1] = np.sort(second_part_probs)[::-1] \n    \n    # Final normalization check for the sorted and combined values\n    # This step is crucial because the sorting might have been applied to already normalized values,\n    # but if the original optimized_probs were not perfectly 1 due to clipping or other reasons,\n    # this ensures the `values` array (excluding index 0) sums to 1.\n    final_sum = np.sum(values[1:])\n    if not np.isclose(final_sum, 1.0):\n        if final_sum &gt; 1e-8:\n            values[1:] /= final_sum\n        else:\n            # print(\"Sum of final probabilities after sorting is too close to zero.\")\n            return None # Cannot form a valid distribution\n\n    return values\n\n# --- Helper: Generate evenly distributed patient schedule ---\ndef generate_evenly_distributed_schedule_intervals(n_patients: int, t_intervals: int) -&gt; List[int]:\n    \"\"\"\n    Generates a list representing a schedule, aiming to distribute 'n_patients'\n    into 't_intervals' as evenly as possible using round(). A '1' indicates\n    a scheduled interval, and '0' an empty one.\n\n    Key Behavior:\n    - If n_patients == 0: Returns a list of all zeros of length 't_intervals'.\n    - If t_intervals &lt; n_patients (and n_patients &gt; 0): Raises a ValueError.\n    - If n_patients == t_intervals (and both &gt; 0): Returns a list of all ones.\n    - If n_patients &lt; t_intervals (and both &gt; 0): The function attempts to mark\n      'n_patients' distinct intervals using rounding.\n      The patient slots are chosen using the formula `round(j * t_intervals / n_patients)`\n      for j from 0 to n_patients-1.\n    - **Warning**: Using `round()` might lead to duplicate indices, potentially\n      resulting in fewer than 'n_patients' being scheduled if collisions occur.\n      If exactly 'n_patients' must be scheduled and distinct slots are paramount,\n      a floor-based approach or a different distribution algorithm might be preferred.\n\n    Args:\n        n_patients (int): The number of patients to schedule.\n                          Must be a non-negative integer.\n        t_intervals (int): The total number of available time intervals.\n                           Must be a non-negative integer.\n\n    Returns:\n        List[int]: A list of integers (0s and 1s) of length 't_intervals',\n                   representing the schedule. '1' for a scheduled patient, '0' otherwise.\n\n    Raises:\n        ValueError: If 'n_patients' or 't_intervals' are not non-negative integers.\n        ValueError: If 't_intervals' is less than 'n_patients' (and n_patients &gt; 0),\n                    as it's impossible to schedule more patients than available intervals.\n    \"\"\"\n    # Validate inputs\n    if not isinstance(n_patients, int) or n_patients &lt; 0:\n        raise ValueError(\"n_patients must be a non-negative integer.\")\n    if not isinstance(t_intervals, int) or t_intervals &lt; 0:\n        raise ValueError(\"t_intervals must be a non-negative integer.\")\n\n    # Handle n_patients == 0\n    if n_patients == 0:\n        return [0] * t_intervals\n\n    # At this point, n_patients &gt; 0.\n\n    # Core logic based on comparison of n_patients and t_intervals\n    if t_intervals &lt; n_patients:\n        raise ValueError(\n            f\"Cannot schedule {n_patients} patients in only {t_intervals} intervals. \"\n            \"Not enough unique slots available.\"\n        )\n    elif n_patients == t_intervals:\n        return [1] * t_intervals\n    else: # n_patients &lt; t_intervals\n        schedule = [0] * t_intervals\n        # scheduled_count = 0 # Not used in current logic but could be for verification\n        for j in range(n_patients):\n            # Use round() and ensure the result is an integer for indexing\n            index = int(round(j * t_intervals / n_patients))\n\n            # Ensure index stays within bounds.\n            # This primarily handles the edge case where j = n_patients - 1,\n            # (n_patients - 1) * t_intervals / n_patients can round up to t_intervals.\n            if index &gt;= t_intervals:\n                index = t_intervals - 1\n            \n            # It's possible that `schedule[index]` is already 1 due to rounding collisions.\n            # The current logic overwrites, effectively scheduling one patient at that slot.\n            # If distinct patient counts are critical, this needs adjustment.\n            schedule[index] = 1\n\n        # Optional: Add a check/warning if the number of scheduled patients\n        # is less than n_patients due to rounding collisions.\n        # actual_scheduled = sum(schedule)\n        # if actual_scheduled &lt; n_patients:\n        #     print(f\"Warning: Due to rounding, only {actual_scheduled} out of {n_patients} patients were scheduled.\")\n        return schedule\n\n# --- Helper: Generate start and tail numbers ---\ndef generate_start_tail_distribution(N_patients: int, T_intervals: int) -&gt; List[Tuple[int, int]]:\n    \"\"\"\n    Generates valid combinations of 'start' and 'tail' patient counts for a schedule.\n\n    'Start' refers to the number of patients scheduled consecutively at the\n    beginning of the `T_intervals`. 'Tail' refers to those at the end.\n    The function iterates through all possible numbers of patients at the start (from 0 to N_patients)\n    and for each, all possible numbers of patients at the tail (from 0 up to remaining patients).\n    A (start, tail) combination is considered valid if the remaining patients\n    (N_patients - start - tail) can fit within the remaining intervals\n    (T_intervals - 2, assuming start and tail each occupy one conceptual \"block\"\n    or represent counts for the first and last actual interval/slot).\n\n    Args:\n        N_patients (int): The total number of patients to be scheduled.\n                          Must be a positive integer for useful output.\n        T_intervals (int): The total number of available time intervals.\n\n    Returns:\n        List[Tuple[int, int]]: A list of tuples, where each tuple is (start_patients, tail_patients).\n                               Returns an empty list if `N_patients &lt;= 0`.\n    \n    Constraint for validity:\n        The number of patients to be scheduled in the \"center\" part of the schedule\n        (N_patients - start - tail) must be less than or equal to the number of\n        intervals available for the center part (T_intervals - 2). This assumes\n        the 'start' and 'tail' numbers might represent single bulk appointments or\n        counts for the very first and very last interval positions, leaving T-2 intervals\n        for the \"center\" distribution.\n    \"\"\"\n    if not isinstance(N_patients, int) or N_patients &lt;= 0:\n        return []\n    if not isinstance(T_intervals, int) or T_intervals &lt; 0: # Allow T_intervals = 0, 1 for edge cases\n        # Consider raising error if T_intervals &lt; 2 if the -2 logic is strict\n        pass\n\n    distribution = []\n    for i in range(N_patients + 1):  # Number of patients at the start\n        start = i\n        for j in range(N_patients + 1 - i): # Number of patients at the tail\n            tail = j\n            # Number of patients to be scheduled in the center:\n            center_patients = N_patients - start - tail\n            # Number of intervals available for the center:\n            # Assumes start and tail might refer to the first and last interval slot counts,\n            # or conceptual blocks, leaving T_intervals - 2 for the middle part.\n            center_intervals = T_intervals - 2\n            \n            if center_intervals &lt; 0: # Not enough intervals for even start/tail representation\n                if center_patients == 0: # Only if no center patients are needed\n                     # This case (e.g., T_intervals=1, N_patients=1, start=1, tail=0) might be valid\n                     # depending on interpretation. The condition below will handle it.\n                     pass # Let the condition below decide\n                else:\n                    continue # Cannot schedule center patients if no center_intervals\n\n            if center_patients &lt;= center_intervals or (center_patients == 0 and center_intervals &gt;= -1) : # Allow N-s-t=0 even if T-2 is -1 or 0\n                distribution.append((start, tail))\n    return distribution\nCode\n# --- Main computation function ---\nN_patients_fig1 = 24  # Renamed to avoid conflict with N_patients for fig2\nT_intervals = 48\nd_interval_len = 10\nmax_s_time = 30\nl_target_avg_service_time = 14.0\ni_sorting_split = 10\n\n# v_star_matrix = get_v_star(T_intervals) # This is not used in compute_schedules_and_objectives\ns_dist = generate_weighted_list(max_s_time, l_target_avg_service_time, i_sorting_split)\nif s_dist is None:\n    raise ValueError(\"Failed to generate service time distribution (s_dist).\")\n\ndef compute_schedules_and_objectives(\n    q_no_show: float,\n    w_weight: float,\n    current_N_patients: int, # Added to make N_patients explicit\n    current_T_intervals: int # Added to make T_intervals explicit\n    ) -&gt; Tuple[List[List[int]], List[float]]:\n    \"\"\"\n    Computes various patient schedules and their corresponding objective function values.\n\n    This function orchestrates the generation of schedules based on start/tail\n    distributions and a central, evenly distributed portion. It then calculates\n    an objective value for each schedule, which is a weighted sum of expected\n    waiting time (EWT) and expected service provider overtime/idleness (ESP).\n\n    Args:\n        q_no_show (float): The probability of a patient not showing up.\n        w_weight (float): The weighting factor for the objective function.\n                          It balances EWT and ESP: `w_weight * EWT + (1 - w_weight) * ESP`.\n        current_N_patients (int): The total number of patients for this computation.\n        current_T_intervals (int): The total number of time intervals for this computation.\n\n    Returns:\n        Tuple[List[List[int]], List[float]]:\n            - schedules (List[List[int]]): A list of generated schedules. Each schedule\n              is a list of integers: `[start_count, c1, c2, ..., c(T-2), tail_count]`,\n              where `c_i` is 0 or 1 for the center part. The sum of elements in\n              a schedule should equal `current_N_patients`.\n            - objective_values (List[float]): A list of objective function values\n              corresponding to each schedule.\n\n    Raises:\n        ValueError: If `s_dist` (globally defined service time distribution) is None\n                    at the time of calling `compute_convolutions` (indirectly, as it's a global).\n        ValueError: If `generate_evenly_distributed_schedule_intervals` fails to produce\n                    a center schedule (e.g., returns None, though its current implementation raises).\n    \n    Dependencies:\n        - `s_dist` (global): Pre-computed service time distribution.\n        - `d_interval_len` (global): Length of each discrete interval.\n        - `compute_convolutions`: External function to get convolution dictionary.\n        - `generate_start_tail_distribution`: Helper to get start/tail patient counts.\n        - `generate_evenly_distributed_schedule_intervals`: Helper for the center part of schedule.\n        - `calculate_objective_serv_time_lookup`: External function for EWT and ESP.\n    \"\"\"\n    if s_dist is None:\n        raise ValueError(\"s_dist (service time distribution) is None.\")\n\n    # `s_dist` from `generate_weighted_list` is np.ndarray.\n    # `compute_convolutions` might expect a list.\n    s_dist_list = s_dist.tolist() if isinstance(s_dist, np.ndarray) else s_dist\n\n    convolutions_dict = compute_convolutions(s_dist_list, current_N_patients, q_no_show)\n\n    # Generate possible (start, tail) combinations for patient counts\n    # Note: generate_start_tail_distribution uses N_patients and T_intervals\n    # implicitly. It's better to pass them as arguments if they can vary.\n    # Here, we use current_N_patients and current_T_intervals.\n    start_tail_options = generate_start_tail_distribution(current_N_patients, current_T_intervals)\n    schedules = []\n    objective_values = []\n\n    for start_count, tail_count in start_tail_options:\n        schedule_parts = [] # To build the full schedule: [start, center..., tail]\n\n        # The 'start_count' itself represents the number of patients in the first conceptual slot/block.\n        # In the context of `calculate_objective_serv_time_lookup`, this might be interpreted\n        # as the count for the first element of the schedule list.\n        schedule_parts.append(start_count)\n\n        num_center_patients = current_N_patients - start_count - tail_count\n        num_center_intervals = current_T_intervals - 2 # Intervals available for the center part\n\n        if num_center_patients &lt; 0: # Should not happen if generate_start_tail_distribution is correct\n            # print(f\"Warning: Negative center patients ({num_center_patients}) for start={start_count}, tail={tail_count}. Skipping.\")\n            continue\n        \n        if num_center_intervals &lt; 0:\n            if num_center_patients &gt; 0:\n                # print(f\"Warning: Cannot schedule {num_center_patients} center patients in {num_center_intervals} intervals. Skipping.\")\n                continue\n            # If num_center_patients is 0 and num_center_intervals is &lt; 0, center_schedule should be empty.\n            center_schedule_segment = []\n        elif num_center_patients == 0: # No patients for the center part\n             center_schedule_segment = [0] * num_center_intervals\n        else:\n            center_schedule_segment = generate_evenly_distributed_schedule_intervals(\n                num_center_patients,\n                num_center_intervals\n            )\n            # generate_evenly_distributed_schedule_intervals raises ValueError on failure\n            # so no need to check for None if its contract is maintained.\n\n        schedule_parts.extend(center_schedule_segment)\n        schedule_parts.append(tail_count) # Add the tail count as the last element\n\n        # Ensure the generated schedule has the correct total length current_T_intervals\n        # The structure is [start_val] + [c1, ..., c_{T-2}] + [tail_val]\n        # So, 1 (for start) + (T-2) (for center) + 1 (for tail) = T elements.\n        if len(schedule_parts) != current_T_intervals:\n            # This might happen if T_intervals &lt; 2.\n            # Example: T_intervals = 1. num_center_intervals = -1.\n            # schedule_parts = [start_count] + [] + [tail_count] -&gt; length 2, not 1.\n            # The interpretation of 'start' and 'tail' and how they map to the schedule list\n            # for `calculate_objective_serv_time_lookup` is critical here.\n            # Assuming `calculate_objective_serv_time_lookup` expects a list of length `current_T_intervals`\n            # where each element is a count of patients for that interval.\n            # If T_intervals=1, schedule should be [N_patients_fig1].\n            # If T_intervals=0, schedule should be [].\n            # The current structure [start, ccc, tail] implies T_intervals &gt;= 2.\n            # Let's adjust if T_intervals &lt; 2.\n            if current_T_intervals == 1:\n                if start_count + tail_count == current_N_patients and not center_schedule_segment: # Only start or tail contributes\n                     # The logic of start/tail might imply distinct first/last intervals.\n                     # For T_intervals=1, the schedule is just [N_patients_fig1].\n                     # We need a single value for the schedule.\n                     # This case is tricky with start/center/tail logic.\n                     # A simpler schedule representation might be needed for T_intervals &lt; 2.\n                     # For now, let's assume `calculate_objective_serv_time_lookup` can handle it,\n                     # or this case (T_intervals &lt; 2) is not expected for this specific schedule structure.\n                     # If `start_count` is meant to be schedule[0] and `tail_count` schedule[-1],\n                     # then for T_intervals=1, start_count and tail_count would refer to the same slot.\n                     # The current `generate_start_tail_distribution` allows (N,0) or (0,N) for T=1, N.\n                     # Let's assume the schedule sent to objective should be of length T_intervals.\n                     if current_N_patients == start_count and tail_count == 0:\n                         final_schedule = [start_count]\n                     elif current_N_patients == tail_count and start_count == 0:\n                         final_schedule = [tail_count]\n                     else: # Ambiguous or invalid state for T=1 with this start/tail split.\n                         # print(f\"Warning: Ambiguous schedule for T_intervals=1 with start={start_count}, tail={tail_count}. Skipping.\")\n                         continue\n                else: # Mismatch or center patients exist where they shouldn't\n                    # print(f\"Warning: Patient count mismatch for T_intervals=1. Skipping.\")\n                    continue\n\n            elif current_T_intervals == 0:\n                if current_N_patients == 0:\n                    final_schedule = []\n                else: # Cannot schedule patients in 0 intervals\n                    # print(f\"Warning: Cannot schedule {current_N_patients} in 0 intervals. Skipping.\")\n                    continue\n            else: # T_intervals &gt;= 2, schedule_parts should be T_intervals long.\n                  # If not, there's a logic error in how center_schedule_segment was made.\n                  # This should ideally not happen if num_center_intervals is correct.\n                  # print(f\"Warning: Schedule length {len(schedule_parts)} != T_intervals {current_T_intervals}. Skipping.\")\n                  # print(f\"  Details: N={current_N_patients}, T={current_T_intervals}, start={start_count}, tail={tail_count}, center_p={num_center_patients}, center_i={num_center_intervals}\")\n                  # print(f\"  Center segment: {center_schedule_segment}\")\n                  continue\n        else:\n            final_schedule = schedule_parts\n\n        # Sanity check: sum of patients in the schedule should match current_N_patients\n        if sum(final_schedule) != current_N_patients:\n            # print(f\"Warning: Sum of patients in schedule {sum(final_schedule)} != N_patients {current_N_patients}. Schedule: {final_schedule}. Skipping.\")\n            continue\n\n        schedules.append(final_schedule)\n\n        # Calculate objective value for this schedule\n        # `d_interval_len` is used from global scope.\n        ewt, esp = calculate_objective_serv_time_lookup(final_schedule, d_interval_len, convolutions_dict)\n        objective_value = w_weight * ewt + (1 - w_weight) * esp\n        objective_values.append(objective_value)\n\n    return schedules, objective_values\n\n# --- Create 3x3 subplot grid ---\nq_values = [0.1, 0.15, 0.2]\nw_values = [0.1, 0.5, 0.9]\nA projection of a solution space is a subset of the solution space that satisfies some additional constraints, such as a fixed sum of certain components. In this case, we are interested in projections where the sum of the start count and tail count is equal to a target value.\nCode\n# Parameters for the new chart\nN_patients_single_case = 48\nq_single_case = 0.2\nw_single_case = 0.5\n# T_intervals is assumed to be the globally defined T_intervals = 48.\n# s_dist is assumed to be the globally computed service time distribution.\n# d_interval_len is assumed to be the globally defined d_interval_len = 10.\n\n# Compute schedules and objectives for the new parameters\n# Assumes T_intervals, s_dist, and d_interval_len are available from previous cells' execution\n# and compute_schedules_and_objectives function is defined.\nschedules_single, objective_values_single = compute_schedules_and_objectives(\n    q_single_case, \n    w_single_case, \n    N_patients_single_case, \n    T_intervals # Use the existing global T_intervals (should be 48)\n)\n\n# Create the 3D scatter plot\nfig_single = go.Figure()\n\nif not schedules_single or not objective_values_single:\n    print(f\"No data to plot for N={N_patients_single_case}, q={q_single_case}, w={w_single_case}\")\n    fig_single.add_annotation(text=\"No data to plot for these parameters\",\n                              xref=\"paper\", yref=\"paper\",\n                              x=0.5, y=0.5, showarrow=False,\n                              font=dict(size=16))\n    fig_single.update_layout(\n        title=f'3D Schedule Analysis: N={N_patients_single_case}, q={q_single_case:.2f}, w={w_single_case:.1f} - No Data',\n        height=500, width=700\n    )\n\nelse:\n    x_coords_single = [schedule[0] for schedule in schedules_single]\n    y_coords_single = [(schedule[-1] if len(schedule)&gt;0 else 0) for schedule in schedules_single]\n    z_values_single = objective_values_single # This is a list\n\n    min_obj_val_single = min(z_values_single)\n    min_index_single = z_values_single.index(min_obj_val_single)\n\n    schedules_wrapped_single = [textwrap.wrap(str(schedule), width=75) for schedule in schedules_single]\n    formatted_schedules_str_single = [\"&lt;br&gt;\".join(schedule_lines) for schedule_lines in schedules_wrapped_single]\n\n    hover_texts_single = [\n        f\"Sch: {f_sch_str}&lt;br&gt;N_sched: {sum(sch_list)}&lt;br&gt;Obj: {obj_val:.4f}&lt;br&gt;\" +\n        f\"Start: {sch_list[0]}, Tail: {(sch_list[-1] if len(sch_list)&gt;0 else 0)}\"\n        for sch_list, f_sch_str, obj_val in zip(schedules_single, formatted_schedules_str_single, z_values_single)\n    ]\n\n    # --- Add visual representation of the plane: start_count + tail_count = 40 ---\n    if z_values_single: \n        plane_z_min = np.min(z_values_single) \n        plane_z_max = np.max(z_values_single) \n        \n        if plane_z_min == plane_z_max: # Add margin if all z-values are the same\n            plane_z_min -= 0.5 \n            plane_z_max += 0.5\n        \n        # Define vertices for the plane segment x + y = 40\n        # P0=(0, 40, plane_z_min)\n        # P1=(40, 0, plane_z_min)\n        # P2=(40, 0, plane_z_max)\n        # P3=(0, 40, plane_z_max)\n        plane_mesh_x = [0, 40, 40, 0] \n        plane_mesh_y = [40, 0, 0, 40] \n        plane_mesh_z = [plane_z_min, plane_z_min, plane_z_max, plane_z_max]\n\n        fig_single.add_trace(go.Mesh3d(\n            x=plane_mesh_x,\n            y=plane_mesh_y,\n            z=plane_mesh_z,\n            # Triangles using vertex indices: (0,1,2) and (0,2,3)\n            i=[0, 0],  \n            j=[1, 2],  \n            k=[2, 3],  \n            opacity=0.15,\n            color='gray',\n            name='Plane S+T=40',\n            showlegend=True\n        ))\n\n    # --- Add normal data points ---\n    normal_indices_single = [idx for idx in range(len(z_values_single)) if idx != min_index_single]\n    normal_x_single = [x_coords_single[idx] for idx in normal_indices_single]\n    normal_y_single = [y_coords_single[idx] for idx in normal_indices_single]\n    normal_z_single = [z_values_single[idx] for idx in normal_indices_single]\n    normal_hover_single = [hover_texts_single[idx] for idx in normal_indices_single]\n\n    fig_single.add_trace(\n        go.Scatter3d(\n            x=normal_x_single, y=normal_y_single, z=normal_z_single,\n            mode='markers',\n            marker=dict(size=4, color=normal_z_single, colorscale='Viridis', opacity=0.7, colorbar=dict(title='Objective Value')),\n            hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;',\n            hovertext=normal_hover_single,\n            name='Data points' \n        )\n    )\n\n    # --- Add minimum point ---\n    min_x_single = [x_coords_single[min_index_single]]\n    min_y_single = [y_coords_single[min_index_single]]\n    min_z_val_single = [z_values_single[min_index_single]]\n    min_hover_single = [hover_texts_single[min_index_single]]\n    \n    fig_single.add_trace(\n        go.Scatter3d(\n            x=min_x_single, y=min_y_single, z=min_z_val_single,\n            mode='markers',\n            marker=dict(size=6, color='red', opacity=1.0),\n            hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;',\n            hovertext=min_hover_single,\n            name=f'Minimum (Obj: {min_obj_val_single:.4f})' \n        )\n    )\n\n    # --- Add projection points for start_count + tail_count = 40 ---\n    proj_x = []\n    proj_y = []\n    proj_z = []\n    proj_hover = []\n\n    for idx, schedule in enumerate(schedules_single):\n        start_count = schedule[0]\n        tail_count = schedule[-1] if len(schedule) &gt; 0 else 0\n        \n        if start_count + tail_count == 40:\n            proj_x.append(start_count)\n            proj_y.append(tail_count)\n            proj_z.append(objective_values_single[idx])\n            proj_hover.append(hover_texts_single[idx]) \n\n    if proj_x: \n        fig_single.add_trace(\n            go.Scatter3d(\n                x=proj_x, y=proj_y, z=proj_z,\n                mode='markers',\n                marker=dict(\n                    size=5, \n                    color='cyan', \n                    opacity=0.9,\n                    symbol='diamond'\n                ),\n                hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;',\n                hovertext=proj_hover,\n                name='On Plane S+T=40' \n            )\n        )\n\n    fig_single.update_layout(\n        title=dict(\n            text=f'3D Schedule Analysis: N={N_patients_single_case}, q={q_single_case:.2f}, w={w_single_case:.1f}&lt;br&gt;&lt;sub&gt;Optimal Objective Value: {min_obj_val_single:.4f}&lt;/sub&gt;',\n            x=0.5, font=dict(size=16)\n        ),\n        scene=dict(\n            xaxis_title='Start Count (Schedule[0])',\n            yaxis_title='Tail Count (Schedule[-1])',\n            zaxis_title='Objective Value',\n            camera=dict(eye=dict(x=-1.5, y=-1.5, z=1.5)),\n            xaxis=dict(range=[0, N_patients_single_case], autorange=False), \n            yaxis=dict(range=[0, N_patients_single_case], autorange=False)\n        ),\n        height=700, width=900,\n        showlegend=True,\n        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01, bgcolor=\"rgba(255,255,255,0.5)\") \n    )\n\nfig_single.show()\n\n\n\n\n                                                \n\n\nFigure 8.1: 3D chart for N=48, q=0.1, w=0.9, with projection on start_count + tail_count = 40. X-axis: Start Count, Y-axis: Tail Count, Z-axis: Objective Value.\nA function \\(f\\) is said to be integer convex if the following holds. For vectors \\(x\\) and \\(d\\) in \\(\\mathbb{Z}^T\\), we have \\[f(x + d) - f(x) \\geq f(x) - f(x-d).\\]\nLet \\(f\\) be multimodular: then it is integer convex (Altman, Gaujal, and Hordijk 2000).\nIn this case we are interested in the specific set of projections where the sum of the start count and tail count is equal to a target value.\nLet \\(m \\leq N\\) be a target value for the sum of the start count and tail count. We can generate a set of projections where the start count and tail count sum to \\(m\\) by starting with a schedule that has \\(m\\) patients in the first interval, \\(0\\) patients in the last interval, and evenly distributed patients in the center intervals. Then we can iteratively add the vector \\(v_0 = (-1, 0, \\ldots, 0, 1)\\) to this schedule until we’ve reached \\(m\\) iterations.\nBecause the function \\(f\\) is multimodular, the projections generated in this way will be integer convex.\nCode\ndef generate_schedules_w_equal_start_tail_sum(\n    target_sum: int,\n    N: int,\n    T: int,\n    d: int,\n    convolutions: Dict[int, np.ndarray],\n    w: float = 0.5\n) -&gt; List[Tuple[List[int], float]]:\n    \"\"\"\n    Generate filtered solution space projections based on a target sum for start_count + tail_count.\n    \n    Parameters:\n        target_sum (int): The target sum for start_count + tail_count.\n        N (int): Total number of patients.\n        T (int): Number of intervals\n        \n    Returns:\n        projections: Filtered projections as tuple of (schedule, objective).\n    \"\"\"\n    ## Validate inputs\n    if not isinstance(target_sum, int) or target_sum &lt; 0:\n        raise ValueError(\"target_sum must be a non-negative integer.\")\n    if not isinstance(N, int) or N &lt; 0:\n        raise ValueError(\"N must be a non-negative integer.\")\n    if not isinstance(T, int) or T &lt; 0:\n        raise ValueError(\"T must be a non-negative integer.\")\n      \n    ## Create v_star\n    v_star_matrix = get_v_star(T)\n    v_star_zero = v_star_matrix[0]  # Assuming we want the first row for T intervals\n    \n    ## Create center_schedule_segment\n    num_center_patients = N - target_sum # Patients in the center part. Must be non-negative.\n    num_center_intervals = T - 2 # Intervals available for the center part. Must be non-negative.\n    if num_center_patients &lt; 0 or num_center_intervals &lt; 0:\n        # print(f\"Warning: Invalid center part with N={N}, T={T}, target_sum={target_sum}. Skipping.\")\n        return []  # No valid projections if center part is negative\n    center_schedule_segment = generate_evenly_distributed_schedule_intervals(\n                num_center_patients,\n                num_center_intervals\n            )\n    # Create initial schedule\n    initial_schedule = [target_sum] + center_schedule_segment + [0]  # Start with target_sum, center part, and tail 0\n    ewt, esp = calculate_objective_serv_time_lookup(\n        initial_schedule, d, convolutions\n    )\n    initial_objective_value = w * ewt + (1 - w) * esp\n    obj_diff = None\n    projections = [(np.array(initial_schedule), initial_objective_value, obj_diff)]\n    for i in range(1, target_sum + 1):  # Iterate from 1 to target_sum\n        new_schedule = initial_schedule + v_star_zero  # Add v_star_zero to each interval\n        if np.any(new_schedule &lt; 0):\n            print(f\"\\nStopping at iteration {i}: Schedule became invalid with negative values.\")\n            print(f\"Invalid schedule: {new_schedule[:5]}...\")\n            break # Exit the loop\n        ewt, esp = calculate_objective_serv_time_lookup(\n        new_schedule, d, convolutions\n    )\n        new_objective_value = w * ewt + (1 - w) * esp\n        obj_diff = new_objective_value - initial_objective_value\n        projections.append((new_schedule, new_objective_value, obj_diff))\n        initial_schedule = new_schedule  # Update for next iteration\n        initial_objective_value = new_objective_value  # Update objective value for next iteration\n    \n    return projections\n  \n# Parameters for the new chart\ntarget_sum = 40\n# N_patients_single_case = 48\n# q_single_case = 0.2\n# w_single_case = 0.5\n# T_intervals is assumed to be the globally defined T_intervals = 48.\n# s_dist is assumed to be the globally computed service time distribution.\n# d_interval_len is assumed to be the globally defined d_interval_len = 10.\n\nconvolutions_projections = compute_convolutions(s_dist, N_patients_single_case, q_single_case)\nprojections_example = generate_schedules_w_equal_start_tail_sum(target_sum, N_patients_single_case, T_intervals, d_interval_len, convolutions_projections, w_single_case )\nCode\n# Extract data for plotting\nschedules = [p[0] for p in projections_example]\nobjectives = [p[1] for p in projections_example]\ndeltas = [p[2] for p in projections_example]\n# Replace None in deltas with 0 for plotting\ndeltas[0] = 0\n\n# Create the chart\nfig_projections = make_subplots(\n    rows=2, cols=1,\n    shared_xaxes=True,\n    vertical_spacing=0.1,\n    subplot_titles=(\"Objective Value per Schedule Iteration\", \"Change in Objective (Delta) per Iteration\")\n)\n\n# Add Objective Value trace\nfig_projections.add_trace(go.Scatter(\n    x=list(range(len(objectives))),\n    y=objectives,\n    mode='lines+markers',\n    name='Objective Value',\n    hovertemplate='&lt;b&gt;Iteration %{x}&lt;/b&gt;&lt;br&gt;Objective: %{y:.2f}&lt;br&gt;Schedule: %{customdata}&lt;extra&gt;&lt;/extra&gt;',\n    customdata=[str(s) for s in schedules],\n    marker=dict(color='royalblue')\n), row=1, col=1)\n\n# Add Delta trace\nfig_projections.add_trace(go.Bar(\n    x=list(range(len(deltas))),\n    y=deltas,\n    name='Objective Delta',\n    hovertemplate='&lt;b&gt;Iteration %{x}&lt;/b&gt;&lt;br&gt;Delta: %{y:.2f}&lt;extra&gt;&lt;/extra&gt;',\n    marker=dict(color='lightcoral')\n), row=2, col=1)\n\n# Update layout\nfig_projections.update_layout(\n    title_text='Analysis of Scheduling Projections',\n    height=600,\n    showlegend=False,\n    xaxis2_title='Schedule Iteration',\n    yaxis_title='Objective Value',\n    yaxis2_title='Objective Delta'\n)\n\nfig_projections.show()\nCode\ntarget_sum = max(0, N_patients_single_case - T_intervals + 2)  # Start from max(0, N - (T - 2)) to ensure non-negative start\nstop = 20\nlowest_objective_value = float('inf')  # Initialize to a very high value\nwhile target_sum &lt;= stop:\n  found_lower = False\n  num_center_patients = N_patients_single_case - target_sum # Patients in the center part\n  num_center_intervals = T_intervals - 2 # Intervals available for the center part\n\n  if num_center_patients &lt; 0: # Should not happen if generate_start_tail_distribution is correct\n      # print(f\"Warning: Negative center patients ({num_center_patients}) for start={start_count}, tail={tail_count}. Skipping.\")\n      continue\n  \n  if num_center_intervals &lt; 0:\n      if num_center_patients &gt; 0:\n          # print(f\"Warning: Cannot schedule {num_center_patients} center patients in {num_center_intervals} intervals. Skipping.\")\n          continue\n      # If num_center_patients is 0 and num_center_intervals is &lt; 0, center_schedule should be empty.\n      center_schedule_segment = []\n  elif num_center_patients == 0: # No patients for the center part\n       center_schedule_segment = [0] * num_center_intervals\n  else:\n      center_schedule_segment = generate_evenly_distributed_schedule_intervals(\n          num_center_patients,\n          num_center_intervals\n      )\n      # generate_evenly_distributed_schedule_intervals raises ValueError on failure\n      # so no need to check for None if its contract is maintained.\n  for s in range(target_sum + 1):\n    schedule_parts = [s]  # Start with the start count\n    t = target_sum - s\n    schedule_parts.extend(center_schedule_segment)\n    schedule_parts.append(t)\n    ewt, esp = calculate_objective_serv_time_lookup(\n        schedule_parts, d_interval_len, convolutions_projections\n    )\n    new_objective_value = w_single_case * ewt + (1 - w_single_case) * esp\n    if new_objective_value &lt; lowest_objective_value:\n        lowest_objective_value = new_objective_value\n        best_schedule = schedule_parts\n        print(f\"New lowest objective value found: {lowest_objective_value} for target_sum={target_sum}, schedule={schedule_parts}. Sum schedule={sum(schedule_parts)}\")\n        found_lower = True\n  if not found_lower:\n    print(f\"No lower objective value found for target_sum={target_sum}. Stopping search.\\nBest schedule so far: {best_schedule} with objective value {lowest_objective_value}\")\n    break \n  target_sum += 1\n\nv_star = get_v_star(T_intervals)\nx_star, c_star = local_search_w_timer(best_schedule, d_interval_len, convolutions_projections, w_single_case, v_star, T_intervals, time_limit = 60, echo = False)\nprint(f\"Final best schedule found: {x_star} with objective value {c_star}\")\n\n\nNew lowest objective value found: 610.7414651034273 for target_sum=2, schedule=[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]. Sum schedule=48\nNew lowest objective value found: 601.2200124412487 for target_sum=2, schedule=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]. Sum schedule=48\nNew lowest objective value found: 552.067758221272 for target_sum=3, schedule=[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]. Sum schedule=48\nNew lowest objective value found: 539.0106349729845 for target_sum=3, schedule=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]. Sum schedule=48\nNew lowest objective value found: 521.7818492537987 for target_sum=4, schedule=[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]. Sum schedule=48\nNew lowest objective value found: 503.8337332023074 for target_sum=4, schedule=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]. Sum schedule=48\nNew lowest objective value found: 491.6195604770515 for target_sum=5, schedule=[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 5]. Sum schedule=48\nNew lowest objective value found: 468.896345789976 for target_sum=5, schedule=[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 4]. Sum schedule=48\nNew lowest objective value found: 445.43078851790466 for target_sum=6, schedule=[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5]. Sum schedule=48\nNew lowest objective value found: 429.0491518636918 for target_sum=7, schedule=[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 6]. Sum schedule=48\nNew lowest objective value found: 425.2232819438275 for target_sum=8, schedule=[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 7]. Sum schedule=48\nNew lowest objective value found: 421.71302508065196 for target_sum=9, schedule=[2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 7]. Sum schedule=48\nNo lower objective value found for target_sum=10. Stopping search.\nBest schedule so far: [2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 7] with objective value 421.71302508065196\nFinal best schedule found: [2 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n 0 1 1 1 1 1 1 1 1 1 6] with objective value 418.7103167456375",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Filtered solution spaces for outpatient appointment scheduling</span>"
    ]
  },
  {
    "objectID": "filtered-solution-spaces.html#introduction",
    "href": "filtered-solution-spaces.html#introduction",
    "title": "8  Filtered solution spaces for outpatient appointment scheduling",
    "section": "",
    "text": "Generate a Service Time Distribution: Create a plausible distribution of patient service times with a target average, allowing for variability.\nConstruct Candidate Schedules: Systematically generate a variety of patient appointment schedules. The schedules explored here are characterized by a defined number of patients at the beginning (‘start’) and end (‘tail’) of the session, with the remaining patients distributed as evenly as possible across the central portion of the available time intervals. We will explore this fitered solution space.\nEvaluate Schedule Performance: For each generated schedule, calculate an objective function value. This objective is a weighted sum, reflecting the trade-off between minimizing expected patient waiting time (EWT) and minimizing expected service provider underutilization or overtime (ESP). This evaluation incorporates the probability of patient no-shows (q_no_show) and a user-defined weight (w_weight) to adjust the relative importance of EWT and ESP.\nVisualize and Analyze Results: Utilize interactive 3D visualizations to explore the solution space. This allows for the examination of how different parameters—such as the no-show probability (q), the objective function weight (w), and the total number of patients (N_patients)—influence the structure of optimal schedules and their corresponding objective values.\n\n\n\n\n\n\n\n\nCode\n# Create subplots with 3D scenes\nfig = make_subplots(\n    rows=3, cols=3,\n    specs=[[{'type': 'scatter3d'} for _ in range(3)] for _ in range(3)],\n    subplot_titles=[f'q={q:.2f}, w={w:.1f}' for w in w_values for q in q_values], # Placeholder titles\n    horizontal_spacing=0.02,\n    vertical_spacing=0.12\n)\n\n# Global color scale limits for consistency\nglobal_z_min = float('inf')\nglobal_z_max = float('-inf')\n\n# First pass: compute all data and find global min/max for consistent coloring\nall_data = {}\nfor i, w in enumerate(w_values):\n    for j, q in enumerate(q_values):\n        schedules, objective_values = compute_schedules_and_objectives(q, w, N_patients_fig1, T_intervals) # Pass N, T\n        all_data[(i, j)] = (schedules, objective_values)\n        if objective_values: # Check if list is not empty\n            global_z_min = min(global_z_min, min(objective_values))\n            global_z_max = max(global_z_max, max(objective_values))\n\n# Handle case where no objective values were found (e.g., all lists were empty)\nif global_z_min == float('inf'): global_z_min = 0\nif global_z_max == float('-inf'): global_z_max = 1\n\n\n# Second pass: create plots\nsubplot_titles_with_min_info = [] # To store titles with min objective info\nfor i, w in enumerate(w_values):\n    for j, q in enumerate(q_values):\n        schedules, objective_values = all_data[(i, j)]\n\n        current_title = f'q={q:.2f}, w={w:.1f}'\n        if not schedules or not objective_values:\n            subplot_titles_with_min_info.append(f'{current_title}&lt;br&gt;&lt;sub&gt;No data&lt;/sub&gt;')\n            # Add an empty trace or skip plotting for this subplot\n            fig.add_trace(go.Scatter3d(x=[], y=[], z=[]), row=i+1, col=j+1) # Add empty trace\n            continue\n\n        # Extract x, y, z coordinates for plotting\n        # x: value of the first element of the schedule (start_count)\n        # y: value of the last element of the schedule (tail_count)\n        # z: objective value\n        x_coords = [schedule[0] for schedule in schedules]\n        y_coords = [schedule[-1] for schedule in schedules] # schedule can be shorter than T_intervals if T_intervals &lt; 2\n        # Ensure y_coords access is safe if schedule can be very short (e.g. length 1)\n        y_coords = [(schedule[-1] if len(schedule)&gt;0 else 0) for schedule in schedules]\n\n\n        z_values = objective_values\n\n        # Find minimum point\n        min_obj_val = min(z_values)\n        min_index = z_values.index(min_obj_val)\n        # min_schedule_at_min_obj = schedules[min_index] # For debugging or detailed hover\n\n        subplot_titles_with_min_info.append(f'{current_title}&lt;br&gt;&lt;sub&gt;Min: {min_obj_val:.4f}&lt;/sub&gt;')\n\n        # Create hover text\n        schedules_wrapped = [textwrap.wrap(str(schedule), width=75) for schedule in schedules]\n        formatted_schedules_str = [\"&lt;br&gt;\".join(schedule_lines) for schedule_lines in schedules_wrapped]\n\n        hover_texts = [\n            f\"Sch: {f_sch_str}, N_sch: {sum(sch_list)}&lt;br&gt;Obj: {obj_val:.4f}&lt;br&gt;\"\n            for sch_list, f_sch_str, obj_val in zip(schedules, formatted_schedules_str, z_values)\n        ]\n\n        # Separate normal and minimum points for distinct plotting\n        normal_indices = [idx for idx in range(len(z_values)) if idx != min_index]\n        normal_x = [x_coords[idx] for idx in normal_indices]\n        normal_y = [y_coords[idx] for idx in normal_indices]\n        normal_z = [z_values[idx] for idx in normal_indices]\n        normal_hover = [hover_texts[idx] for idx in normal_indices]\n\n        min_x = [x_coords[min_index]]\n        min_y = [y_coords[min_index]]\n        min_z_val = [z_values[min_index]] # Renamed to avoid conflict\n        min_hover = [hover_texts[min_index]]\n\n        # Add normal points scatter plot\n        fig.add_trace(\n            go.Scatter3d(\n                x=normal_x,\n                y=normal_y,\n                z=normal_z,\n                mode='markers',\n                marker=dict(\n                    size=4,\n                    color=normal_z,          # Color by Z value (objective)\n                    colorscale='Viridis',\n                    opacity=0.7,\n                    cmin=global_z_min,       # Use global min for color scale\n                    cmax=global_z_max,       # Use global max for color scale\n                    colorbar=dict(title='Objective Value') if i == 0 and j == 2 else None, # Show colorbar once\n                    showscale=(i == 0 and j == 2) # Control visibility of the color bar\n                ),\n                name=f'Data (q={q:.2f}, w={w:.1f})', # Legend name (if legend shown)\n                hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;', # Custom hover text\n                hovertext=normal_hover,\n                showlegend=False\n            ),\n            row=i+1, col=j+1\n        )\n\n        # Add minimum point highlighted\n        fig.add_trace(\n            go.Scatter3d(\n                x=min_x,\n                y=min_y,\n                z=min_z_val,\n                mode='markers',\n                marker=dict(\n                    size=6,\n                    color='red',    # Distinct color for minimum point\n                    opacity=1.0\n                ),\n                name=f'Minimum (q={q:.2f}, w={w:.1f})', # Legend name\n                hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;', # Custom hover text\n                hovertext=min_hover,\n                showlegend=False\n            ),\n            row=i+1, col=j+1\n        )\n\n# Update subplot titles with the minimum objective information\nfor idx, title_text in enumerate(subplot_titles_with_min_info):\n    if idx &lt; len(fig.layout.annotations): # Safety check\n        fig.layout.annotations[idx].text = title_text\n\n# Update overall layout for the figure\nfig.update_layout(\n    title=dict(\n        text=f'3D Analysis: Schedule Optimization (N={N_patients_fig1})&lt;br&gt;&lt;sub&gt;Rows: w (weighting factor), Columns: q (no-show probability)&lt;/sub&gt;',\n        x=0.5, # Center title\n        y=0.98,\n        font=dict(size=16)\n    ),\n    height=1200,\n    width=1400,\n    margin=dict(t=100, b=100, l=50, r=50),\n    font=dict(size=10) # Default font size for other elements\n)\n\n# Update 3D scene properties for all subplots (axes titles, camera angle)\nfor r_idx_loop in range(1, 4): # 1-based for rows\n    for c_idx_loop in range(1, 4): # 1-based for columns\n        # Calculate scene name (e.g., 'scene', 'scene2', 'scene3', ..., 'scene9')\n        scene_num = (r_idx_loop - 1) * 3 + c_idx_loop\n        scene_name_key = f'scene{scene_num}' if scene_num &gt; 1 else 'scene'\n\n        fig.update_layout(**{\n            scene_name_key: dict(\n                xaxis_title='Start Count (Schedule[0])',\n                yaxis_title='Tail Count (Schedule[-1])',\n                zaxis_title='Objective Value',\n                camera=dict(eye=dict(x=-1.5, y=-1.5, z=1.5)), # Adjust camera view\n                xaxis=dict(range=[0, None]), # Ensure x-axis starts at 0\n                yaxis=dict(range=[0, None])  # Ensure y-axis starts at 0\n            )\n        })\n\nfig.show()\n\n\n                                                \n\n\n\n\n\n\nCode\n# --- Parameters and Setup for Figure 2 ---\nN_patients_fig2 = 48  # Update N_patients for the second figure\n# T_intervals, d_interval_len, max_s_time, l_target_avg_service_time, i_sorting_split\n# are assumed to be the same as for Figure 1.\n# `s_dist` is also assumed to be the same (re-used).\nif s_dist is None: # Recalculate if it wasn't set or if params changed\n    s_dist = generate_weighted_list(max_s_time, l_target_avg_service_time, i_sorting_split)\n    if s_dist is None:\n        raise ValueError(\"Failed to generate service time distribution for Figure 2.\")\n\n\nq_values_fig2 = [0.1, 0.2]\nw_values_fig2 = [0.1, 0.9]\n\n# --- Create 2x2 subplot grid for Figure 2 ---\nfig2 = make_subplots(\n    rows=len(w_values_fig2), cols=len(q_values_fig2),\n    specs=[[{'type': 'scatter3d'} for _ in range(len(q_values_fig2))] for _ in range(len(w_values_fig2))],\n    subplot_titles=[f'q={q_val:.2f}, w={w_val:.1f}' for w_val in w_values_fig2 for q_val in q_values_fig2], # Placeholder\n    horizontal_spacing=0.02,\n    vertical_spacing=0.12\n)\n\n# Global color scale limits for consistency in Figure 2\nglobal_z_min_fig2 = float('inf')\nglobal_z_max_fig2 = float('-inf')\n\n# First pass: compute all data for Figure 2 and find global min/max for consistent coloring\nall_data_fig2 = {}\nfor i, w in enumerate(w_values_fig2):\n    for j, q in enumerate(q_values_fig2):\n        schedules_fig2, objective_values_fig2 = compute_schedules_and_objectives(q, w, N_patients_fig2, T_intervals) # Use N_patients_fig2\n        all_data_fig2[(i, j)] = (schedules_fig2, objective_values_fig2)\n        if objective_values_fig2: # Ensure list is not empty\n            global_z_min_fig2 = min(global_z_min_fig2, min(objective_values_fig2))\n            global_z_max_fig2 = max(global_z_max_fig2, max(objective_values_fig2))\n        else:\n            print(f\"Warning: No objective values for Figure 2 with q={q}, w={w}, N_patients={N_patients_fig2}\")\n\nif global_z_min_fig2 == float('inf'): global_z_min_fig2 = 0 # Default if no data\nif global_z_max_fig2 == float('-inf'): global_z_max_fig2 = 1 # Default if no data\n\n\n# Second pass: create plots for Figure 2\nsubplot_titles_with_min_fig2 = []\nfor i, w in enumerate(w_values_fig2):\n    for j, q in enumerate(q_values_fig2):\n        schedules, objective_values = all_data_fig2[(i, j)]\n\n        current_title_fig2 = f'q={q:.2f}, w={w:.1f}'\n        if not schedules or not objective_values:\n            subplot_titles_with_min_fig2.append(f'{current_title_fig2}&lt;br&gt;&lt;sub&gt;No data&lt;/sub&gt;')\n            fig2.add_trace(go.Scatter3d(x=[], y=[], z=[]), row=i+1, col=j+1) # Add empty trace\n            continue\n\n        x_coords_fig2 = [schedule[0] for schedule in schedules]\n        y_coords_fig2 = [(schedule[-1] if len(schedule)&gt;0 else 0) for schedule in schedules] # Safe access\n        z_values_fig2 = objective_values\n\n        min_obj_fig2 = min(z_values_fig2)\n        min_index_fig2 = z_values_fig2.index(min_obj_fig2)\n\n        subplot_titles_with_min_fig2.append(f'{current_title_fig2}&lt;br&gt;&lt;sub&gt;Min: {min_obj_fig2:.4f}&lt;/sub&gt;')\n\n        schedules_wrapped_fig2 = [textwrap.wrap(str(schedule), width=75) for schedule in schedules]\n        formatted_schedules_str_fig2 = [\"&lt;br&gt;\".join(sl) for sl in schedules_wrapped_fig2]\n\n        hover_texts_fig2 = [\n            f\"Sch: {f_sch_str}, N_sch: {sum(sch_list)}&lt;br&gt;Obj: {obj_val:.4f}&lt;br&gt;\"\n            for sch_list, f_sch_str, obj_val in zip(schedules, formatted_schedules_str_fig2, z_values_fig2)\n        ]\n\n        normal_indices_fig2 = [idx for idx in range(len(z_values_fig2)) if idx != min_index_fig2]\n        normal_x_fig2 = [x_coords_fig2[idx] for idx in normal_indices_fig2]\n        normal_y_fig2 = [y_coords_fig2[idx] for idx in normal_indices_fig2]\n        normal_z_fig2 = [z_values_fig2[idx] for idx in normal_indices_fig2]\n        normal_hover_fig2 = [hover_texts_fig2[idx] for idx in normal_indices_fig2]\n\n        min_x_fig2 = [x_coords_fig2[min_index_fig2]]\n        min_y_fig2 = [y_coords_fig2[min_index_fig2]]\n        min_z_val_fig2 = [z_values_fig2[min_index_fig2]]\n        min_hover_fig2 = [hover_texts_fig2[min_index_fig2]]\n\n        fig2.add_trace(\n            go.Scatter3d(\n                x=normal_x_fig2, y=normal_y_fig2, z=normal_z_fig2, mode='markers',\n                marker=dict(\n                    size=4, color=normal_z_fig2, colorscale='Viridis', opacity=0.7,\n                    cmin=global_z_min_fig2, cmax=global_z_max_fig2,\n                    colorbar=dict(title='Objective Value') if i == 0 and j == (len(q_values_fig2) - 1) else None,\n                    showscale=(i == 0 and j == (len(q_values_fig2) - 1))\n                ),\n                name=f'Data (q={q:.2f}, w={w:.1f})',\n                hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;', hovertext=normal_hover_fig2, showlegend=False\n            ), row=i+1, col=j+1\n        )\n\n        fig2.add_trace(\n            go.Scatter3d(\n                x=min_x_fig2, y=min_y_fig2, z=min_z_val_fig2, mode='markers',\n                marker=dict(size=6, color='red', opacity=1.0),\n                name=f'Minimum (q={q:.2f}, w={w:.1f})',\n                hovertemplate='%{hovertext}&lt;extra&gt;&lt;/extra&gt;', hovertext=min_hover_fig2, showlegend=False\n            ), row=i+1, col=j+1\n        )\n\n# Update subplot titles for Figure 2\nfor idx, title_text in enumerate(subplot_titles_with_min_fig2):\n    if idx &lt; len(fig2.layout.annotations):\n        fig2.layout.annotations[idx].text = title_text\n\n# Update layout for Figure 2\nfig2.update_layout(\n    title=dict(\n        text=f'&lt;b&gt;Figure 2:&lt;/b&gt; N_patients={N_patients_fig2} - Schedule Optimization&lt;br&gt;&lt;sub&gt;Rows: w (weight), Columns: q (no-show probability)&lt;/sub&gt;',\n        x=0.5, y=0.98, font=dict(size=16)\n    ),\n    height=1000, width=1200,\n    margin=dict(t=100, b=100, l=50, r=50), font=dict(size=10)\n)\n\n# Update 3D scene properties for Figure 2\nnum_rows_fig2 = len(w_values_fig2)\nnum_cols_fig2 = len(q_values_fig2)\nfor r_loop_idx in range(num_rows_fig2):\n    for c_loop_idx in range(num_cols_fig2):\n        scene_idx_plotly = r_loop_idx * num_cols_fig2 + c_loop_idx + 1\n        scene_name_key_fig2 = f'scene{scene_idx_plotly}' if scene_idx_plotly &gt; 1 else 'scene'\n\n        fig2.update_layout(**{\n            scene_name_key_fig2: dict(\n                xaxis_title='Start Count (Schedule[0])',\n                yaxis_title='Tail Count (Schedule[-1])',\n                zaxis_title='Objective Value',\n                camera=dict(eye=dict(x=-1.5, y=-1.5, z=1.5)),\n                xaxis=dict(range=[0, None]),\n                yaxis=dict(range=[0, None])\n            )\n        })\n\nfig2.show()\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAltman, Eitan, Bruno Gaujal, and Arie Hordijk. 2000. “Multimodularity, Convexity, and Optimization Properties.” Mathematics of Operations Research 25 (2): 324–47. https://www.jstor.org/stable/3690584.\n\n\nKaandorp, Guido C., and Ger Koole. 2007. “Optimal Outpatient Appointment Scheduling.” Health Care Management Science 10 (3): 217–29. https://doi.org/10.1007/s10729-007-9015-x.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Filtered solution spaces for outpatient appointment scheduling</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "9  References",
    "section": "",
    "text": "References",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "service-time-with-no-shows.html",
    "href": "service-time-with-no-shows.html",
    "title": "service_time_with_no_shows",
    "section": "",
    "text": "Function Documentation\nservice_time_with_no_shows(s: List[float], q: float) -&gt; List[float]",
    "crumbs": [
      "Function documentation",
      "`service_time_with_no_shows`"
    ]
  },
  {
    "objectID": "service-time-with-no-shows.html#function-documentation",
    "href": "service-time-with-no-shows.html#function-documentation",
    "title": "service_time_with_no_shows",
    "section": "",
    "text": "Description\nAdjusts a distribution of service times to account for no-shows. The function scales the original service time distribution by the probability of a patient showing up (i.e., 1 - q) and then adds the no-show probability q to the service time for zero time slots.\n\n\nParameters\n\ns (List[float]): The original service time probability distribution. This list represents the probabilities associated with different service times.\nq (float): The probability of no-shows. This value should be between 0 and 1.\n\n\n\nReturns\n\nList[float]: The adjusted service time probability distribution where the no-show probability has been incorporated into the probability of zero service time.\n\n\n\nExample\n\nfrom functions import service_time_with_no_shows\n\n# Example usage\noriginal_distribution = [0.0, 0.5, 0.3, 0.2]\nno_show_probability = 0.1\nadjusted_distribution = service_time_with_no_shows(original_distribution, no_show_probability)\nprint(\"Adjusted distribution:\", adjusted_distribution)\n\nAdjusted distribution: [0.1, 0.45, 0.27, 0.18000000000000002]\n\n\n\nimport unittest\n\nclass TestServiceTimeWithNoShows(unittest.TestCase):\n    def test_adjust_distribution(self):\n        # Test with a known distribution and no-show probability\n        original_distribution = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.1\n        \n        # Expected adjustment: second element 0.1, \n        # other elements: multiplied by 0.9\n        expected_distribution = [0.1, 0.45, 0.27, 0.18]\n        \n        result = service_time_with_no_shows(original_distribution, no_show_probability)\n        \n        # Using almost equal check due to floating point arithmetic\n        for r, e in zip(result, expected_distribution):\n            self.assertAlmostEqual(r, e, places=5)\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n.\n----------------------------------------------------------------------\nRan 1 test in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`service_time_with_no_shows`"
    ]
  },
  {
    "objectID": "compute-convolutions.html",
    "href": "compute-convolutions.html",
    "title": "compute_convolutions",
    "section": "",
    "text": "Function Documentation\ncompute_convolutions(probabilities: List[float], N: int, q: float = 0.0) -&gt; Dict[int, np.ndarray]",
    "crumbs": [
      "Function documentation",
      "`compute_convolutions`"
    ]
  },
  {
    "objectID": "compute-convolutions.html#function-documentation",
    "href": "compute-convolutions.html#function-documentation",
    "title": "compute_convolutions",
    "section": "",
    "text": "Description\nComputes the k-fold convolution of a given probability mass function (PMF) for k from 1 up to N. Before computing the convolutions, the PMF is adjusted for no-shows using the provided no-show probability q via the service_time_with_no_shows function. Convolution is performed using NumPy’s np.convolve.\n\n\nParameters\n\nprobabilities (List[float]): The original PMF represented as a list where the index corresponds to a value (for instance, a service time) and the value at that index is its probability. This function is generic and does not have to be used solely for service times.\nN (int): The maximum number of convolutions to compute.\nq (float, optional): The probability of a no-show. Defaults to 0.0.\n\n\n\nReturns\n\nDict[int, np.ndarray]: A dictionary where each key k (with 1 ≤ k ≤ N) corresponds to the PMF resulting from the k-fold convolution of the adjusted PMF.\n\n\n\nExample\n\nimport numpy as np\nfrom functions import compute_convolutions, service_time_with_no_shows\n\n# Example usage\noriginal_pmf = [0.0, 0.5, 0.3, 0.2]\nN = 3\nno_show_probability = 0.1\n\nconvs = compute_convolutions(original_pmf, N, no_show_probability)\nfor k, pmf in convs.items():\n    print(f\"{k}-fold convolution: {pmf}\")\n\n1-fold convolution: [0.1  0.45 0.27 0.18]\n2-fold convolution: [0.01   0.09   0.2565 0.279  0.2349 0.0972 0.0324]\n3-fold convolution: [0.001    0.0135   0.06885  0.169425 0.234495 0.236925 0.160623 0.083106\n 0.026244 0.005832]\n\n\n\nimport unittest\n\nclass TestComputeConvolutions(unittest.TestCase):\n    def test_single_convolution(self):\n        # When N = 1, the result should be the adjusted PMF\n        original_pmf = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.1\n        N = 1\n        expected = np.array(service_time_with_no_shows(original_pmf, no_show_probability))\n        result = compute_convolutions(original_pmf, N, no_show_probability)\n        self.assertTrue(np.allclose(result[1], expected), \"Single convolution test failed\")\n\n    def test_multiple_convolutions(self):\n        # Test for N = 3 using a simple PMF\n        original_pmf = [0.0, 0.5, 0.3, 0.2]\n        no_show_probability = 0.0  # No adjustment for simplicity\n        N = 3\n        result = compute_convolutions(original_pmf, N, no_show_probability)\n\n        # For N=1, result is the original pmf\n        self.assertTrue(np.allclose(result[1], np.array(original_pmf)))\n\n        # For higher convolutions, ensure the sum of probabilities remains 1 (within numerical precision)\n        for k in range(1, N + 1):\n            self.assertAlmostEqual(np.sum(result[k]), 1.0, places=5, msg=f\"Sum of probabilities for {k}-fold convolution is not 1\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`compute_convolutions`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html",
    "href": "calculate-objective-serv-time-lookup.html",
    "title": "calculate_objective_serv_time_lookup",
    "section": "",
    "text": "Function Documentation\ncalculate_objective_serv_time_lookup(schedule: List[int], d: int, convolutions: dict) -&gt; Tuple[float, float]",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html#function-documentation",
    "href": "calculate-objective-serv-time-lookup.html#function-documentation",
    "title": "calculate_objective_serv_time_lookup",
    "section": "",
    "text": "Description\nThis notebook provides documentation for the function calculate_objective_serv_time_lookup, which calculates an objective value (in terms of expected waiting time and expected spillover) based on a given schedule and pre-computed convolutions of a probability mass function (PMF).\nThe function uses the following inputs:\n\nschedule: A list of integers representing the number of patients scheduled in each time slot.\nd: An integer indicating the duration threshold for a time slot.\nconvolutions: A dictionary of precomputed convolutions of the service time PMF. The key 1 should correspond to the adjusted service time distribution (for example, one adjusted for no-shows), while keys greater than 1 are used for multiple patients in a time slot.\n\nThe function returns a tuple:\n\newt: The sum of expected waiting times over the schedule.\nesp: The expected spillover time (or overtime) after the final time slot.",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "calculate-objective-serv-time-lookup.html#example-usage",
    "href": "calculate-objective-serv-time-lookup.html#example-usage",
    "title": "calculate_objective_serv_time_lookup",
    "section": "Example Usage",
    "text": "Example Usage\nA trivial example using a precomputed convolution dictionary with a degenerate PMF (i.e. always zero service time) is provided in the unit tests below.\n\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom functions import service_time_with_no_shows, compute_convolutions, calculate_objective_serv_time_lookup\n\n# For demonstration purposes, we use a trivial convolution dictionary.\noriginal_distribution = [0.0, 0.5, 0.3, 0.2]\nno_show_probability = 0.1\nadjusted_distribution = service_time_with_no_shows(original_distribution, no_show_probability)\nschedule_example = [2, 0, 0, 0, 0, 0, 1]\nN = sum(schedule_example)\nconvolutions_example = compute_convolutions(original_distribution, N, no_show_probability)\nd_example = 1\newt, esp = calculate_objective_serv_time_lookup(schedule_example, d_example, convolutions_example)\nprint(\"Adjusted Service Time Distribution: \", adjusted_distribution)\nprint(\"Expected Adjusted Service Time: \", np.dot(range(len(adjusted_distribution)), adjusted_distribution))\nprint(\"Expected Waiting Time:\", ewt)\nprint(\"Expected Spillover:\", esp)\n\nAdjusted Service Time Distribution:  [0.1, 0.45, 0.27, 0.18000000000000002]\nExpected Adjusted Service Time:  1.53\nExpected Waiting Time: 1.53\nExpected Spillover: 0.6300000000000001\n\n\n\nimport unittest\n\nclass TestCalculateObjectiveServTimeLookup(unittest.TestCase):\n    def setUp(self):\n        # Create a convolution dictionary\n        self.convolutions = convolutions_example\n        self.d = d_example\n\n    def test_single_time_slot(self):\n        # With one patient there will be no waiting and spillover (overtime) can be calculated by hand.\n        schedule = [1]\n        ewt, esp = calculate_objective_serv_time_lookup(schedule, self.d, self.convolutions)\n        self.assertAlmostEqual(ewt, 0.0, places=5, msg=\"Expected waiting time should be 0\")\n        self.assertAlmostEqual(esp, 0.6300000000000001, places=5, msg=\"Expected spillover should be 0\")\n\n    def test_zero_patients(self):\n        # If no patients are scheduled in a time slot, the process simply advances in time.\n        schedule = [0]\n        ewt, esp = calculate_objective_serv_time_lookup(schedule, self.d, self.convolutions)\n        self.assertAlmostEqual(ewt, 0.0, places=5, msg=\"Expected waiting time should be 0 when no patients\")\n        self.assertAlmostEqual(esp, 0.0, places=5, msg=\"Expected spillover should be 0 when no patients\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`calculate_objective_serv_time_lookup`"
    ]
  },
  {
    "objectID": "get-neighborhood.html",
    "href": "get-neighborhood.html",
    "title": "get_neighborhood",
    "section": "",
    "text": "Function Documentation\nget_neighborhood(x: Union[List[int], np.ndarray], v_star: np.ndarray, ids: List[List[int]], verbose: bool = False) -&gt; np.ndarray",
    "crumbs": [
      "Function documentation",
      "`get_neighborhood`"
    ]
  },
  {
    "objectID": "get-neighborhood.html#function-documentation",
    "href": "get-neighborhood.html#function-documentation",
    "title": "get_neighborhood",
    "section": "",
    "text": "Description\nThe get_neighborhood function computes a set of neighbor solutions by adding together selected rows from the array v_star to an initial solution vector x. The selection of rows is determined by the list of index lists ids, where each inner list represents a combination of indices. After generating the candidate neighbors, the function filters out any that contain negative values. An optional verbose flag provides debugging output during execution.\n\n\nParameters\n\nx (Union[List[int], np.ndarray]):\nThe current solution vector. Can be provided as a list of integers or as a NumPy array.\nv_star (np.ndarray):\nA 2D NumPy array where each row is an adjustment vector. These vectors are used to modify the current solution to explore its neighborhood.\nids (List[List[int]]):\nA list of index lists, where each inner list specifies which rows from v_star to sum together. Each combination represents a potential adjustment to the current solution.\nverbose (bool, optional):\nA flag indicating whether to print debugging information (e.g., intermediate computations, progress messages). Defaults to False.\n\n\n\nReturns\n\nnp.ndarray:\nA 2D NumPy array where each row is a neighbor solution (i.e., the result of adding a valid combination of adjustment vectors from v_star to x). Only neighbors with all non-negative entries are included in the output.\n\n\n\nExample\n\nimport numpy as np\nfrom functions import get_neighborhood, get_v_star, powerset\n\n# Define an initial solution vector\nx = [3, 2, 1]\n\n# Generate adjustment vectors using get_v_star\n# For instance, create a set of cyclic adjustment vectors of length 3\nv_star = get_v_star(3)\n\n# Generate combinations of indices (e.g., using a powerset for switching 1 patient)\nids = powerset(range(3), size=1)\n\n# Generate the neighborhood (neighbors with non-negative entries only)\nneighbors = get_neighborhood(x, v_star, ids, echo=True)\nprint(\"Neighbor solutions:\")\nprint(neighbors)\n\nPrinting every 50th result\nv_star[0]: [-1  0  1]\nx, x', delta:\n[3 2 1],\n[2 2 2],\n[-1  0  1]\n-----------------\nv_star[1]: [ 1 -1  0]\nv_star[2]: [ 0  1 -1]\nSize of raw neighborhood: 3\nFiltered out: 0 schedules with negative values.\nSize of filtered neighborhood: 3\nNeighbor solutions:\n[[2 2 2]\n [4 1 1]\n [3 3 0]]\n\n\n\nimport unittest\nimport numpy as np\nfrom functions import get_neighborhood, get_v_star, powerset\n\nclass TestGetNeighborhood(unittest.TestCase):\n    def test_non_negative_neighbors(self):\n        # Test with a simple solution vector and adjustment vectors\n        x = [3, 2, 1]\n        v_star = get_v_star(3)\n        ids = powerset(range(3), size=1)\n        \n        neighbors = get_neighborhood(x, v_star, ids, echo=False)\n        \n        # Ensure that no neighbor has negative entries\n        self.assertTrue(np.all(neighbors &gt;= 0), \"Some neighbor solutions contain negative values\")\n    \n    def test_neighborhood_shape(self):\n        # Test that the neighborhood returns a NumPy array with the proper dimensions\n        x = [3, 2, 1]\n        v_star = get_v_star(3)\n        ids = powerset(range(3), size=1)\n        neighbors = get_neighborhood(x, v_star, ids, echo=False)\n        self.assertIsInstance(neighbors, np.ndarray, \"Neighborhood is not a NumPy array\")\n        # The number of rows should equal the number of valid combinations in ids (after filtering negatives)\n        self.assertLessEqual(neighbors.shape[0], len(ids), \"Neighborhood size is larger than expected\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.001s\n\nOK",
    "crumbs": [
      "Function documentation",
      "`get_neighborhood`"
    ]
  },
  {
    "objectID": "local-search.html",
    "href": "local-search.html",
    "title": "local_search",
    "section": "",
    "text": "Function Documentation\nlocal_search(x: Union[List[int], np.ndarray], d: int, convolutions: Dict[int, np.ndarray], w: float, v_star: np.ndarray, size: int = 2, echo: bool = False) -&gt; Tuple[np.ndarray, float]",
    "crumbs": [
      "Function documentation",
      "`local_search`"
    ]
  },
  {
    "objectID": "local-search.html#function-documentation",
    "href": "local-search.html#function-documentation",
    "title": "local_search",
    "section": "",
    "text": "Description\nThe local_search function optimizes a schedule by iteratively exploring its neighborhood. Starting with an initial solution x, the function computes its objective value using the precomputed convolutions of the service time probability mass function. The neighborhood is generated by combining adjustment vectors from v_star (using a powerset-based approach) and filtering out candidates that contain negative values. The search continues until no further improvement is found for neighborhoods up to the specified size. The objective function combines expected average waiting time per patient and spillover time weighted by w.\n\n\nParameters\n\nx (Union[List[int], np.ndarray]):\nThe initial solution vector representing the schedule. It can be provided as a list of integers or as a NumPy array.\nd (int):\nThe duration threshold for a time slot. It is used to adjust the service process and waiting time distribution.\nconvolutions (Dict[int, np.ndarray]):\nA dictionary containing precomputed convolutions of the service time PMF. The key 1 represents the adjusted service time distribution, and other keys represent the convolution for the corresponding number of scheduled patients.\nw (float):\nThe weighting factor for combining the two performance objectives: expected waiting time and expected spillover time.\nv_star (np.ndarray):\nA 2D NumPy array of adjustment vectors. Each row in v_star is used to modify the current solution vector in order to generate its neighborhood.\nsize (int, optional):\nThe maximum number of patients to switch (i.e., the size of the neighborhood to explore) during the local search. Defaults to 2.\necho (bool, optional):\nA flag that, when set to True, prints progress and debugging messages during the search process. Defaults to False.\n\n\n\nReturns\n\nTuple[np.ndarray, float]:\nA tuple containing:\n\nThe best solution found as a 1D NumPy array.\nThe corresponding cost (objective value) as a float.\n\n\n\n\nExample\n\nimport numpy as np\nfrom functions import local_search, calculate_objective_serv_time_lookup, compute_convolutions, get_v_star, powerset\n\nfrom typing import List, Dict, Tuple, Union\n\ndef ways_to_distribute(N: int, T: int) -&gt; List[List[int]]:\n    \"\"\"\n    Compute all possible ways to distribute N identical items into T bins.\n    \n    Each distribution is represented as a list of T nonnegative integers whose sum is N.\n    \n    Parameters:\n        N (int): Total number of identical items.\n        T (int): Number of bins.\n        \n    Returns:\n        List[List[int]]: A list of distributions. Each distribution is a list of T integers that sum to N.\n        \n    Example:\n        &gt;&gt;&gt; ways_to_distribute(3, 2)\n        [[0, 3], [1, 2], [2, 1], [3, 0]]\n    \"\"\"\n    # Base case: only one bin left, all items must go into it.\n    if T == 1:\n        return [[N]]\n    \n    distributions = []\n    # Iterate over possible numbers of items in the first bin\n    for i in range(N + 1):\n        # Recursively distribute the remaining items among the remaining bins.\n        for distribution in ways_to_distribute(N - i, T - 1):\n            distributions.append([i] + distribution)\n            \n    return distributions\n  \ndef choose_best_solution(solutions: List[np.ndarray], d: int, convs: Dict[int, np.ndarray], w: float, v_star: np.ndarray) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"\n    Choose the best solution from a list of solutions based on the objective function.\n    \n    Parameters:\n        solutions (List[np.ndarray]): A list of solution vectors.\n        d (int): Duration threshold for a time slot.\n        convs (Dict[int, np.ndarray]): Precomputed convolutions of the service time PMF.\n        w (float): Weighting factor for the objective function.\n        \n    Returns:\n        Tuple[np.ndarray, float]: The best solution and its corresponding cost.\n    \"\"\"\n    best_solution = None\n    best_cost = float('inf')\n    \n    for solution in solutions:\n        waiting_time, spillover = calculate_objective_serv_time_lookup(solution, d, convs)\n        cost = w * waiting_time /N + (1 - w) * spillover\n        if cost &lt; best_cost:\n            best_solution = solution\n            best_cost = cost\n            \n    return np.array(best_solution), best_cost\n\n# Example schedule: initial solution vector\nx_initial = [3, 2, 1, 0]\nT = len(x_initial)\nN = sum(x_initial)\n\n# Duration threshold for a time slot\nd = 5\n\n# Example probability mass function and no-show probability\nservice_time = np.zeros(11)\nservice_time[3] = 0.2\nservice_time[5] = 0.3\nservice_time[8] = 0.5\nq = 0.1\n\n# Compute convolutions (precomputed service time distributions)\nconvs = compute_convolutions(service_time, N=N, q=q)\n\n# Weighting factor for the objective function\nw = 0.5\n\n# Generate adjustment vectors for the schedule (v_star)\nv_star = get_v_star(len(x_initial))\n\n# Perform local search to optimize the schedule\nbest_solution, best_cost = local_search(x_initial, d, convs, w, v_star, size=T, echo=True)\n\nprint(\"Best Solution:\", best_solution)\nprint(\"Best Cost:\", best_cost)\n\nInitial solution: [3 2 1 0], cost: 37.71594467672401\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 3\nFound better solution: [2 2 1 1], cost: 30.52386358592401\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nFound better solution: [1 2 1 2], cost: 25.53066071370001\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 6\nFound better solution: [1 1 1 3], cost: 22.474543162500005\nRunning local search with switching 1 patient(s)\nSize of neighborhood: 4\nRunning local search with switching 2 patient(s)\nSize of neighborhood: 6\nRunning local search with switching 3 patient(s)\nSize of neighborhood: 4\nBest Solution: [1 1 1 3]\nBest Cost: 22.474543162500005\n\n\n\nimport unittest\nimport numpy as np\nfrom functions import local_search, compute_convolutions, get_v_star\n\nclass TestLocalSearch(unittest.TestCase):\n    def test_local_search_improvement(self):\n        # Set up a simple test with a known schedule and parameters\n        x_initial = [3, 2, 1, 0]\n        T = len(x_initial)\n        N = sum(x_initial)\n        d = 5\n        service_time = np.zeros(11)\n        service_time[3] = 0.2\n        service_time[5] = 0.3\n        service_time[8] = 0.5\n        q = 0.1\n        convs = compute_convolutions(service_time, N=N, q=q)\n        w = 0.5\n        v_star = get_v_star(len(x_initial))\n        \n        # Perform local search\n        best_solution, best_cost = local_search(x_initial, d, convs, w, v_star, size=T, echo=False)\n        print(\"Best Solution:\", best_solution, \"Best Cost:\", best_cost)\n        \n        # Iterate over all solutions and choose best solution\n        solutions = ways_to_distribute(N, T)\n        best_solution_brute, best_cost_brute = choose_best_solution(solutions, d, convs, w, v_star)\n        print(\"Best Brute-force Solution:\", best_solution_brute, \"Best Brute-force Cost:\", best_cost_brute)\n        \n        # Verify that the local search solution is equal to the brute-force solution\n        self.assertTrue(np.array_equal(best_solution, best_solution_brute), \"The local search solution should match the brute-force solution.\")\n        \n        # Verify that the returned solution has the same length as the initial schedule\n        self.assertEqual(len(best_solution), len(x_initial), \"The optimized solution should have the same length as the initial solution.\")\n        \n        # Check that the cost is a float and that a solution is returned\n        self.assertIsInstance(best_cost, float, \"Cost should be a float value.\")\n\nif __name__ == '__main__':\n    unittest.main(argv=[''], exit=False)\n\nF\n======================================================================\nFAIL: test_local_search_improvement (__main__.TestLocalSearch.test_local_search_improvement)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/var/folders/gf/gtt1mww524x0q33rqlwsmjw80000gn/T/ipykernel_37119/3482521855.py\", line 31, in test_local_search_improvement\n    self.assertTrue(np.array_equal(best_solution, best_solution_brute), \"The local search solution should match the brute-force solution.\")\nAssertionError: False is not true : The local search solution should match the brute-force solution.\n\n----------------------------------------------------------------------\nRan 1 test in 0.010s\n\nFAILED (failures=1)\n\n\nInitial solution: [3 2 1 0], cost: 37.71594467672401\nBest Solution: [1 1 1 3] Best Cost: 22.474543162500005\nBest Brute-force Solution: [2 1 1 2] Best Brute-force Cost: 9.894705450000002",
    "crumbs": [
      "Function documentation",
      "`local_search`"
    ]
  }
]