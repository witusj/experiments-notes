{
  "hash": "c16ab387f3151298d5dd9d51965a6a84",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Preferential Bayesian Optimization for Outpatient Appointment Scheduling\nformat: html\nbibliography: references.bib\nwarning: false\n---\n\n## Objective\n\nThis experiment aims to apply Preferential Bayesian Optimization (PBO) to find optimal or near-optimal solutions for the outpatient appointment scheduling problem as defined by @kaandorp_optimal_2007. Specifically, the objective is to minimize a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP) by efficiently searching the space of schedule perturbations. The experiment leverages dictionary-based embeddings (HED) as proposed by @deshwal_bayesian_2023 to handle the high-dimensional combinatorial space of perturbation selection vectors within the PBO framework, drawing on the original preferential-BO formulation of @gonzalez_preferential_2017.\n\n## Background\n\nWe consider an outpatient appointment scheduling problem as described by @kaandorp_optimal_2007 where the schedule is represented by a vector $\\mathbf{x} = (x_0, x_1, \\ldots, x_{T-1})^T$. This vector comprises $T$ components, where $x_j$ denotes the non-negative allocation (number of patients) to time slot $j$, for $j = 0, \\ldots, T-1$. A fundamental constraint is that the total allocation across all time slots must equal a fixed constant $N$:\n\n$$\\sum_{j=0}^{T-1} x_j = N$$ where $N$ is the total number of patients to be scheduled. This constraint ensures that the schedule is feasible and respects the total patient load.\n\nWe require $x_j \\ge 0$ for all $j = 0, \\ldots, T-1$. Consequently, a valid schedule $\\mathbf{x}$ belongs to the feasible set $\\mathcal{F} = { \\mathbf{z} \\in \\mathbb{D}^{T} \\mid \\sum_{j=0}^{T-1} z_j = N, z_j \\ge 0 \\text{ for all } j}$, where $\\mathbb{D}$ is the set of non-negative integers ($\\mathbb{Z}\\_{\\ge 0}$)\n\n@kaandorp_optimal_2007 define a neighborhood structure for local search based on perturbation vectors derived from a set of $T$ basis change vectors, $v_i \\in \\mathbb{D}^{T}$, for $i = 0, \\ldots, T-1$. These basis vectors represent elementary shifts of allocation between time slots:\n\n-   $v\\_0 = (-1, 0, \\ldots, 0, 1)$ (Shift unit *from* slot 0 *to* slot $T-1$)\n-   $v\\_1 = (1, -1, 0, \\ldots, 0)$ (Shift unit *from* slot 1 *to* slot 0)\n-   $v\\_i = (0, \\ldots, 0, \\underbrace{1}*{\\text{pos } i-1}, \\underbrace{-1}*{\\text{pos } i}, 0, \\ldots, 0)$ for $i = 2, \\ldots, T-1$ (Shift unit *from* slot $i$ *to* slot $i-1$)\n\nA key property of these basis vectors is that the sum of components for each vector is zero: $\\sum_{j=0}^{T-1} v_{ij} = 0$ for all $i=0, \\ldots, T-1$.\n\nPerturbations are constructed using a binary selection vector $\\mathbf{U} = (u_0, u_1, \\ldots, u_{T-1})$, where $u_i \\in {0, 1}$. Each $u_i$ indicates whether the basis change $v_i$ is included in the perturbation. The resulting perturbation vector $\\mathbf{r}(\\mathbf{U}) \\in \\mathbb{D}^{T}$ is the linear combination:\n\n$$\n\\mathbf{r}(\\mathbf{U}) := \\sum_{i=0}^{T-1} u_i v_i\n$$\n\nSince each $v\\_i$ sums to zero, any perturbation $\\mathbf{r}(\\mathbf{U})$ also sums to zero: $\\sum\\_{j=0}^{T-1} r\\_j(\\mathbf{U}) = 0$. This ensures that applying such a perturbation to a valid schedule $\\mathbf{x}$ preserves the total allocation $N$.\n\nThe neighborhood of a schedule $\\mathbf{x} \\in \\mathcal{F}$, denoted by $\\mathcal{N}(\\mathbf{x})$, comprises all distinct, feasible schedules $\\mathbf{x}'$ reachable by applying a non-zero perturbation $\\mathbf{r}(\\mathbf{U})$ (@kaandorp_optimal_2007, use a slightly different but related neighborhood definition based on combinations of these basis vectors \\[cite: 89, 93, 1645\\]).\n\nThe objective function to be minimized is a weighted sum of Expected Waiting Time (EWT) and Expected Staff Penalty (ESP), as defined by @kaandorp_optimal_2007:\n\n$$\nC(\\mathbf{x}) = w \\cdot EWT(\\mathbf{x}) + (1-w) \\cdot ESP(\\mathbf{x})\n$$\n\n@kaandorp_optimal_2007 prove that this objective function is multimodular, which guarantees that a local search algorithm using their defined neighborhood converges to the global optimum.\n\nHowever, evaluating this function can be computationally expensive for large $N$ and $T$, and the search space of binary vectors $\\mathbf{U}$ is high-dimensional ($2^T - 2$ possibilities).\n\n**Dictionary‐Based Hamming Embeddings.** @deshwal_bayesian_2023 identify that directly modeling high-dimensional binary vectors with a Gaussian process is both statistically and computationally challenging, since the search space grows as $2^d$. They propose Hamming Embedding via Dictionaries (HED): choose a small set of $m$ “dictionary” vectors $\\{a_i\\}\\subset\\{0,1\\}^d$ and embed any candidate $z$ by its Hamming distances $\\phi_i(z)=\\mathrm{Hamming}(a_i,z)$. By using carefully constructed binary-wavelet (Hadamard) dictionaries, they both dramatically reduce input dimensionality $(m\\ll d)$ and obtain provable regret bounds $\\widetilde O(\\sqrt{Tm})$. Empirically on combinatorial tasks (e.g. MAX-SAT, feature selection, compiler flags), BO with HED (“BODi”) converges faster and to better optima than state-of-the-art discrete methods.\n\n**Preferential Bayesian Optimization.**\\\nGonzález et al. introduced the first PBO framework for optimizing a latent black-box function using only pairwise “duels.” They place a Gaussian-process prior over a latent utility function $f$, then squash it through a probit (or logistic) likelihood to model the probability $\\pi_f([x, x'])$ that $x$ is preferred to $x'$. From this they define acquisition functions—such as a Copeland-expected-improvement extension and a “dueling” Thompson–sampling rule—that balance exploration and exploitation by selecting the next pair $[x_t, x'_t]$ to query @gonzalez_preferential_2017.\n\nBecause the preferential likelihood is non-conjugate, each iteration requires expensive approximate inference (refitting the GP classification model) and an inner optimization over pairs to maximize the acquisition. Although sample-efficient (drastically reducing the number of duels needed to find the Condorcet winner), this per-step computational overhead motivates integrating faster surrogate updates or approximate acquisition schemes—exactly the gap our HED-based embedding approach helps address by reducing problem dimensionality before applying PBO.\n\n## Hypothesis\n\nBy applying PBO with HED embeddings and Thompson sampling, we expect to efficiently identify perturbation vectors $\\mathbf{U}$ that yield significantly improved schedules (lower cost) compared to random or simple local search heuristics.\n\n## Methodology\nWe are using Botorch for the PBO implementation [@balandat2020botorch].\n\n::: {#d10b8efb .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport numpy as np\nimport gpytorch\nfrom botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\nfrom botorch.fit import fit_gpytorch_mll\nfrom botorch.models.transforms.input import Normalize\nfrom scipy.linalg import hadamard\nfrom scipy.optimize import minimize\nimport random\nfrom typing import List, Tuple, Dict, Optional, Union\nimport plotly.graph_objects as go\n\nfrom functions import (\n    bailey_welch_schedule,\n    get_v_star,\n    compute_convolutions,\n    calculate_objective_serv_time_lookup,\n)\n```\n:::\n\n\n## Helper Functions\n\n::: {#afa55de9 .cell execution_count=2}\n``` {.python .cell-code}\n# --- Helper: generate_weighted_list ---\ndef generate_weighted_list(max_s: int, l: float, i: int) -> Optional[np.ndarray]:\n    if not isinstance(max_s, int) or max_s <= 0: return None\n    if not isinstance(l, (int, float)) or not (1 <= l <= max_s): return None\n    if not isinstance(i, int) or not (0 <= i < max_s): return None\n    def objective_fn(x: np.ndarray) -> float:\n        return (np.dot(np.arange(1, max_s + 1), x) - l) ** 2\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})\n    bounds = [(0, 1)] * max_s\n    initial_guess = np.random.dirichlet(np.ones(max_s))\n    try:\n        result = minimize(objective_fn, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints, options={'maxiter': 300, 'ftol': 1e-9})\n        if not result.success: return None\n        optimized_probs = result.x\n        optimized_probs[optimized_probs < 0] = 0\n        current_sum = np.sum(optimized_probs)\n        if not np.isclose(current_sum, 1.0):\n            if current_sum > 1e-8: optimized_probs /= current_sum\n            else: return None\n    except Exception: return None\n    first_part_probs = optimized_probs[:i] if i > 0 else np.array([])\n    second_part_probs = optimized_probs[i:]\n    values = np.zeros(max_s + 1)\n    if i > 0: values[1 : i + 1] = np.sort(first_part_probs)\n    values[i + 1 : max_s + 1] = np.sort(second_part_probs)[::-1]\n    final_sum = np.sum(values[1:])\n    if not np.isclose(final_sum, 1.0):\n        if final_sum > 1e-8: values[1:] /= final_sum\n        else: return None\n    return values\n```\n:::\n\n\n## Problem Setup\n\n::: {#159ab814 .cell execution_count=3}\n``` {.python .cell-code}\nN_patients = 50\nT_param = 48\nd_interval_len = 10\nmax_s_time = 30\nq_no_show = 0.20\nw_weight = 0.1\nl_target_avg_service_time = 14.0\ni_sorting_split = 10\n\nv_star_matrix = get_v_star(T_param)\ns_dist = generate_weighted_list(max_s_time, l_target_avg_service_time, i_sorting_split)\nif s_dist is None: raise ValueError(\"Failed to generate service time distribution.\")\nprint(f\"Service time distribution (s): {s_dist.tolist()}\")\n# Assuming s_dist is already defined\nfig = go.Figure(data=go.Bar(\n    x=np.arange(1, len(s_dist) + 1),\n    y=s_dist,\n    marker_line_width=1\n))\nfig.update_layout(\n    title=\"Service Time Distribution\",\n    xaxis_title=\"Service Time (units)\",\n    yaxis_title=\"Probability\",\n    template=\"plotly_white\"\n)\nfig.show()\nprint(f\"Average generated service time: {np.dot(np.arange(len(s_dist)), s_dist):.4f}\")\nconvolutions_dict = compute_convolutions(s_dist.tolist(), N_patients, q_no_show)\nX_initial_schedule = np.array(bailey_welch_schedule(T_param, d_interval_len, N_patients, s_dist))\nprint(f\"Initial base schedule (X_vec): {X_initial_schedule.tolist()}\")\nprint(f\"Sum of patients in X_vec: {np.sum(X_initial_schedule)}\")\nLARGE_PENALTY_VAL = 1e10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nService time distribution (s): [0.0, 0.004576792432933182, 0.005042754833603077, 0.00510307545664624, 0.009365073577823145, 0.017793365993912437, 0.034530092187205284, 0.03492180601649989, 0.03578220399497069, 0.03865742560006752, 0.24416921235311434, 0.1145286817062926, 0.0795910492783792, 0.05620985046099889, 0.05344068523775664, 0.039371833061619496, 0.03875094165247829, 0.03392828286917832, 0.027748450585691357, 0.022998750435874744, 0.01956125867973198, 0.017178944714080557, 0.0116561089768119, 0.009041365103306453, 0.008956037094145932, 0.00833595745483968, 0.00820748618716757, 0.007655975806650731, 0.007006783941681272, 0.00502165389736911, 0.0008681009882908807]\nAverage generated service time: 12.5292\nInitial base schedule (X_vec): [2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 11]\nSum of patients in X_vec: 50\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>                            <div id=\"d74eaa89-74c0-4695-8163-cfaa9074f44a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d74eaa89-74c0-4695-8163-cfaa9074f44a\")) {                    Plotly.newPlot(                        \"d74eaa89-74c0-4695-8163-cfaa9074f44a\",                        [{\"marker\":{\"line\":{\"width\":1}},\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"y\":[0.0,0.004576792432933182,0.005042754833603077,0.00510307545664624,0.009365073577823145,0.017793365993912437,0.034530092187205284,0.03492180601649989,0.03578220399497069,0.03865742560006752,0.24416921235311434,0.1145286817062926,0.0795910492783792,0.05620985046099889,0.05344068523775664,0.039371833061619496,0.03875094165247829,0.03392828286917832,0.027748450585691357,0.022998750435874744,0.01956125867973198,0.017178944714080557,0.0116561089768119,0.009041365103306453,0.008956037094145932,0.00833595745483968,0.00820748618716757,0.007655975806650731,0.007006783941681272,0.00502165389736911,0.0008681009882908807],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Service Time Distribution\"},\"xaxis\":{\"title\":{\"text\":\"Service Time (units)\"}},\"yaxis\":{\"title\":{\"text\":\"Probability\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('d74eaa89-74c0-4695-8163-cfaa9074f44a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>\n```\n:::\n:::\n\n\n## Objective Function\n\n::: {#2c48a17b .cell execution_count=4}\n``` {.python .cell-code}\ndef evaluate_objective(U_np: Union[np.ndarray, List[int]], X_vec: np.ndarray, v_star: np.ndarray,\n                       conv_dict: Dict[int, np.ndarray], d_len: int, w_val: float) -> float:\n    if not isinstance(U_np, np.ndarray): U_np = np.array(U_np, dtype=int)\n    if U_np.ndim != 1: raise ValueError(\"Input U must be 1-dimensional\")\n    if U_np.shape[0] != v_star.shape[0]: raise ValueError(f\"U length {U_np.shape[0]} != V* rows {v_star.shape[0]}.\")\n    if X_vec.shape[0] != v_star.shape[1]: raise ValueError(f\"X length {X_vec.shape[0]} != V* columns {v_star.shape[1]}.\")\n    if not np.all((U_np == 0) | (U_np == 1)): raise ValueError(\"Input U must be binary.\")\n    V_sum = np.sum(v_star[U_np == 1, :], axis=0)\n    Y_schedule = X_vec + V_sum\n    if np.all(Y_schedule >= 0) and np.sum(Y_schedule) == np.sum(X_vec):\n        ewt, esp = calculate_objective_serv_time_lookup(Y_schedule.tolist(), d_len, conv_dict)\n        return w_val * ewt + (1 - w_val) * esp\n    return LARGE_PENALTY_VAL\n\nU_zeros = np.zeros(T_param, dtype=int)\ninitial_obj_val = evaluate_objective(U_zeros, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\nprint(f\"Initial objective value (U=zeros): {initial_obj_val:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInitial objective value (U=zeros): 188.8749\n```\n:::\n:::\n\n\n## PBO Setup\n\n::: {#397e8a4a .cell execution_count=5}\n``` {.python .cell-code}\n# --- HED: Binary Wavelet Dictionary Construction ---\ndef get_binary_wavelet_dictionary(T_dim_U: int, m_dict_size: int) -> np.ndarray:\n    d_hadamard = 1\n    while d_hadamard < T_dim_U: d_hadamard *= 2\n    H = hadamard(d_hadamard)\n    if m_dict_size > d_hadamard: m_dict_size = d_hadamard\n    dictionary = np.zeros((m_dict_size, T_dim_U), dtype=int)\n    for i in range(m_dict_size):\n        dictionary[i, :] = (H[i, :T_dim_U] + 1) // 2\n    return dictionary\n\ndef embed_HED(U_np: np.ndarray, dictionary: np.ndarray) -> np.ndarray:\n    U_np_reshaped = U_np.reshape(1, -1) if U_np.ndim == 1 else U_np\n    hamming_distances = np.sum(dictionary != U_np_reshaped[:, np.newaxis, :], axis=2).T\n    return hamming_distances.flatten().astype(float) if U_np.ndim == 1 else hamming_distances.astype(float)\n\nm_dictionary_size = min(T_param * 2, 32 if T_param <=20 else 64)\nhed_dictionary = get_binary_wavelet_dictionary(T_param, m_dictionary_size)\nprint(f\"HED dictionary shape: {hed_dictionary.shape}\")\n\nnum_total_initial_pairs = 10\nnum_initial_U_zeros_comparisons = 3 # Number of times to compare U_zeros with random U\nnum_purely_random_initial_pairs = num_total_initial_pairs - num_initial_U_zeros_comparisons\n\nnum_pbo_iterations = 50\nn_candidates_for_thompson = 200\nn_thompson_posterior_samples = 20\n\nall_U_vectors_list = []\nall_U_embeddings_tensor = None\ncomparison_pairs_indices = []\n\ndef add_U_to_master_list(U_np: np.ndarray, embedding: np.ndarray) -> int:\n    global all_U_vectors_list, all_U_embeddings_tensor\n    U_np = U_np.astype(int) # Ensure consistent type\n    for i, existing_U_np_item in enumerate(all_U_vectors_list):\n        if np.array_equal(existing_U_np_item, U_np): return i\n    new_index = len(all_U_vectors_list)\n    all_U_vectors_list.append(U_np.copy())\n    if embedding.ndim > 1: embedding = embedding.flatten()\n    embedding_tensor = torch.from_numpy(embedding).double().unsqueeze(0)\n    if all_U_embeddings_tensor is None: all_U_embeddings_tensor = embedding_tensor\n    else: all_U_embeddings_tensor = torch.cat([all_U_embeddings_tensor, embedding_tensor], dim=0)\n    return new_index\n\ndef generate_random_U_vector(dim: int) -> np.ndarray:\n    return np.random.randint(0, 2, size=dim, dtype=int)\n\ndef get_hamming_neighbors(U_vector: np.ndarray, num_neighbors: int, max_flips: int = 1) -> List[np.ndarray]:\n    neighbors = []\n    dim = len(U_vector)\n    if dim == 0: return []\n    for _ in range(num_neighbors):\n        neighbor = U_vector.copy()\n        actual_flips = np.random.randint(1, max_flips + 1)\n        flip_indices = np.random.choice(dim, size=min(actual_flips, dim), replace=False)\n        for idx in flip_indices: neighbor[idx] = 1 - neighbor[idx]\n        neighbors.append(neighbor)\n    return neighbors\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHED dictionary shape: (64, 48)\n```\n:::\n:::\n\n\n## PBO Initialization\n\n::: {#cef7e16e .cell execution_count=6}\n``` {.python .cell-code}\nprint(\"Starting PBO Initialization...\")\nbest_U_overall = U_zeros.copy() # Start with U_zeros as initial best\nbest_obj_overall = initial_obj_val\nbest_iter_found = 0 # 0 for initial U_zeros evaluation\n\n# Add U_zeros to the master list first\nidx_U_zeros = add_U_to_master_list(U_zeros, embed_HED(U_zeros, hed_dictionary))\nobj_U_zeros = initial_obj_val # Already calculated\n\n# --- Initial comparisons involving U_zeros ---\nprint(f\"Generating {num_initial_U_zeros_comparisons} initial comparisons involving U_zeros...\")\nfor i in range(num_initial_U_zeros_comparisons):\n    U_competitor = generate_random_U_vector(T_param)\n    attempts = 0\n    while np.array_equal(U_competitor, U_zeros) and attempts < 100: # Avoid comparing U_zeros to itself\n        U_competitor = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_competitor, U_zeros): continue\n\n    obj_competitor = evaluate_objective(U_competitor, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"  Init U_zeros vs U_rand_{i}: Obj_U_zeros={obj_U_zeros:.4f}, Obj_U_rand={obj_competitor:.4f}\")\n\n    if obj_competitor < best_obj_overall:\n        best_obj_overall = obj_competitor\n        best_U_overall = U_competitor.copy()\n        best_iter_found = 0 # Still initialization phase\n\n    idx_competitor = add_U_to_master_list(U_competitor, embed_HED(U_competitor, hed_dictionary))\n    \n    if not np.isclose(obj_U_zeros, obj_competitor):\n        pref_pair = None\n        if obj_U_zeros < obj_competitor: pref_pair = [idx_U_zeros, idx_competitor]\n        elif obj_competitor < obj_U_zeros: pref_pair = [idx_competitor, idx_U_zeros]\n        \n        if pref_pair and pref_pair not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair)\n\n# --- Purely random initial comparisons (excluding U_zeros unless randomly picked again) ---\nprint(f\"Generating {num_purely_random_initial_pairs} purely random initial comparisons...\")\nfor i in range(num_purely_random_initial_pairs):\n    U_A = generate_random_U_vector(T_param)\n    U_B = generate_random_U_vector(T_param)\n    attempts = 0\n    while np.array_equal(U_A, U_B) and attempts < 100:\n        U_B = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_A, U_B): continue\n\n    obj_A = evaluate_objective(U_A, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    obj_B = evaluate_objective(U_B, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"  Init U_randA_{i} vs U_randB_{i}: Obj_A={obj_A:.4f}, Obj_B={obj_B:.4f}\")\n\n\n    if obj_A < best_obj_overall: best_obj_overall = obj_A; best_U_overall = U_A.copy(); best_iter_found = 0\n    if obj_B < best_obj_overall: best_obj_overall = obj_B; best_U_overall = U_B.copy(); best_iter_found = 0\n\n    idx_A = add_U_to_master_list(U_A, embed_HED(U_A, hed_dictionary))\n    idx_B = add_U_to_master_list(U_B, embed_HED(U_B, hed_dictionary))\n    \n    if not np.isclose(obj_A, obj_B):\n        pref_pair = None\n        if obj_A < obj_B: pref_pair = [idx_A, idx_B]\n        elif obj_B < obj_A: pref_pair = [idx_B, idx_A]\n\n        if pref_pair and pref_pair not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair)\n\nprint(f\"Initialization complete. Observed {len(all_U_vectors_list)} unique schedules.\")\nprint(f\"Number of preference pairs: {len(comparison_pairs_indices)}\")\nif best_U_overall is not None:\n    print(f\"Best U after initialization: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStarting PBO Initialization...\nGenerating 3 initial comparisons involving U_zeros...\n  Init U_zeros vs U_rand_0: Obj_U_zeros=188.8749, Obj_U_rand=10000000000.0000\n  Init U_zeros vs U_rand_1: Obj_U_zeros=188.8749, Obj_U_rand=10000000000.0000\n  Init U_zeros vs U_rand_2: Obj_U_zeros=188.8749, Obj_U_rand=10000000000.0000\nGenerating 7 purely random initial comparisons...\n  Init U_randA_0 vs U_randB_0: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_1 vs U_randB_1: Obj_A=10000000000.0000, Obj_B=208.5125\n  Init U_randA_2 vs U_randB_2: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_3 vs U_randB_3: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_4 vs U_randB_4: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_5 vs U_randB_5: Obj_A=10000000000.0000, Obj_B=10000000000.0000\n  Init U_randA_6 vs U_randB_6: Obj_A=10000000000.0000, Obj_B=10000000000.0000\nInitialization complete. Observed 18 unique schedules.\nNumber of preference pairs: 4\nBest U after initialization: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 188.8749\n```\n:::\n:::\n\n\n## PBO Loop\n\n::: {#00c3e921 .cell execution_count=7}\n``` {.python .cell-code}\nimport time\n\n# Start timer for PBO loop\nstart_time = time.time()\n\npairwise_model = None\n\nfor pbo_iter in range(num_pbo_iterations):\n    print(f\"\\n--- PBO Iteration {pbo_iter + 1}/{num_pbo_iterations} ---\")\n    if len(comparison_pairs_indices) < 1 or all_U_embeddings_tensor is None or all_U_embeddings_tensor.shape[0] < 2:\n        print(\"Not enough data for GP. Generating a random pair to add to comparisons.\")\n        # (Simplified fallback: add one random comparison)\n        U_A_fallback = generate_random_U_vector(T_param)\n        U_B_fallback = generate_random_U_vector(T_param)\n        attempts = 0\n        while np.array_equal(U_A_fallback, U_B_fallback) and attempts < 100:\n            U_B_fallback = generate_random_U_vector(T_param)\n            attempts += 1\n        if np.array_equal(U_A_fallback, U_B_fallback):\n            continue\n\n        obj_A_fb = evaluate_objective(U_A_fallback, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n        obj_B_fb = evaluate_objective(U_B_fallback, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n        if obj_A_fb < best_obj_overall:\n            best_obj_overall = obj_A_fb\n            best_U_overall = U_A_fallback.copy()\n            best_iter_found = pbo_iter + 1\n        if obj_B_fb < best_obj_overall:\n            best_obj_overall = obj_B_fb\n            best_U_overall = U_B_fallback.copy()\n            best_iter_found = pbo_iter + 1\n\n        idx_A_fb = add_U_to_master_list(U_A_fallback, embed_HED(U_A_fallback, hed_dictionary))\n        idx_B_fb = add_U_to_master_list(U_B_fallback, embed_HED(U_B_fallback, hed_dictionary))\n        if not np.isclose(obj_A_fb, obj_B_fb):\n            pref_pair_fb = [idx_A_fb, idx_B_fb] if obj_A_fb < obj_B_fb else [idx_B_fb, idx_A_fb]\n            if pref_pair_fb not in comparison_pairs_indices:\n                comparison_pairs_indices.append(pref_pair_fb)\n        if len(comparison_pairs_indices) < 1 or all_U_embeddings_tensor.shape[0] < 2:\n            continue\n\n    train_X_gp = all_U_embeddings_tensor.double()\n    train_Y_gp = torch.tensor(comparison_pairs_indices, dtype=torch.long)\n    min_bounds = torch.zeros(train_X_gp.shape[-1], dtype=torch.double)\n    max_bounds = torch.full((train_X_gp.shape[-1],), float(T_param), dtype=torch.double)\n    input_transform = Normalize(d=train_X_gp.shape[-1], bounds=torch.stack([min_bounds, max_bounds]))\n\n    pairwise_model = PairwiseGP(\n        train_X_gp,\n        train_Y_gp,\n        input_transform=input_transform,\n        covar_module=gpytorch.kernels.ScaleKernel(\n            gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=train_X_gp.shape[-1])\n        )\n    )\n    mll = PairwiseLaplaceMarginalLogLikelihood(pairwise_model.likelihood, pairwise_model)\n\n    U_query1, U_query2 = None, None\n    try:\n        fit_gpytorch_mll(mll)\n        U_cand_pool_list = []\n        for _ in range(n_candidates_for_thompson // 2):\n            U_cand_pool_list.append(generate_random_U_vector(T_param))\n        if best_U_overall is not None:\n            U_cand_pool_list.extend(\n                get_hamming_neighbors(best_U_overall, n_candidates_for_thompson // 2, max_flips=2)\n            )\n        else:\n            for _ in range(n_candidates_for_thompson // 2):\n                U_cand_pool_list.append(generate_random_U_vector(T_param))\n\n        unique_U_cand_tuples = {tuple(u.tolist()) for u in U_cand_pool_list}\n        U_cand_pool_np = np.array([list(t) for t in unique_U_cand_tuples], dtype=int)\n        if len(U_cand_pool_np) == 0:\n            raise ValueError(\"Candidate pool is empty.\")\n\n        embedded_candidates_np = np.array([embed_HED(u, hed_dictionary) for u in U_cand_pool_np])\n        embedded_candidates_torch = torch.from_numpy(embedded_candidates_np).double()\n\n        pairwise_model.eval()\n        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n            posterior_f = pairwise_model.posterior(input_transform(embedded_candidates_torch))\n            f_samples = posterior_f.sample(torch.Size([n_thompson_posterior_samples]))\n\n        best_indices_per_sample = torch.argmax(f_samples, dim=1)\n        query_idx1_in_cand_pool = best_indices_per_sample[0].item()\n        U_query1 = U_cand_pool_np[query_idx1_in_cand_pool]\n        query_idx2_in_cand_pool = -1\n\n        if len(U_cand_pool_np) > 1:\n            if len(best_indices_per_sample) > 1:\n                for i in range(1, len(best_indices_per_sample)):\n                    if best_indices_per_sample[i].item() != query_idx1_in_cand_pool:\n                        query_idx2_in_cand_pool = best_indices_per_sample[i].item()\n                        break\n            if (\n                query_idx2_in_cand_pool == -1\n                or query_idx1_in_cand_pool == query_idx2_in_cand_pool\n            ):\n                rand_indices = np.arange(len(U_cand_pool_np))\n                np.random.shuffle(rand_indices)\n                for rand_idx in rand_indices:\n                    if rand_idx != query_idx1_in_cand_pool:\n                        query_idx2_in_cand_pool = rand_idx\n                        break\n                U_query2 = (\n                    U_cand_pool_np[query_idx2_in_cand_pool]\n                    if query_idx2_in_cand_pool != -1\n                    else generate_random_U_vector(T_param)\n                )\n            else:\n                U_query2 = U_cand_pool_np[query_idx2_in_cand_pool]\n        else:\n            U_query2 = generate_random_U_vector(T_param)\n    except Exception as e:\n        print(f\"Error in GP/TS: {e}. Falling back to random.\")\n        U_query1 = generate_random_U_vector(T_param)\n        U_query2 = generate_random_U_vector(T_param)\n\n    attempts = 0\n    while np.array_equal(U_query1, U_query2) and attempts < 100:\n        U_query2 = generate_random_U_vector(T_param)\n        attempts += 1\n    if np.array_equal(U_query1, U_query2):\n        continue\n\n    obj_q1 = evaluate_objective(\n        U_query1,\n        X_initial_schedule,\n        v_star_matrix,\n        convolutions_dict,\n        d_interval_len,\n        w_weight,\n    )\n    obj_q2 = evaluate_objective(\n        U_query2,\n        X_initial_schedule,\n        v_star_matrix,\n        convolutions_dict,\n        d_interval_len,\n        w_weight,\n    )\n    print(f\"  Query 1 (U): {U_query1.tolist()}, Obj: {obj_q1:.4f}\")\n    print(f\"  Query 2 (U): {U_query2.tolist()}, Obj: {obj_q2:.4f}\")\n\n    if obj_q1 < best_obj_overall:\n        best_obj_overall = obj_q1\n        best_U_overall = U_query1.copy()\n        best_iter_found = pbo_iter + 1\n        print(\n            f\"  New best U from Q1: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f} (Iter: {best_iter_found})\"\n        )\n    if obj_q2 < best_obj_overall:\n        best_obj_overall = obj_q2\n        best_U_overall = U_query2.copy()\n        best_iter_found = pbo_iter + 1\n        print(\n            f\"  New best U from Q2: {best_U_overall.tolist()}, Obj: {best_obj_overall:.4f} (Iter: {best_iter_found})\"\n        )\n\n    idx_q1 = add_U_to_master_list(\n        U_query1, embed_HED(U_query1, hed_dictionary)\n    )\n    idx_q2 = add_U_to_master_list(\n        U_query2, embed_HED(U_query2, hed_dictionary)\n    )\n\n    if not np.isclose(obj_q1, obj_q2):\n        pref_pair_iter = [idx_q1, idx_q2] if obj_q1 < obj_q2 else [idx_q2, idx_q1]\n        print(f\"  Preference: {'Q1 > Q2' if obj_q1 < obj_q2 else 'Q2 > Q1'}\")\n        if pref_pair_iter not in comparison_pairs_indices:\n            comparison_pairs_indices.append(pref_pair_iter)\n        else:\n            print(\"  (Preference already recorded)\")\n    else:\n        print(\"  Preference: Tie\")\n    print(f\"  Total unique Us: {len(all_U_vectors_list)}, Total preference pairs: {len(comparison_pairs_indices)}\")\n\nprint(\"\\n--- PBO Experiment Finished ---\")\nif best_U_overall is not None:\n    print(f\"Best U vector found (by direct evaluation): {best_U_overall.tolist()}\")\n    final_Y_schedule = X_initial_schedule + np.sum(v_star_matrix[best_U_overall == 1, :], axis=0)\n    print(f\"Corresponding Y schedule: {final_Y_schedule.tolist()}\")\n    print(f\"Objective value: {best_obj_overall:.4f}\")\n    iter_str = \"during initialization (before PBO iterations)\" if best_iter_found == 0 else f\"at PBO iteration {best_iter_found}\"\n    print(f\"Found {iter_str}\")\n    print(f\"Patient count in final Y schedule: {np.sum(final_Y_schedule)}\")\nelse: print(\"No valid U vector found.\")\n\nif pairwise_model is not None and all_U_embeddings_tensor is not None and len(all_U_embeddings_tensor) > 0:\n    pairwise_model.eval()\n    transformed_all_U_embeddings = input_transform(all_U_embeddings_tensor)\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n        posterior_f_all = pairwise_model.posterior(transformed_all_U_embeddings)\n        mean_f_all = posterior_f_all.mean\n    best_idx_model = torch.argmax(mean_f_all).item()\n    U_reco_model = all_U_vectors_list[best_idx_model]\n    obj_reco_model = evaluate_objective(U_reco_model, X_initial_schedule, v_star_matrix, convolutions_dict, d_interval_len, w_weight)\n    print(f\"\\nRecommendation based on GP model (highest posterior mean utility over all {len(all_U_vectors_list)} evaluated Us):\")\n    print(f\"  U vector: {U_reco_model.tolist()}\")\n    Y_reco = X_initial_schedule + np.sum(v_star_matrix[U_reco_model == 1, :], axis=0)\n    print(f\"  Corresponding Y schedule: {Y_reco.tolist()}\")\n    print(f\"  Objective value of this GP recommended U: {obj_reco_model:.4f}\")\n    print(f\"  GP's posterior mean utility for this U: {mean_f_all[best_idx_model].item():.4f}\")\nelse: print(\"\\nGP model not available for recommendation.\")\n\n# End of PBO loop\nend_time = time.time()\nelapsed = end_time - start_time\nprint(f\"\\n--- PBO Experiment Finished in {elapsed:.2f} seconds ---\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n--- PBO Iteration 1/50 ---\n  Query 1 (U): [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 20, Total preference pairs: 4\n\n--- PBO Iteration 2/50 ---\n  Query 1 (U): [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 22, Total preference pairs: 4\n\n--- PBO Iteration 3/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.7302\n  Query 2 (U): [1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 24, Total preference pairs: 5\n\n--- PBO Iteration 4/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 190.5780\n  Query 2 (U): [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 26, Total preference pairs: 6\n\n--- PBO Iteration 5/50 ---\n  Query 1 (U): [0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.6442\n  Preference: Q2 > Q1\n  Total unique Us: 28, Total preference pairs: 7\n\n--- PBO Iteration 6/50 ---\n  Query 1 (U): [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 30, Total preference pairs: 7\n\n--- PBO Iteration 7/50 ---\n  Query 1 (U): [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 32, Total preference pairs: 7\n\n--- PBO Iteration 8/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 188.9738\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.5868\n  Preference: Q1 > Q2\n  Total unique Us: 34, Total preference pairs: 8\n\n--- PBO Iteration 9/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 36, Total preference pairs: 8\n\n--- PBO Iteration 10/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 188.9738\n  Query 2 (U): [0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 37, Total preference pairs: 9\n\n--- PBO Iteration 11/50 ---\n  Query 1 (U): [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.1779\n  Preference: Q2 > Q1\n  Total unique Us: 39, Total preference pairs: 10\n\n--- PBO Iteration 12/50 ---\n  Query 1 (U): [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], Obj: 189.5561\n  Preference: Q2 > Q1\n  Total unique Us: 41, Total preference pairs: 11\n\n--- PBO Iteration 13/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.7954\n  Query 2 (U): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 43, Total preference pairs: 12\n\n--- PBO Iteration 14/50 ---\n  Query 1 (U): [0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], Obj: 189.6911\n  Preference: Q2 > Q1\n  Total unique Us: 45, Total preference pairs: 13\n\n--- PBO Iteration 15/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 188.5505\n  Query 2 (U): [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0], Obj: 10000000000.0000\n  New best U from Q1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 188.5505 (Iter: 15)\n  Preference: Q1 > Q2\n  Total unique Us: 47, Total preference pairs: 14\n\n--- PBO Iteration 16/50 ---\n  Query 1 (U): [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 189.1042\n  Preference: Q2 > Q1\n  Total unique Us: 49, Total preference pairs: 15\n\n--- PBO Iteration 17/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Obj: 189.7313\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 51, Total preference pairs: 16\n\n--- PBO Iteration 18/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 53, Total preference pairs: 16\n\n--- PBO Iteration 19/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.1829\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 10000000000.0000\n  New best U from Q1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.1829 (Iter: 19)\n  Preference: Q1 > Q2\n  Total unique Us: 55, Total preference pairs: 17\n\n--- PBO Iteration 20/50 ---\n  Query 1 (U): [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1], Obj: 207.3972\n  Query 2 (U): [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 57, Total preference pairs: 18\n\n--- PBO Iteration 21/50 ---\n  Query 1 (U): [1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.8181\n  Preference: Q2 > Q1\n  Total unique Us: 59, Total preference pairs: 19\n\n--- PBO Iteration 22/50 ---\n  Query 1 (U): [1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 61, Total preference pairs: 19\n\n--- PBO Iteration 23/50 ---\n  Query 1 (U): [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 187.3640\n  New best U from Q2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 187.3640 (Iter: 23)\n  Preference: Q2 > Q1\n  Total unique Us: 63, Total preference pairs: 20\n\n--- PBO Iteration 24/50 ---\n  Query 1 (U): [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 65, Total preference pairs: 20\n\n--- PBO Iteration 25/50 ---\n  Query 1 (U): [0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.4277\n  Preference: Q2 > Q1\n  Total unique Us: 67, Total preference pairs: 21\n\n--- PBO Iteration 26/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 187.3268\n  Query 2 (U): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 187.6287\n  New best U from Q1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 187.3268 (Iter: 26)\n  Preference: Q1 > Q2\n  Total unique Us: 69, Total preference pairs: 22\n\n--- PBO Iteration 27/50 ---\n  Query 1 (U): [0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 188.6286\n  Preference: Q2 > Q1\n  Total unique Us: 71, Total preference pairs: 23\n\n--- PBO Iteration 28/50 ---\n  Query 1 (U): [0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 188.6286\n  Preference: Q2 > Q1\n  Total unique Us: 72, Total preference pairs: 24\n\n--- PBO Iteration 29/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 74, Total preference pairs: 24\n\n--- PBO Iteration 30/50 ---\n  Query 1 (U): [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 76, Total preference pairs: 24\n\n--- PBO Iteration 31/50 ---\n  Query 1 (U): [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.8678\n  Preference: Q2 > Q1\n  Total unique Us: 78, Total preference pairs: 25\n\n--- PBO Iteration 32/50 ---\n  Query 1 (U): [0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 80, Total preference pairs: 25\n\n--- PBO Iteration 33/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 82, Total preference pairs: 25\n\n--- PBO Iteration 34/50 ---\n  Query 1 (U): [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0], Obj: 187.8840\n  Preference: Q2 > Q1\n  Total unique Us: 84, Total preference pairs: 26\n\n--- PBO Iteration 35/50 ---\n  Query 1 (U): [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1], Obj: 195.1057\n  Query 2 (U): [1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 86, Total preference pairs: 27\n\n--- PBO Iteration 36/50 ---\n  Query 1 (U): [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 88, Total preference pairs: 27\n\n--- PBO Iteration 37/50 ---\n  Query 1 (U): [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 90, Total preference pairs: 27\n\n--- PBO Iteration 38/50 ---\n  Query 1 (U): [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 92, Total preference pairs: 27\n\n--- PBO Iteration 39/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 188.4906\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 188.5644\n  Preference: Q1 > Q2\n  Total unique Us: 94, Total preference pairs: 28\n\n--- PBO Iteration 40/50 ---\n  Query 1 (U): [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 96, Total preference pairs: 28\n\n--- PBO Iteration 41/50 ---\n  Query 1 (U): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 98, Total preference pairs: 28\n\n--- PBO Iteration 42/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 187.6943\n  Query 2 (U): [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 100, Total preference pairs: 29\n\n--- PBO Iteration 43/50 ---\n  Query 1 (U): [1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 102, Total preference pairs: 29\n\n--- PBO Iteration 44/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], Obj: 188.9228\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 188.6286\n  Preference: Q2 > Q1\n  Total unique Us: 103, Total preference pairs: 30\n\n--- PBO Iteration 45/50 ---\n  Query 1 (U): [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 105, Total preference pairs: 30\n\n--- PBO Iteration 46/50 ---\n  Query 1 (U): [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1], Obj: 10000000000.0000\n  Preference: Tie\n  Total unique Us: 107, Total preference pairs: 30\n\n--- PBO Iteration 47/50 ---\n  Query 1 (U): [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0], Obj: 187.9551\n  Preference: Q2 > Q1\n  Total unique Us: 109, Total preference pairs: 31\n\n--- PBO Iteration 48/50 ---\n  Query 1 (U): [0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1], Obj: 10000000000.0000\n  Query 2 (U): [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1], Obj: 196.1532\n  Preference: Q2 > Q1\n  Total unique Us: 111, Total preference pairs: 32\n\n--- PBO Iteration 49/50 ---\n  Query 1 (U): [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 208.6713\n  Query 2 (U): [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1], Obj: 10000000000.0000\n  Preference: Q1 > Q2\n  Total unique Us: 113, Total preference pairs: 33\n\n--- PBO Iteration 50/50 ---\n  Query 1 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], Obj: 187.6943\n  Query 2 (U): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], Obj: 188.6286\n  Preference: Q1 > Q2\n  Total unique Us: 113, Total preference pairs: 34\n\n--- PBO Experiment Finished ---\nBest U vector found (by direct evaluation): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\nCorresponding Y schedule: [2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 11]\nObjective value: 187.3268\nFound at PBO iteration 26\nPatient count in final Y schedule: 50\n\nRecommendation based on GP model (highest posterior mean utility over all 113 evaluated Us):\n  U vector: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n  Corresponding Y schedule: [2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 11]\n  Objective value of this GP recommended U: 188.6286\n  GP's posterior mean utility for this U: 1.5571\n\n--- PBO Experiment Finished in 35.67 seconds ---\n```\n:::\n:::\n\n\n## Discussion\n\nIn this study, we demonstrated how Preferential Bayesian Optimization (PBO) combined with Hamming Embeddings via Dictionaries (HED) can efficiently navigate the high-dimensional binary space of schedule perturbations and deliver improved outpatient appointment schedules with far fewer objective evaluations than naïve random or local‐search heuristics.\n\n### Future Directions\n\n**Automated Acquisition–Function Discovery with FunBO.**\\\n@aglietti_funbo_2024 introduce *FunBO*, a technique that leverages large language models to programmatically generate, refine, and evaluate novel Bayesian‐optimization acquisition functions. By iterating between an LLM prompt (to propose new code variants) and empirical benchmarking, FunBO has discovered bespoke strategies that outperform classical rules like Expected Improvement or Upper Confidence Bound on standard continuous benchmarks.\n\n> *Why this matters for HED+PBO:* Our current pipeline uses off‐the‐shelf PBO acquisitions (e.g. Thompson sampling on Hamming‐dictionary inputs). FunBO could be tasked to propose *duel‐specific* acquisition rules—perhaps embedding‐aware diversity measures or adaptive exploration–exploitation schedules—that are tailor‐made for the combinatorial neighborhood of outpatient schedules. Systematically comparing these LLM‐generated acquisitions could lead to even faster convergence or better final schedules, especially in large or highly constrained clinics.\n\n**Inner–Loop Amortization via Learned Proposal Policies.**\\\n@swersky_amortized_2020 train a lightweight neural policy via reinforcement learning to *amortize* the inner maximization of discrete‐space acquisition functions. Instead of exhaustively scanning candidates at each BO step, the network instantly proposes high‐quality points, yielding dramatic per‐iteration speed‐ups on tasks such as protein‐sequence design.\n\n> *Why this matters for HED+PBO:* In our implementation, we still sample and score hundreds of Hamming‐neighbors each iteration—incurring nontrivial runtime as $T$ and the dictionary size grow. By training a “deep evolutionary” proposal network on synthetic perturbation‐scheduling tasks (varying $N,T$, service distributions, no‐show rates), we could *replace* that random/Hamming sampling step with a single neural forward pass, enabling near‐real‐time PBO for large‐scale or interactive applications.\n\n**Fully Amortized Preferential BO with Meta‐Learning.**\\\n@zhang_pabbo_2025 develop PABBO, a transformer‐based meta‐learner that jointly models both the surrogate posterior and the duel acquisition policy. Once pre‐trained on a diverse corpus of BO problems, it requires *no* GP refitting or inner‐loop optimization at test time—simply mapping past duels to new pair scores in one forward pass, and achieving orders‐of‐magnitude speed‐ups while matching or exceeding GP dynamics :contentReference[oaicite:2]{index=\"2\"}.\n\n> *Why this matters for HED+PBO:* Although our HED+PairwiseGP already reduces input dimensionality, each iteration still fits a GP and samples dozens of candidates. A PABBO‐inspired extension could meta‐train on HED‐embedded scheduling duels, so that in a new clinic setting, the model instantly proposes top perturbations—unlocking truly interactive preferential optimization for clinician‐in‐the‐loop scheduling or adaptive appointment systems.\n\nBy exploring these directions—LLM‐driven acquisition design, learned inner‐loop proposals, and fully amortized PBO—we can further improve the **scalability**, **runtime efficiency**, and **automation** of HED‐based preferential optimization for outpatient scheduling.\n\n## Timeline\n\n-   **Experiment Design**: 19-05-2025\n-   **Implementation**: 19-05-2025\n-   **Execution**: (to be filled after run)\n-   **Analysis**: (to be filled after run)\n\n## References\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "preferential-bayesian-optimization_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script type=\"text/javascript\">\nwindow.PlotlyConfig = {MathJaxConfig: 'local'};\nif (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\nif (typeof require !== 'undefined') {\nrequire.undef(\"plotly\");\nrequirejs.config({\n    paths: {\n        'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n    }\n});\nrequire(['plotly'], function(Plotly) {\n    window._Plotly = Plotly;\n});\n}\n</script>\n\n"
      ]
    }
  }
}